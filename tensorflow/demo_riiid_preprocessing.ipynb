{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "demo-riiid-preprocessing.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxypEzmP1FSa"
      },
      "source": [
        "# Logging \n",
        "# set up logging to file - see previous section for more details\n",
        "def create_logging(OUTPUT_FOLDER):\n",
        "    logging.basicConfig(level=logging.DEBUG,\n",
        "                        format='%(asctime)s %(name)-12s %(levelname)-8s %(message)s',\n",
        "                        datefmt='%d-%m %H:%M:%S',\n",
        "                        filename= os.path.join(OUTPUT_FOLDER, 'logger.log'),\n",
        "                        filemode='w')\n",
        "\n",
        "    # define a Handler which writes INFO messages or higher to the sys.stderr or sys.stdout\n",
        "    console = logging.StreamHandler()\n",
        "    console.setLevel(logging.INFO)\n",
        "    # set a format which is simpler for console use\n",
        "    formatter = logging.Formatter(fmt='%(asctime)s %(name)-12s %(levelname)-8s %(message)s',\n",
        "                                  datefmt='%d-%m %H:%M')\n",
        "    # tell the handler to use this format\n",
        "    console.setFormatter(formatter)\n",
        "    # add the handler to the root logger\n",
        "    logging.getLogger().addHandler(console)\n",
        "    return logging"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTVGdnnpuR8L"
      },
      "source": [
        "def read_df_print(path, format = \"feather\"): # TODO: can change to other formats too\n",
        "  if format == \"feather\":\n",
        "    df = pd.read_feather(path)\n",
        "  print(df.shape)\n",
        "  display(df.head(3))\n",
        "  return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gALkAThsoYb-"
      },
      "source": [
        "# Gets a feature as a sequence in lists (with pd.Series)\n",
        "def get_user_sequence(feature):\n",
        "  user_seq = train.groupby(\"user_id\")[feature].apply(list)\n",
        "  return user_seq"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wu4WoWwHo-gz"
      },
      "source": [
        "# Exercises\n",
        "def return_E():\n",
        "  E_lists = get_user_sequence(\"content_id\")\n",
        "  return E_lists"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYkfkgm2qPGf"
      },
      "source": [
        "# Results r\n",
        "def return_r():\n",
        "  # Add results\n",
        "  r_lists = get_user_sequence(\"answered_correctly\") # All results (r)\n",
        "  return r_lists"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ro23M2gxXojl"
      },
      "source": [
        "# Results r\r\n",
        "def return_r(add_start_token):\r\n",
        "  # Add results\r\n",
        "  r_lists = get_user_sequence(\"answered_correctly\") # All results (r)\r\n",
        "\r\n",
        "  # Add start token to r_list\r\n",
        "  if add_start_token:\r\n",
        "    r_lists = r_lists.apply(lambda x: [N_response+1] + x)\r\n",
        "  return r_lists"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZfbY4T4P0k0"
      },
      "source": [
        "# Elapsed time - categorical\r\n",
        "def return_etc():\r\n",
        "    train[\"etc\"] = train[\"prior_question_elapsed_time\"]/1000.0\r\n",
        "    \r\n",
        "    # Add start token\r\n",
        "    train[\"etc\"] = train[\"etc\"].fillna(301)\r\n",
        "    train[\"etc\"] = np.round(train[\"etc\"]).astype(np.int32) # nearest integer\r\n",
        "\r\n",
        "    etc_lists = get_user_sequence(\"etc\") \r\n",
        "    del train[\"etc\"]\r\n",
        "    return etc_lists"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7grgn3TRBSdf"
      },
      "source": [
        "# Lag time - categorical\r\n",
        "def return_ltc():\r\n",
        "    train[\"ltc\"] = train.groupby(\"user_id\")[\"timestamp\"].shift()\r\n",
        "    \r\n",
        "    # Lag in minutes\r\n",
        "    train[\"ltc\"] = ((train[\"timestamp\"] - train[\"ltc\"])/(1000.0 * 60))\r\n",
        "    \r\n",
        "    # Cap lag time to 1440 minutes\r\n",
        "    train[\"ltc\"] = np.clip(train[\"ltc\"], 0, 1439)\r\n",
        "    train[\"ltc\"] = train[\"ltc\"].fillna(1440)\r\n",
        "    train[\"ltc\"] = np.round(train[\"ltc\"]).astype(np.int32) # nearest integer\r\n",
        "\r\n",
        "    ltc_lists = get_user_sequence(\"ltc\") \r\n",
        "    del train[\"ltc\"]\r\n",
        "    return ltc_lists"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sduDbijVV0j"
      },
      "source": [
        "# Attempt number\r\n",
        "def return_attempt(max_attempts=8):\r\n",
        "    train[\"attempt\"] = train.groupby([\"user_id\", \"content_id\"]).cumcount()\r\n",
        "    train[\"attempt\"] = np.clip(train[\"attempt\"], 0, max_attempts-1).astype(np.int16)\r\n",
        "    at_lists = get_user_sequence(\"attempt\")\r\n",
        "    del train[\"attempt\"]\r\n",
        "    return at_lists"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c43TaWofC6hu"
      },
      "source": [
        "# Content difficulty\r\n",
        "def return_ca():\r\n",
        "    ca = train.groupby(\"content_id\")[\"answered_correctly\"].transform('mean')\r\n",
        "    train[\"ca\"] = np.round(ca*100)\r\n",
        "    train[\"ca\"] = np.clip(train[\"ca\"], 0, 100).astype(np.int32)\r\n",
        "    ca = get_user_sequence(\"ca\")\r\n",
        "    del train[\"ca\"]\r\n",
        "    return ca"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJcJmNJhylxo"
      },
      "source": [
        "# Part\n",
        "def return_p():\n",
        "    part_dict = dict(zip(questions.question_id, questions.part))\n",
        "    train[\"part\"]= train[\"content_id\"].map(part_dict).fillna(0).astype(\"int8\")\n",
        "    p_lists = get_user_sequence(\"part\") # All parts (p) of the exercises\n",
        "    del train[\"part\"]\n",
        "    return p_lists"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8N9Jd4fhLEvm"
      },
      "source": [
        "# Prior question had explanation\r\n",
        "def return_ex():\r\n",
        "    train[\"ex\"] = train[\"prior_question_had_explanation\"] # *1 # => binary 0/1\r\n",
        "    train[\"ex\"] = train[\"ex\"].fillna(3) # Start token\r\n",
        "    ex_lists = get_user_sequence(\"ex\")\r\n",
        "    del train[\"ex\"]\r\n",
        "    return ex_lists"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mg79ClJEAxki"
      },
      "source": [
        "# Average result\r\n",
        "def return_r_avg():\r\n",
        "    cums = train.groupby(\"user_id\")[\"answered_correctly\"].cumsum()\r\n",
        "    cumc = train.groupby(\"user_id\")[\"answered_correctly\"].cumcount() + 1\r\n",
        "    train[\"ra\"] = round(100*cums/cumc)\r\n",
        "    train[\"ra\"] = np.clip(train[\"ra\"], 0, 100).astype(np.int32)\r\n",
        "    ra = get_user_sequence(\"ra\")\r\n",
        "    del train[\"ra\"]\r\n",
        "    return ra"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwSkC9kn6G6H"
      },
      "source": [
        "# Elapsed time - grouped\r\n",
        "def return_etg(bins):\r\n",
        "    train[\"etg\"] = train[\"prior_question_elapsed_time\"]/1000.0\r\n",
        "    train[\"etg\"] = np.clip(train[\"etg\"], 0, 300)\r\n",
        "    train[\"etg\"] = np.round(train[\"etg\"]) #.astype(np.int32)\r\n",
        "    \r\n",
        "    N_labels = len(bins)-1\r\n",
        "    train[\"etg\"] = pd.cut(train[\"etg\"], bins, labels = range(N_labels))\r\n",
        "    train[\"etg\"] = np.array(train[\"etg\"]) # Remove category \r\n",
        "    train[\"etg\"] = train[\"etg\"].fillna(N_labels+1).astype(np.int32)\r\n",
        "\r\n",
        "    etg_lists = get_user_sequence(\"etg\") \r\n",
        "    del train[\"etg\"]\r\n",
        "    return etg_lists"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHDgWceaB0Ux"
      },
      "source": [
        "# Lag time dense\r\n",
        "def return_lt():\r\n",
        "    train[\"lt\"] = train.groupby(\"user_id\")[\"timestamp\"].shift()\r\n",
        "    train[\"lt\"] = train[\"timestamp\"] - train[\"lt\"]\r\n",
        "    assert((train[\"lt\"]<0).sum()==0) # There should be no negative time differences\r\n",
        "\r\n",
        "    quantile_transformer = preprocessing.QuantileTransformer(random_state=0)\r\n",
        "    train[\"lt\"] = quantile_transformer.fit_transform(train[\"lt\"].values.reshape(-1, 1))\r\n",
        "    # train[\"lt\"] = train[\"lt\"].fillna(0.0) # Fill NA with 0.0? 0.5?\r\n",
        "    train[\"lt\"] = train[\"lt\"].fillna(0.5)\r\n",
        "        \r\n",
        "    lt_lists = get_user_sequence(\"lt\") \r\n",
        "    del train[\"lt\"]\r\n",
        "    return lt_lists, quantile_transformer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EYwMJcuLVRl"
      },
      "source": [
        "# Elapsed time dense\r\n",
        "def return_et():\r\n",
        "    train[\"et\"] = train[\"prior_question_elapsed_time\"].fillna(0) # Replace \"start\" with zero\r\n",
        "\r\n",
        "    quantile_transformer = preprocessing.QuantileTransformer(random_state=0)\r\n",
        "    qt_transform_train = quantile_transformer.fit_transform(train.loc[train[\"user_id\"].isin(train_users), \"et\"].values.reshape(-1, 1))\r\n",
        "    qt_transform_val = quantile_transformer.transform(train.loc[train[\"user_id\"].isin(val_users), \"et\"].values.reshape(-1, 1))\r\n",
        "    \r\n",
        "    train.loc[train[\"user_id\"].isin(train_users), \"et\"] = qt_transform_train\r\n",
        "    train.loc[train[\"user_id\"].isin(val_users), \"et\"] = qt_transform_val\r\n",
        "\r\n",
        "    et_lists = get_user_sequence(\"et\") # Elapsed  times\r\n",
        "    del train[\"et\"]\r\n",
        "    return et_lists, quantile_transformer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSJcDpXb6Eme"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLnbykIu-85p"
      },
      "source": [
        "# Older code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6HKaATW--rA"
      },
      "source": [
        "# # Elapsed time - grouped\r\n",
        "# def return_etg(N_groups):\r\n",
        "#     train[\"etg\"] = train[\"prior_question_elapsed_time\"]/1000.0\r\n",
        "#     train[\"etg\"] = np.clip(train[\"etg\"], 0, 300)\r\n",
        "#     train[\"etg\"] = np.round(train[\"etg\"]) #.astype(np.int32)\r\n",
        "    \r\n",
        "#     train[\"etg\"] = pd.qcut(train[\"etg\"], N_groups, labels=range(N_groups))\r\n",
        "#     train[\"etg\"] = np.array(train[\"etg\"]) # Start token\r\n",
        "#     train[\"etg\"] = train[\"etg\"].fillna(N_groups).astype(np.int32)\r\n",
        "#     etg_lists = get_user_sequence(\"etg\") \r\n",
        "#     del train[\"etg\"]\r\n",
        "#     return etg_lists"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psxffLl3EIiV"
      },
      "source": [
        "# Seperately train/val\r\n",
        "# qt_transform_train = quantile_transformer.fit_transform(train.loc[train[\"user_id\"].isin(train_users), \"lt\"].values.reshape(-1, 1))\r\n",
        "# qt_transform_val = quantile_transformer.transform(train.loc[train[\"user_id\"].isin(val_users), \"lt\"].values.reshape(-1, 1))\r\n",
        "\r\n",
        "# train.loc[train[\"user_id\"].isin(train_users), \"lt\"] = qt_transform_train\r\n",
        "# train.loc[train[\"user_id\"].isin(val_users), \"lt\"] = qt_transform_val "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}