{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "demo-riiid-preprocessing.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxypEzmP1FSa"
      },
      "source": [
        "# Logging \n",
        "# set up logging to file - see previous section for more details\n",
        "def create_logging(OUTPUT_FOLDER):\n",
        "    logging.basicConfig(level=logging.DEBUG,\n",
        "                        format='%(asctime)s %(name)-12s %(levelname)-8s %(message)s',\n",
        "                        datefmt='%d-%m %H:%M:%S',\n",
        "                        filename= os.path.join(OUTPUT_FOLDER, 'logger.log'),\n",
        "                        filemode='w')\n",
        "\n",
        "    # define a Handler which writes INFO messages or higher to the sys.stderr or sys.stdout\n",
        "    console = logging.StreamHandler()\n",
        "    console.setLevel(logging.INFO)\n",
        "    # set a format which is simpler for console use\n",
        "    formatter = logging.Formatter(fmt='%(asctime)s %(name)-12s %(levelname)-8s %(message)s',\n",
        "                                  datefmt='%d-%m %H:%M')\n",
        "    # tell the handler to use this format\n",
        "    console.setFormatter(formatter)\n",
        "    # add the handler to the root logger\n",
        "    logging.getLogger().addHandler(console)\n",
        "    return logging"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTVGdnnpuR8L"
      },
      "source": [
        "def read_df_print(path, format = \"feather\"): # TODO: can change to other formats too\n",
        "  if format == \"feather\":\n",
        "    df = pd.read_feather(path)\n",
        "  print(df.shape)\n",
        "  display(df.head(3))\n",
        "  return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gALkAThsoYb-"
      },
      "source": [
        "# Gets a feature as a sequence in lists (with pd.Series)\n",
        "def get_user_sequence(feature):\n",
        "  user_seq = train.groupby(\"user_id\")[feature].apply(list)\n",
        "  return user_seq"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wu4WoWwHo-gz"
      },
      "source": [
        "# Exercises\n",
        "def return_E():\n",
        "  E_lists = get_user_sequence(\"content_id\")\n",
        "  return E_lists"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYkfkgm2qPGf"
      },
      "source": [
        "# Results r\n",
        "def return_r():\n",
        "  # Add results\n",
        "  r_lists = get_user_sequence(\"answered_correctly\") # All results (r)\n",
        "  return r_lists"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ro23M2gxXojl"
      },
      "source": [
        "# Results r\r\n",
        "def return_r(add_start_token):\r\n",
        "  # Add results\r\n",
        "  r_lists = get_user_sequence(\"answered_correctly\") # All results (r)\r\n",
        "\r\n",
        "  # Add start token to r_list\r\n",
        "  if add_start_token:\r\n",
        "    r_lists = r_lists.apply(lambda x: [N_response+1] + x)\r\n",
        "  return r_lists"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7grgn3TRBSdf"
      },
      "source": [
        "# Lag time - categorical\r\n",
        "def return_ltc():\r\n",
        "    train[\"ltc\"] = train.groupby(\"user_id\")[\"timestamp\"].shift()\r\n",
        "    \r\n",
        "    # Lag in minutes\r\n",
        "    train[\"ltc\"] = ((train[\"timestamp\"] - train[\"ltc\"])/(1000.0 * 60))\r\n",
        "    \r\n",
        "    # Cap lag time to 1440 minutes\r\n",
        "    train[\"ltc\"] = np.clip(train[\"ltc\"], 0, 1439)\r\n",
        "    train[\"ltc\"] = train[\"ltc\"].fillna(1440)\r\n",
        "    train[\"ltc\"] = train[\"ltc\"].astype(np.int32)\r\n",
        "\r\n",
        "    ltc_lists = get_user_sequence(\"ltc\") \r\n",
        "    del train[\"ltc\"]\r\n",
        "    return ltc_lists"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHDgWceaB0Ux"
      },
      "source": [
        "# Lag time dense\r\n",
        "def return_lt():\r\n",
        "    train[\"lt\"] = train.groupby(\"user_id\")[\"timestamp\"].shift()\r\n",
        "    train[\"lt\"] = train[\"timestamp\"] - train[\"lt\"]\r\n",
        "    assert((train[\"lt\"]<0).sum()==0) # There should be no negative time differences\r\n",
        "\r\n",
        "    quantile_transformer = preprocessing.QuantileTransformer(random_state=0)\r\n",
        "    train[\"lt\"] = quantile_transformer.fit_transform(train[\"lt\"].values.reshape(-1, 1))\r\n",
        "    # train[\"lt\"] = train[\"lt\"].fillna(0.0) # Fill NA with 0.0? 0.5?\r\n",
        "    train[\"lt\"] = train[\"lt\"].fillna(0.5)\r\n",
        "        \r\n",
        "    lt_lists = get_user_sequence(\"lt\") \r\n",
        "    del train[\"lt\"]\r\n",
        "    return lt_lists, quantile_transformer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EYwMJcuLVRl"
      },
      "source": [
        "# Elapsed time dense\r\n",
        "def return_et():\r\n",
        "    train[\"et\"] = train[\"prior_question_elapsed_time\"].fillna(0) # Replace \"start\" with zero\r\n",
        "\r\n",
        "    quantile_transformer = preprocessing.QuantileTransformer(random_state=0)\r\n",
        "    qt_transform_train = quantile_transformer.fit_transform(train.loc[train[\"user_id\"].isin(train_users), \"et\"].values.reshape(-1, 1))\r\n",
        "    qt_transform_val = quantile_transformer.transform(train.loc[train[\"user_id\"].isin(val_users), \"et\"].values.reshape(-1, 1))\r\n",
        "    \r\n",
        "    train.loc[train[\"user_id\"].isin(train_users), \"et\"] = qt_transform_train\r\n",
        "    train.loc[train[\"user_id\"].isin(val_users), \"et\"] = qt_transform_val\r\n",
        "\r\n",
        "    et_lists = get_user_sequence(\"et\") # Elapsed  times\r\n",
        "    del train[\"et\"]\r\n",
        "    return et_lists, quantile_transformer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZfbY4T4P0k0"
      },
      "source": [
        "# Elapsed time - categorical\r\n",
        "def return_etc():\r\n",
        "    train[\"etc\"] = train[\"prior_question_elapsed_time\"]/1000.0\r\n",
        "    \r\n",
        "    # Add start token\r\n",
        "    train[\"etc\"] = train[\"etc\"].fillna(301)\r\n",
        "    train[\"etc\"] = train[\"etc\"].astype(np.int32)\r\n",
        "\r\n",
        "    etc_lists = get_user_sequence(\"etc\") \r\n",
        "    del train[\"etc\"]\r\n",
        "    return etc_lists"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJcJmNJhylxo"
      },
      "source": [
        "# Part\n",
        "def return_p():\n",
        "    part_dict = dict(zip(questions.question_id, questions.part))\n",
        "    train[\"part\"]= train[\"content_id\"].map(part_dict).fillna(0).astype(\"int8\")\n",
        "    p_lists = get_user_sequence(\"part\") # All parts (p) of the exercises\n",
        "    del train[\"part\"]\n",
        "    return p_lists"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psxffLl3EIiV"
      },
      "source": [
        "# Seperately train/val\r\n",
        "# qt_transform_train = quantile_transformer.fit_transform(train.loc[train[\"user_id\"].isin(train_users), \"lt\"].values.reshape(-1, 1))\r\n",
        "# qt_transform_val = quantile_transformer.transform(train.loc[train[\"user_id\"].isin(val_users), \"lt\"].values.reshape(-1, 1))\r\n",
        "\r\n",
        "# train.loc[train[\"user_id\"].isin(train_users), \"lt\"] = qt_transform_train\r\n",
        "# train.loc[train[\"user_id\"].isin(val_users), \"lt\"] = qt_transform_val "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}