{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "demo-riiid-train.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1alPO9cYR8zX",
        "outputId": "08756a5a-77f9-4778-8acb-2369a843f632"
      },
      "source": [
        "# Install latest version sklearn (0.23)\n",
        "!pip install -U scikit-learn"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scikit-learn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/aa/db462d385c56905b731403885454188683f63c86ea68900f6f7e7558b5fa/scikit_learn-0.24.0-cp36-cp36m-manylinux2010_x86_64.whl (22.2MB)\n",
            "\u001b[K     |████████████████████████████████| 22.2MB 68.3MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.0.0)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.19.4)\n",
            "Collecting threadpoolctl>=2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f7/12/ec3f2e203afa394a149911729357aa48affc59c20e2c1c8297a60f33f133/threadpoolctl-2.1.0-py3-none-any.whl\n",
            "Installing collected packages: threadpoolctl, scikit-learn\n",
            "  Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "Successfully installed scikit-learn-0.24.0 threadpoolctl-2.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "id": "fl0JGKUzPcs0"
      },
      "source": [
        "# Imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import shutil\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import gc\n",
        "import sys\n",
        "import random\n",
        "import pickle\n",
        "\n",
        "from scipy.stats import iqr\n",
        "from sklearn import preprocessing\n",
        "\n",
        "import datetime\n",
        "import logging\n",
        "\n",
        "# Deep learning\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "import tensorflow.keras.layers as L\n",
        "import tensorflow.keras.models as M\n",
        "\n",
        "from IPython.display import display\n",
        "# Set pandas options\n",
        "pd.options.display.max_rows = 2000"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "id": "TyCCeSTaw6_s"
      },
      "source": [
        "# Global variables \n",
        "THR_E = 100 # interaction threshold of exercises (E) for user\n",
        "BATCH_SIZE = 128\n",
        "TRAIN_FRACTION = 0.95\n",
        "\n",
        "AUTO = tf.data.experimental.AUTOTUNE\n",
        "EPOCHS = 160\n",
        "N_SELECT_PER_EPOCH = 100000 # Random select N samples for each epoch from train/val set\n",
        "VAL_EVERY_N_EPOCHS = 5\n",
        "PRINT_EVERY_N_BATCHES = 50 \n",
        "ZERO_TASK_ETC = True\n",
        "\n",
        "SAVE_DICTS = True"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4M-mWBNVcaQ7"
      },
      "source": [
        "# SEED THE EXPERIMENTS\r\n",
        "np.random.seed(18)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XR5Io93kU0RK"
      },
      "source": [
        "# Experiment date and number!\r\n",
        "date = datetime.datetime.today().strftime(\"%d-%b\")\r\n",
        "experiment = \"-riiid-3\"\r\n",
        "OUTPUT_FOLDER = date + experiment \r\n",
        "os.makedirs(OUTPUT_FOLDER, exist_ok=True)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPFvJd9PsbR6"
      },
      "source": [
        "# Selected features\n",
        "selections = [\"E\", \"r\", \"etc\", \"ltg\", \"at\", \"p\", \"ex\"]\n",
        "assert((selections[0] == \"E\") & (selections[1]==\"r\"))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wiHtMtRWAvE8"
      },
      "source": [
        "# Choose model setting\n",
        "ENC_EMB, ENC_DENSE = [0, 4, 5], [] \n",
        "DEC_EMB, DEC_DENSE = [1, 2, 3, 6], []"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRrlNtCi8QxP",
        "outputId": "b352f86b-1876-469e-8842-cf23b4d510a8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "FOLDER_FEATHER = \"/content/drive/My Drive/kaggle-riiid/feather-files\"\n",
        "PREPROCESS_FILE = \"/content/drive/My\\ Drive/Colab\\ Notebooks/demo-riiid-preprocessing.ipynb\"\n",
        "MODEL_FILE = \"/content/drive/My\\ Drive/Colab\\ Notebooks/demo-riiid-transformer.ipynb\" # https://stackoverflow.com/questions/57464810/how-to-run-a-jupyter-notebook-with-space-in-relative-path-from-another-notebook\n",
        "# MODEL_FILE = \"/content/drive/My\\ Drive/Colab\\ Notebooks/riiid-functional-transformer.ipynb\" # https://stackoverflow.com/questions/57464810/how-to-run-a-jupyter-notebook-with-space-in-relative-path-from-another-notebook\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2pN4ICUn9tK"
      },
      "source": [
        "# Add functions to preprocess data\n",
        "%run $PREPROCESS_FILE"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eoay_2ef1W7r"
      },
      "source": [
        "# Create logger\n",
        "logging = create_logging(OUTPUT_FOLDER)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "4aC9MfDSbI0c",
        "outputId": "311e71b6-a718-43dc-8c00-41d3ee50ed13"
      },
      "source": [
        "%%time\n",
        "# Read all dataframes from feather files and print out\n",
        "train = read_df_print(os.path.join(FOLDER_FEATHER, \"train.feather\")) \n",
        "questions = read_df_print(os.path.join(FOLDER_FEATHER, \"questions.feather\"))\n",
        "lectures = read_df_print(os.path.join(FOLDER_FEATHER, \"lectures.feather\"))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(101230332, 10)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>row_id</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>user_id</th>\n",
              "      <th>content_id</th>\n",
              "      <th>content_type_id</th>\n",
              "      <th>task_container_id</th>\n",
              "      <th>user_answer</th>\n",
              "      <th>answered_correctly</th>\n",
              "      <th>prior_question_elapsed_time</th>\n",
              "      <th>prior_question_had_explanation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>115</td>\n",
              "      <td>5692</td>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>56943</td>\n",
              "      <td>115</td>\n",
              "      <td>5716</td>\n",
              "      <td>False</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>37000.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>118363</td>\n",
              "      <td>115</td>\n",
              "      <td>128</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>55000.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   row_id  ...  prior_question_had_explanation\n",
              "0       0  ...                            None\n",
              "1       1  ...                           False\n",
              "2       2  ...                           False\n",
              "\n",
              "[3 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "(13523, 5)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question_id</th>\n",
              "      <th>bundle_id</th>\n",
              "      <th>correct_answer</th>\n",
              "      <th>part</th>\n",
              "      <th>tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>51 131 162 38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>131 36 81</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>131 101 162 92</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   question_id  bundle_id  correct_answer  part            tags\n",
              "0            0          0               0     1   51 131 162 38\n",
              "1            1          1               1     1       131 36 81\n",
              "2            2          2               0     1  131 101 162 92"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "(418, 4)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lecture_id</th>\n",
              "      <th>tag</th>\n",
              "      <th>part</th>\n",
              "      <th>type_of</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>89</td>\n",
              "      <td>24584</td>\n",
              "      <td>5</td>\n",
              "      <td>concept</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>100</td>\n",
              "      <td>22243</td>\n",
              "      <td>1</td>\n",
              "      <td>concept</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>185</td>\n",
              "      <td>7035</td>\n",
              "      <td>6</td>\n",
              "      <td>concept</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   lecture_id    tag  part  type_of\n",
              "0          89  24584     5  concept\n",
              "1         100  22243     1  concept\n",
              "2         185   7035     6  concept"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1.69 s, sys: 2.07 s, total: 3.76 s\n",
            "Wall time: 29.5 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PrxymFQ6jkrL",
        "outputId": "e71619d8-48ba-45b3-e6ac-8c38cf217bca"
      },
      "source": [
        "train[\"content_type_id\"].sum()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1959032"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXzO9eqHzFhg"
      },
      "source": [
        "# train[\"user_id\"].value_counts().hist()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKCkG5SuiEnQ"
      },
      "source": [
        "# Preprocess for lectures\n",
        "if (\"v\" in selections) or (\"l\" in selections) or (\"vc\" in selections):\n",
        "    lectures[\"lecture_id\"] = pd.Categorical(lectures[\"lecture_id\"])\n",
        "    lectures[\"new_id\"] = lectures[\"lecture_id\"].cat.codes\n",
        "    lec_map = dict(zip(lectures[\"lecture_id\"], lectures[\"new_id\"]))\n",
        "\n",
        "    train[\"l\"] = train[\"content_id\"]\n",
        "    boolean_lec = train[\"content_type_id\"]==1\n",
        "    train.loc[boolean_lec, \"l\"] = train.loc[boolean_lec, \"l\"].map(lec_map)\n",
        "    train[\"v\"] = train[\"content_type_id\"].shift(1).fillna(0).astype(np.int8)\n",
        "    train[\"l\"] = train[\"l\"].shift(1).fillna(418).astype(np.int32)\n",
        "    train.loc[train[\"v\"]==0, \"l\"] = 418 # Start token value\n",
        "    train[\"vc\"] = train.groupby(\"user_id\")[\"v\"].cumsum()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifHkb8aPPhma",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "772d93e5-d7a6-4b3c-f8a8-4402b7542016"
      },
      "source": [
        "# We don't need the lectures now!\n",
        "train = train.loc[train[\"content_type_id\"]==0]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "31-12 11:46 numexpr.utils INFO     NumExpr defaulting to 4 threads.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XqeE-GuynMui"
      },
      "source": [
        "# Save space by deleting some columns\n",
        "del train[\"user_answer\"]"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "id": "yjODj3l-Eas9"
      },
      "source": [
        "N_questions, N_parts = questions[\"question_id\"].nunique(), questions[\"part\"].nunique()\n",
        "N_response, N_task, N_lag, N_et, N_groups, N_attempt, N_avg, N_ltg, N_l, N_pos = 2, 2, 1440, 301, 10, 8, 101, 4000, 418, 1000 # N_avg = 100 for regular?"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bp-gBbzHlND"
      },
      "source": [
        "# Seq len of users [sorted same as df]. USED FOR TRAINING\n",
        "seq_len_dict = dict(train[\"user_id\"].value_counts())\n",
        "users = train[\"user_id\"].unique()\n",
        "seq_lens = [seq_len_dict[user] for user in users]"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kF2zoN0jRqzV"
      },
      "source": [
        "# Train/valid split\r\n",
        "train_len = int(len(users)*TRAIN_FRACTION)\r\n",
        "val_len = len(users) - train_len\r\n",
        "train_users, val_users = users[:train_len], users[train_len:]\r\n",
        "\r\n",
        "# PROBS of sequence\r\n",
        "seq_len_train, seq_len_val = seq_lens[:train_len], seq_lens[train_len:]\r\n",
        "PROBS_TRAIN = seq_len_train/np.sum(seq_len_train)\r\n",
        "PROBS_VAL = seq_len_val/np.sum(seq_len_val)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5pBSw-YFjgZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a76269b-cccd-40c9-e7a0-61f66b68899b"
      },
      "source": [
        "len(train_users), len(val_users)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(373973, 19683)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhH7a4bGQDjZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8dec7c17-d023-442a-eeca-25199499c840"
      },
      "source": [
        "train[\"prior_question_had_explanation\"].isnull().sum() # Less than users - why?"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "392506"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWvX2zk-AIBg"
      },
      "source": [
        "## Add all inputs/outputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8P_CP-lACNhq"
      },
      "source": [
        "p_lists, lt_lists, et_lists, tag_lists, task_lists, quantile_transformer_et, lt_cat, quantile_transformer_lt, et_cat, ltc, etc, ex, etg, ra, ca, at, r_dup, ltg, ltg_bins, v_lists, l_lists, n  = [], [], [], [], [], [], [], [], [], [],[], [], [], [], [], [], [], [], [], [], [], []"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUDcPATyYwkN"
      },
      "source": [
        "if \"l\" in selections:\r\n",
        "  %time l_lists = return_l()\r\n",
        "  del train[\"l\"], train[\"v\"], train[\"vc\"]\r\n",
        "if \"v\" in selections:\r\n",
        "    %time v_lists = return_v()\r\n",
        "    del train[\"l\"], train[\"v\"], train[\"vc\"]"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQw0mNR3QJy3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4cf4331-d739-4c98-d448-bdd7cf7bcccc"
      },
      "source": [
        "if \"at\" in selections:\r\n",
        "    %time at = return_attempt()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1min 6s, sys: 3.52 s, total: 1min 10s\n",
            "Wall time: 1min 9s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmyjLmh_-PUc"
      },
      "source": [
        "n_bins = []\r\n",
        "if \"n\" in selections:\r\n",
        "  %time n, N_pos, n_bins = return_n(N_pos)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgJckHd9R47p"
      },
      "source": [
        "if \"ra\" in selections:\r\n",
        "    %time ra = return_r_avg(add_start_token=True, N_avg = N_avg)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "id": "aTBlz8gcKwIq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f03bef16-bb24-4516-b0c0-6c367aa982e7"
      },
      "source": [
        "# Add exercises\n",
        "%time E_lists = return_E()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 27.6 s, sys: 1.41 s, total: 29 s\n",
            "Wall time: 29 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NhhuL1-QDUT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "556c2b33-d025-4840-a17a-1864ab0ea42d"
      },
      "source": [
        "# Add results, with or without start token\n",
        "%time r_lists = return_r(add_start_token=True)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 28.9 s, sys: 279 ms, total: 29.1 s\n",
            "Wall time: 29.1 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqqgBFwxvMI6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edaea7ba-ab4f-49c3-c166-ae76769d2c91"
      },
      "source": [
        "# Lag time grouped\r\n",
        "if \"ltg\" in selections:\r\n",
        "    %time ltg, ltg_bins, N_ltg = return_ltg(N_ltg)    \r\n",
        "print(N_ltg)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 47 s, sys: 734 ms, total: 47.8 s\n",
            "Wall time: 46.9 s\n",
            "678\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4lfwLZ1UHFE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b24bf594-42c4-4782-d51e-8f89ed2fe1a6"
      },
      "source": [
        "if \"etc\" in selections:\r\n",
        "    %time etc = return_etc(zero_task=ZERO_TASK_ETC)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 44.6 s, sys: 543 ms, total: 45.1 s\n",
            "Wall time: 44.8 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hp6pkC62ZRw"
      },
      "source": [
        "if \"r_dup\" in selections:\r\n",
        "   %time r_dup = r_lists.apply(lambda x: x[:-1])"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uA-ropTQLh81"
      },
      "source": [
        "if \"ca\" in selections:\r\n",
        "    %time ca = return_ca()"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCZ0-bcyNAxi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a57ba746-ec6b-4d62-bcb7-37fdfcfe3c96"
      },
      "source": [
        "if \"ex\" in selections:\r\n",
        "    %time ex = return_ex()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 40.8 s, sys: 386 ms, total: 41.2 s\n",
            "Wall time: 41.2 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7OIGHkzpVYN"
      },
      "source": [
        "if \"ltc\" in selections:\n",
        "    %time ltc = return_ltc()"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrREQHH1RR84"
      },
      "source": [
        "bins = list(range(30)) + [32, 35, 40, 48, 60, 80, 120, 299, 300]\r\n",
        "if \"etg\" in selections:\r\n",
        "    %time etg = return_etg(bins)\r\n",
        "    # %time etg = return_etg(N_groups)\r\n"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFCxAcxx_6Op"
      },
      "source": [
        "if \"lt\" in selections:\n",
        "    %time lt_lists, quantile_transformer_lt = return_lt()"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRFLPPQ4_6Om",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e18b93b-4aa2-43b0-916f-0ef0d1f875d8"
      },
      "source": [
        "if \"p\" in selections:\n",
        "    %time p_lists = return_p()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 23.8 s, sys: 189 ms, total: 24 s\n",
            "Wall time: 24 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yEUWCAAXNsl3"
      },
      "source": [
        "if \"et\" in selections:\r\n",
        "    %time et_lists, quantile_transformer_et = return_et()"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2pE03BaNqid"
      },
      "source": [
        "if \"tag\" in selections:\n",
        "    %time tag_lists = return_N_highest_tags() # TODO: specify N tags"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gF9IXoPo8VZW"
      },
      "source": [
        "if \"task\" in selections:\n",
        "    %time task_lists = return_task_binary()"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUSTsXKtEX4o"
      },
      "source": [
        "feature_mapping = {\"E\": E_lists, \"r\": r_lists, \"p\": p_lists, \"et\": et_lists, \"lt\": lt_lists, \"tag\": tag_lists, \"task\": task_lists, \"et_std\": et_lists, \"ltc\": ltc, \"etc\": etc, \"ex\": ex, \"etg\": etg, \"ra\": ra, \"at\": at, \"ca\": ca, \"r_dup\": r_dup, \"v\": v_lists, \"ltg\": ltg, \"l\": l_lists, \"n\": n}\n",
        "type_mapping = {\"E\": tf.int32, \"r\": tf.int32, \"p\": tf.int32, \"et\": tf.float32, \"et_std\": tf.float32, \"lt\": tf.float32, \"tag\": tf.float32, \"task\": tf.float32, \"ltc\":tf.int32, \"etc\": tf.int32, \"ex\": tf.int32, \"etg\": tf.int32, \"ra\": tf.int32, \"at\": tf.int32, \"ca\": tf.int32, \"r_dup\": tf.int32, \"v\": tf.int32, \"ltg\": tf.int32, \"l\": tf.int32, \"n\": tf.int32}\n",
        "pad_mapping = {\"E\": N_questions, \"r\": N_response, \"p\": 0, \"et\": 0.5, \"et_std\": 0.0, \"lt\": 0.5, \"tag\": 2.0, \"task\": float(N_task), \"ltc\": N_lag+1, \"etc\": N_et+1, \"ex\": 2, \"etg\": len(bins)+1, \"ra\": N_avg+1, \"at\": N_attempt, \"ca\": N_avg+1, \"r_dup\": N_response, \"v\": N_response, \"ltg\": N_ltg+2, \"l\": N_l+1, \"n\": N_pos+1}\n",
        "vocab_mapping = {\"E\": N_questions+1, \"r\": N_response+2, \"et\":None, \"p\": N_parts+1, \"lt\": None, \"tag\": 3.0, \"task\": float(N_task+1), \"et_std\": float(300), \"ltc\": N_lag+2, \"etc\": N_et+2, \"ex\": 4, \"etg\": len(bins)+2, \"ra\": N_avg+2, \"at\": N_attempt+1, \"ca\": N_avg+2, \"r_dup\": N_response+2, \"v\": N_response+1, \"ltg\": N_ltg+3, \"l\": N_l+2, \"n\": N_pos+2}\n",
        "pad_shapes = {\"E\": [THR_E], \"r\": [THR_E+1], \"p\": [THR_E], \"et\": [THR_E], \"et_std\": [THR_E],  \"lt\": [THR_E], \"tag\": [THR_E], \"task\": [THR_E], \"ltc\": [THR_E], \"etc\": [THR_E], \"ex\": [THR_E], \"etg\": [THR_E], \"ra\": [THR_E], \"at\": [THR_E], \"ca\": [THR_E], \"r_dup\": [THR_E], \"v\": [THR_E], \"ltg\": [THR_E], \"l\": [THR_E], \"n\": [THR_E]}"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_g8Yp5YRrtXw"
      },
      "source": [
        "def save_as_dict(df, filename):\n",
        "    seq_dict = df.to_dict()\n",
        "    with open(os.path.join(OUTPUT_FOLDER_DICT, filename), 'wb') as handle:\n",
        "      pickle.dump(seq_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "poOMvtlCq1Pl"
      },
      "source": [
        "if SAVE_DICTS:\n",
        "  OUTPUT_FOLDER_DICT = f\"seq-dict-{THR_E}\"\n",
        "  os.makedirs(OUTPUT_FOLDER_DICT, exist_ok=True)\n",
        "\n",
        "  for feature in selections:\n",
        "      feat_df = feature_mapping[feature]\n",
        "      feat_df = feat_df.apply(lambda x: x[-THR_E:]) # Take last THR_E in history \n",
        "      filename = f\"{feature}.pickle\"\n",
        "      save_as_dict(feat_df, filename)\n",
        "  shutil.move(OUTPUT_FOLDER_DICT, OUTPUT_FOLDER)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipaNyd2L4E3f"
      },
      "source": [
        "# # Add start token!\r\n",
        "# # Answers\r\n",
        "# r_lists = r_lists.apply(lambda x: [3] + x) # Start token = 3\r\n",
        "# feature_mapping[\"r\"] = r_lists"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6aQlsiawcO-8"
      },
      "source": [
        "# Running answers\r\n",
        "if \"ra\" in selections:\r\n",
        "    ra = ra.apply(lambda x: x[:-1]) # For training => we don't have last value of average\r\n",
        "    feature_mapping[\"ra\"] = ra"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtGXR1IZvyKP"
      },
      "source": [
        "vocab_sizes = [vocab_mapping[select] for select in selections]\n",
        "feature_lists = [feature_mapping[select] for select in selections]"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ai9vHiP4I1hI"
      },
      "source": [
        "PADDING_VALUES = tuple((pad_mapping[select] for select in selections))\n",
        "OUTPUT_TYPES = tuple((type_mapping[select] for select in selections))\n",
        "PADDED_SHAPES = tuple((pad_shapes[select] for select in selections))"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sO-UUR-V21KT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57b0517f-a9fc-4eba-d9c0-6ce68ad0b2ef"
      },
      "source": [
        "feature_lists"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[user_id\n",
              " 115           [5692, 5716, 128, 7860, 7922, 156, 51, 50, 789...\n",
              " 124           [7900, 7876, 175, 1278, 2064, 2063, 2065, 3364...\n",
              " 2746          [5273, 758, 5976, 236, 404, 382, 405, 873, 531...\n",
              " 5382          [5000, 3944, 217, 5844, 5965, 4990, 5235, 6050...\n",
              " 8623          [3915, 4750, 6456, 3968, 6104, 5738, 6435, 549...\n",
              "                                     ...                        \n",
              " 2147470770    [7900, 7876, 175, 1278, 2064, 2065, 2063, 3363...\n",
              " 2147470777    [7900, 7876, 175, 1278, 2065, 2064, 2063, 3365...\n",
              " 2147481750    [4137, 1270, 9261, 8201, 367, 378, 214, 6071, ...\n",
              " 2147482216    [3748, 4765, 5474, 9261, 4665, 5987, 6666, 561...\n",
              " 2147482888    [6147, 4792, 5738, 6102, 4748, 7956, 6435, 928...\n",
              " Name: content_id, Length: 393656, dtype: object, user_id\n",
              " 115           [3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, ...\n",
              " 124           [3, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, ...\n",
              " 2746          [3, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, ...\n",
              " 5382          [3, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, ...\n",
              " 8623          [3, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, ...\n",
              "                                     ...                        \n",
              " 2147470770    [3, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, ...\n",
              " 2147470777    [3, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, ...\n",
              " 2147481750    [3, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, ...\n",
              " 2147482216    [3, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, ...\n",
              " 2147482888    [3, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, ...\n",
              " Name: answered_correctly, Length: 393656, dtype: object, user_id\n",
              " 115           [301, 37, 55, 19, 11, 5, 17, 17, 16, 16, 17, 2...\n",
              " 124           [301, 26, 29, 26, 18, 0, 0, 33, 0, 0, 21, 0, 0...\n",
              " 2746          [301, 28, 17, 24, 20, 16, 16, 19, 18, 18, 20, ...\n",
              " 5382          [301, 24, 35, 88, 18, 12, 5, 92, 70, 14, 79, 6...\n",
              " 8623          [301, 16, 33, 30, 40, 35, 30, 29, 15, 19, 14, ...\n",
              "                                     ...                        \n",
              " 2147470770    [301, 21, 22, 26, 16, 0, 0, 25, 0, 0, 24, 0, 0...\n",
              " 2147470777    [301, 23, 23, 23, 17, 0, 0, 26, 0, 0, 18, 0, 0...\n",
              " 2147481750    [301, 19, 18, 8, 21, 15, 15, 18, 17, 14, 22, 2...\n",
              " 2147482216    [301, 38, 27, 17, 9, 12, 28, 22, 25, 15, 19, 1...\n",
              " 2147482888    [301, 15, 18, 21, 21, 16, 20, 41, 41, 30, 18, ...\n",
              " Name: etc, Length: 393656, dtype: object, user_id\n",
              " 115           [679, 55, 59, 11, 5, 17, 17, 16, 16, 17, 22, 2...\n",
              " 124           [679, 31, 27, 20, 104, 678, 678, 67, 678, 678,...\n",
              " 2746          [679, 20, 25, 21, 18, 18, 21, 98, 47, 43, 27, ...\n",
              " 5382          [679, 38, 90, 20, 13, 7, 94, 72, 16, 82, 70, 4...\n",
              " 8623          [679, 37, 32, 42, 37, 32, 30, 17, 20, 16, 39, ...\n",
              "                                     ...                        \n",
              " 2147470770    [679, 23, 26, 16, 76, 678, 678, 75, 678, 678, ...\n",
              " 2147470777    [679, 25, 527, 18, 116, 678, 678, 107, 678, 67...\n",
              " 2147481750    [679, 21, 9, 22, 16, 16, 22, 18, 15, 23, 73, 2...\n",
              " 2147482216    [679, 29, 18, 10, 13, 28, 23, 26, 248, 57, 45,...\n",
              " 2147482888    [679, 19, 21, 22, 17, 21, 41, 646, 36, 54, 356...\n",
              " Name: ltg, Length: 393656, dtype: object, user_id\n",
              " 115           [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
              " 124           [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
              " 2746          [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, ...\n",
              " 5382          [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
              " 8623          [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
              "                                     ...                        \n",
              " 2147470770    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
              " 2147470777    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
              " 2147481750    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
              " 2147482216    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
              " 2147482888    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
              " Name: attempt, Length: 393656, dtype: object, user_id\n",
              " 115           [5, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
              " 124           [1, 1, 1, 2, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, ...\n",
              " 2746          [5, 2, 5, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...\n",
              " 5382          [5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 5, 1, 1, 1, 1, ...\n",
              " 8623          [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 2, 2, 2, ...\n",
              "                                     ...                        \n",
              " 2147470770    [1, 1, 1, 2, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, ...\n",
              " 2147470777    [1, 1, 1, 2, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, ...\n",
              " 2147481750    [5, 2, 5, 5, 2, 2, 2, 5, 5, 5, 5, 5, 5, 5, 5, ...\n",
              " 2147482216    [5, 5, 5, 5, 5, 5, 5, 5, 2, 2, 2, 2, 2, 2, 2, ...\n",
              " 2147482888    [5, 5, 5, 5, 5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...\n",
              " Name: part, Length: 393656, dtype: object, user_id\n",
              " 115           [3, False, False, False, False, False, False, ...\n",
              " 124           [3, False, False, False, False, False, False, ...\n",
              " 2746          [3, False, False, False, False, False, False, ...\n",
              " 5382          [3, False, False, False, False, False, False, ...\n",
              " 8623          [3, False, False, False, False, False, False, ...\n",
              "                                     ...                        \n",
              " 2147470770    [3, False, False, False, False, False, False, ...\n",
              " 2147470777    [3, False, False, False, False, False, False, ...\n",
              " 2147481750    [3, False, False, False, False, False, False, ...\n",
              " 2147482216    [3, False, False, False, False, False, False, ...\n",
              " 2147482888    [3, False, False, False, False, False, False, ...\n",
              " Name: ex, Length: 393656, dtype: object]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "id": "POEyvHfcIBws",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e27af3a-9674-4bd4-8bfb-132818dbf50e"
      },
      "source": [
        "try:\n",
        "  del train\n",
        "except Exception as e:\n",
        "  print(\"train already deleted\")\n",
        "gc.collect(), gc.collect()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzzYXM3bba7p"
      },
      "source": [
        "# Create train/val datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJMvNzqIY8QS"
      },
      "source": [
        "# Lists of numpy arrays\r\n",
        "train_list = [features.values[:train_len] for features in feature_lists]\r\n",
        "val_list = [features.values[train_len:] for features in feature_lists]"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wkQrxFMtI-s"
      },
      "source": [
        "def select_window_size(*x):\n",
        "    series_len = len(x[0]) # Length of series\n",
        "    if series_len <= THR_E: # Just return the sequence!\n",
        "        return x\n",
        "    else: # Random select from sequence\n",
        "        max_select = series_len - THR_E\n",
        "        random_select = tf.random.uniform(shape=(), minval=0, maxval=max_select, dtype=tf.int32)\n",
        "        x = [i[random_select:random_select+THR_E] for i in x]\n",
        "        x = tuple(x)\n",
        "        return x"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "teDfc5v2UNAp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25a498ce-4049-4a86-aafa-e652101d3b7e"
      },
      "source": [
        "train_list"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([list([5692, 5716, 128, 7860, 7922, 156, 51, 50, 7896, 7863, 152, 104, 108, 7900, 7901, 7971, 25, 183, 7926, 7927, 4, 7984, 45, 185, 55, 7876, 6, 172, 7898, 175, 100, 7859, 57, 7948, 151, 167, 7897, 7882, 7962, 1278, 2065, 2064, 2063, 3363, 3365, 3364]),\n",
              "        list([7900, 7876, 175, 1278, 2064, 2063, 2065, 3364, 3365, 3363, 2948, 2947, 2946, 2595, 2593, 2594, 4492, 4120, 4696, 6116, 6173, 6370, 6909, 6910, 6908, 6911, 7218, 7216, 7217, 7219]),\n",
              "        list([5273, 758, 5976, 236, 404, 382, 405, 873, 531, 775, 294, 714, 297, 297, 775, 1295, 10684, 1014, 484]),\n",
              "        ...,\n",
              "        list([7900, 7876, 175, 1278, 2064, 2063, 2065, 3364, 3365, 3363, 2947, 2948, 2946, 2593, 2595, 2594, 4492, 4120, 4696, 6116, 6173, 6370, 6878, 6880, 6879, 6877, 7219, 7218, 7217, 7216, 6106, 4755, 9313, 3586, 4476, 6432, 5845, 9094, 6191, 5437]),\n",
              "        list([7900, 7876, 175, 1278, 2064, 2063, 2065, 3364, 3363, 3365, 2946, 2948, 2947, 2594, 2595, 2593, 4492, 4120, 4696, 6116, 6173, 6370, 6879, 6880, 6877, 6878, 7219, 7218, 7216, 7217]),\n",
              "        list([7900, 7876, 175, 1278, 2065, 2064, 2063, 3363, 3364, 3365, 2947, 2948, 2946, 2593, 2594, 2595, 4492, 4120, 4696, 6116, 6173, 6370, 6878, 6877, 6880, 6879, 7217, 7218, 7216, 7219])],\n",
              "       dtype=object),\n",
              " array([list([3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1]),\n",
              "        list([3, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]),\n",
              "        list([3, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1]),\n",
              "        ...,\n",
              "        list([3, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0]),\n",
              "        list([3, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1]),\n",
              "        list([3, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0])],\n",
              "       dtype=object),\n",
              " array([list([301, 37, 55, 19, 11, 5, 17, 17, 16, 16, 17, 22, 23, 21, 24, 22, 21, 20, 18, 17, 29, 20, 19, 21, 22, 16, 20, 22, 22, 23, 20, 15, 20, 20, 22, 19, 17, 20, 17, 21, 17, 0, 0, 14, 0, 0]),\n",
              "        list([301, 26, 29, 26, 18, 0, 0, 33, 0, 0, 21, 0, 0, 22, 0, 0, 15, 32, 23, 27, 14, 17, 7, 0, 0, 0, 6, 0, 0, 0]),\n",
              "        list([301, 28, 17, 24, 20, 16, 16, 19, 18, 18, 20, 13, 13, 16, 15, 16, 17, 19, 20]),\n",
              "        ...,\n",
              "        list([301, 19, 28, 25, 13, 0, 0, 22, 0, 0, 12, 0, 0, 2, 0, 0, 1, 44, 13, 68, 25, 48, 21, 0, 0, 0, 36, 0, 0, 0, 60, 88, 18, 34, 10, 13, 19, 5, 11, 9]),\n",
              "        list([301, 27, 20, 13, 16, 0, 0, 47, 0, 0, 19, 0, 0, 14, 0, 0, 19, 26, 15, 18, 17, 30, 16, 0, 0, 0, 24, 0, 0, 0]),\n",
              "        list([301, 18, 18, 20, 17, 0, 0, 22, 0, 0, 17, 0, 0, 15, 0, 0, 24, 25, 21, 9, 7, 10, 11, 0, 0, 0, 26, 0, 0, 0])],\n",
              "       dtype=object),\n",
              " array([list([679, 55, 59, 11, 5, 17, 17, 16, 16, 17, 22, 23, 21, 24, 22, 21, 20, 18, 17, 29, 20, 18, 22, 21, 16, 21, 22, 22, 23, 20, 15, 20, 369, 31, 29, 35, 37, 54, 51, 662, 108, 678, 678, 116, 678, 678]),\n",
              "        list([679, 31, 27, 20, 104, 678, 678, 67, 678, 678, 70, 678, 678, 50, 678, 678, 34, 24, 28, 15, 19, 8, 29, 678, 678, 678, 15, 678, 678, 678]),\n",
              "        list([679, 20, 25, 21, 18, 18, 21, 98, 47, 43, 27, 25, 42, 244, 28, 29, 25, 36, 33]),\n",
              "        ...,\n",
              "        list([679, 30, 25, 14, 67, 678, 678, 38, 678, 678, 6, 678, 678, 3, 678, 678, 45, 14, 69, 26, 49, 22, 146, 678, 678, 678, 243, 678, 678, 678, 671, 28, 39, 15, 22, 27, 10, 15, 14, 22]),\n",
              "        list([679, 22, 14, 17, 142, 678, 678, 56, 678, 678, 42, 678, 678, 58, 678, 678, 27, 16, 19, 18, 31, 17, 95, 678, 678, 678, 139, 678, 678, 678]),\n",
              "        list([679, 19, 21, 17, 66, 678, 678, 52, 678, 678, 45, 678, 678, 74, 678, 678, 26, 22, 9, 7, 10, 12, 103, 678, 678, 678, 177, 678, 678, 678])],\n",
              "       dtype=object),\n",
              " array([list([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
              "        list([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
              "        list([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0]),\n",
              "        ...,\n",
              "        list([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
              "        list([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
              "        list([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])],\n",
              "       dtype=object),\n",
              " array([list([5, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 3, 3, 4, 4, 4]),\n",
              "        list([1, 1, 1, 2, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 7]),\n",
              "        list([5, 2, 5, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]),\n",
              "        ...,\n",
              "        list([1, 1, 1, 2, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]),\n",
              "        list([1, 1, 1, 2, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 7]),\n",
              "        list([1, 1, 1, 2, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 7])],\n",
              "       dtype=object),\n",
              " array([list([3, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, False, False, False, False, False, False, False]),\n",
              "        list([3, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False]),\n",
              "        list([3, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True]),\n",
              "        ...,\n",
              "        list([3, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True]),\n",
              "        list([3, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False]),\n",
              "        list([3, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False])],\n",
              "       dtype=object)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_uGV6iLARz1"
      },
      "source": [
        "def create_train_dataset(N_training_per_epoch, probs_train):\n",
        "  index = np.random.choice(train_len, N_training_per_epoch, replace=True, p = probs_train) # random indexing (similar to shuffling)\n",
        "  tr_list = [features[index] for features in train_list] # Selecting by index \n",
        "  train_ds = (tf.data.Dataset\n",
        "                  .from_generator(lambda: iter(zip(*tr_list)), output_types=OUTPUT_TYPES)\n",
        "                  .map(select_window_size)\n",
        "                  .padded_batch(batch_size = BATCH_SIZE, padded_shapes = PADDED_SHAPES, padding_values = PADDING_VALUES)\n",
        "                  .prefetch(AUTO)\n",
        "  )\n",
        "  return train_ds"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MyI8fDf7Ik4A"
      },
      "source": [
        "def create_val_dataset(N_valid_per_epoch, probs_val):\n",
        "  index = np.random.choice(val_len, N_valid_per_epoch, replace=True, p = probs_val) # random indexing (similar to shuffling)\n",
        "  vl_list = [features[index] for features in val_list] # Selecting by index \n",
        "  val_ds = (tf.data.Dataset\n",
        "                  .from_generator(lambda: iter(zip(*vl_list)), output_types=OUTPUT_TYPES)\n",
        "                  .map(select_window_size)\n",
        "                  .padded_batch(batch_size = BATCH_SIZE, padded_shapes = PADDED_SHAPES, padding_values = PADDING_VALUES)\n",
        "                  .cache()\n",
        "                  .prefetch(AUTO)\n",
        "  )\n",
        "  return val_ds"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDJudy20sEdg"
      },
      "source": [
        "val_dataset = create_val_dataset(N_SELECT_PER_EPOCH, PROBS_VAL)\r\n",
        "a = iter(val_dataset) # Small check"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMsYgAgVJhxq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d9bac5c-a1f7-421b-a71f-ff4f80b1419f"
      },
      "source": [
        "next(a)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(128, 100), dtype=int32, numpy=\n",
              " array([[ 1252,   322,  1725, ...,  3507,  3509,  3508],\n",
              "        [10001,  5616,  6154, ...,  4105,  5563,  6076],\n",
              "        [ 6630,  6720,  6717, ...,  2240,  2241,  2218],\n",
              "        ...,\n",
              "        [  930,   533,  1146, ...,   647,   585,   835],\n",
              "        [ 9165,  4978,  4240, ...,  9365,  6016,  4481],\n",
              "        [ 8249,   249,  6099, ..., 13523, 13523, 13523]], dtype=int32)>,\n",
              " <tf.Tensor: shape=(128, 101), dtype=int32, numpy=\n",
              " array([[1, 1, 1, ..., 1, 1, 2],\n",
              "        [1, 1, 1, ..., 1, 1, 2],\n",
              "        [1, 0, 1, ..., 0, 0, 2],\n",
              "        ...,\n",
              "        [1, 1, 1, ..., 0, 1, 2],\n",
              "        [1, 1, 1, ..., 1, 1, 2],\n",
              "        [3, 0, 1, ..., 2, 2, 2]], dtype=int32)>,\n",
              " <tf.Tensor: shape=(128, 100), dtype=int32, numpy=\n",
              " array([[ 17,  15,  19, ...,  30,   0,   0],\n",
              "        [  7,  30,  25, ...,   8,  22, 294],\n",
              "        [  0,  31,   0, ...,   0,   0,   4],\n",
              "        ...,\n",
              "        [ 21,  25,  17, ...,  27,  23,  18],\n",
              "        [ 25,   8,  19, ...,  12,  13,  20],\n",
              "        [301,  53,  18, ..., 302, 302, 302]], dtype=int32)>,\n",
              " <tf.Tensor: shape=(128, 100), dtype=int32, numpy=\n",
              " array([[ 21,  24, 325, ...,  82, 678, 678],\n",
              "        [ 33,  28,  22, ..., 149, 396,  62],\n",
              "        [678, 220, 678, ..., 678, 678,  88],\n",
              "        ...,\n",
              "        [ 45,  38,  37, ...,  73,  56,  73],\n",
              "        [ 13,  24,  20, ...,  27,  34,  31],\n",
              "        [679,  44,   8, ..., 680, 680, 680]], dtype=int32)>,\n",
              " <tf.Tensor: shape=(128, 100), dtype=int32, numpy=\n",
              " array([[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 1, 1, 1],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 8, 8, 8]], dtype=int32)>,\n",
              " <tf.Tensor: shape=(128, 100), dtype=int32, numpy=\n",
              " array([[2, 2, 3, ..., 4, 4, 4],\n",
              "        [5, 5, 5, ..., 5, 5, 5],\n",
              "        [6, 6, 6, ..., 3, 3, 3],\n",
              "        ...,\n",
              "        [2, 2, 2, ..., 2, 2, 2],\n",
              "        [5, 5, 5, ..., 5, 5, 5],\n",
              "        [5, 2, 5, ..., 0, 0, 0]], dtype=int32)>,\n",
              " <tf.Tensor: shape=(128, 100), dtype=int32, numpy=\n",
              " array([[1, 1, 1, ..., 1, 1, 1],\n",
              "        [1, 1, 1, ..., 1, 1, 1],\n",
              "        [1, 1, 1, ..., 1, 1, 1],\n",
              "        ...,\n",
              "        [1, 1, 1, ..., 1, 1, 1],\n",
              "        [1, 1, 1, ..., 1, 1, 1],\n",
              "        [3, 0, 0, ..., 2, 2, 2]], dtype=int32)>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yz9Fk6sp6sgP"
      },
      "source": [
        "## Get model and set hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "feqp6ENL6sgT"
      },
      "source": [
        "%run $MODEL_FILE"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEQBB9KthwmS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5480fc65-5b9d-4f72-e2da-0a78d5ecce58"
      },
      "source": [
        "shutil.copy('/content/drive/My Drive/Colab Notebooks/demo-riiid-transformer.ipynb', OUTPUT_FOLDER)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'31-Dec-riiid-3/demo-riiid-transformer.ipynb'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9IBAuXw6sgY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ef16de2-7cae-4a39-a719-bb12f8daa7cc"
      },
      "source": [
        "# Hyperparameters main model\n",
        "config = {\"features\": selections, \"n_features\": len(selections), \"vocab_sizes\": vocab_sizes, \n",
        "          \"enc_emb\": ENC_EMB, \"enc_dense\": ENC_DENSE, \"dec_emb\": DEC_EMB, \"dec_dense\": DEC_DENSE, \n",
        "          \"window_size\": THR_E, \"enc_num_layers\": 2, \"dec_num_layers\": 2, \"d_model\": 256, \n",
        "          \"dff\": 512, \"num_heads\": 8, \"dropout_rate\": 0.1, \"pos_encoding\": True,\n",
        "          \"padding_values\": PADDING_VALUES, \"output_types\": OUTPUT_TYPES, \"padded_shapes\": PADDED_SHAPES, \n",
        "          \"quantile_transformer_et\": quantile_transformer_et,  \"quantile_transformer_lt\": quantile_transformer_lt, \"ltg_bins\": ltg_bins, \"zero_task_etc\": ZERO_TASK_ETC,\n",
        "          \"n_bins\": n_bins}\n",
        "\n",
        "with open(os.path.join(OUTPUT_FOLDER, \"config.pickle\"), 'wb') as handle:\n",
        "  pickle.dump(config, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "logging.info('config: %s', config)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "31-12 11:52 root         INFO     config: {'features': ['E', 'r', 'etc', 'ltg', 'at', 'p', 'ex'], 'n_features': 7, 'vocab_sizes': [13524, 4, 303, 681, 9, 8, 4], 'enc_emb': [0, 4, 5], 'enc_dense': [], 'dec_emb': [1, 2, 3, 6], 'dec_dense': [], 'window_size': 100, 'enc_num_layers': 2, 'dec_num_layers': 2, 'd_model': 256, 'dff': 512, 'num_heads': 8, 'dropout_rate': 0.1, 'pos_encoding': True, 'padding_values': (13523, 2, 302, 680, 8, 0, 2), 'output_types': (tf.int32, tf.int32, tf.int32, tf.int32, tf.int32, tf.int32, tf.int32), 'padded_shapes': ([100], [101], [100], [100], [100], [100], [100]), 'quantile_transformer_et': [], 'quantile_transformer_lt': [], 'ltg_bins': array([0.00000000e+00, 2.00000000e+00, 3.00000000e+00, 4.00000000e+00,\n",
            "       5.00000000e+00, 6.00000000e+00, 7.00000000e+00, 8.00000000e+00,\n",
            "       9.00000000e+00, 1.00000000e+01, 1.10000000e+01, 1.20000000e+01,\n",
            "       1.30000000e+01, 1.40000000e+01, 1.50000000e+01, 1.60000000e+01,\n",
            "       1.70000000e+01, 1.80000000e+01, 1.90000000e+01, 2.00000000e+01,\n",
            "       2.10000000e+01, 2.20000000e+01, 2.30000000e+01, 2.40000000e+01,\n",
            "       2.50000000e+01, 2.60000000e+01, 2.70000000e+01, 2.80000000e+01,\n",
            "       2.90000000e+01, 3.00000000e+01, 3.10000000e+01, 3.20000000e+01,\n",
            "       3.30000000e+01, 3.40000000e+01, 3.50000000e+01, 3.60000000e+01,\n",
            "       3.70000000e+01, 3.80000000e+01, 3.90000000e+01, 4.00000000e+01,\n",
            "       4.10000000e+01, 4.20000000e+01, 4.30000000e+01, 4.40000000e+01,\n",
            "       4.50000000e+01, 4.60000000e+01, 4.70000000e+01, 4.80000000e+01,\n",
            "       4.90000000e+01, 5.00000000e+01, 5.10000000e+01, 5.20000000e+01,\n",
            "       5.30000000e+01, 5.40000000e+01, 5.50000000e+01, 5.60000000e+01,\n",
            "       5.70000000e+01, 5.80000000e+01, 5.90000000e+01, 6.00000000e+01,\n",
            "       6.10000000e+01, 6.20000000e+01, 6.30000000e+01, 6.40000000e+01,\n",
            "       6.50000000e+01, 6.60000000e+01, 6.70000000e+01, 6.80000000e+01,\n",
            "       6.90000000e+01, 7.00000000e+01, 7.10000000e+01, 7.20000000e+01,\n",
            "       7.30000000e+01, 7.40000000e+01, 7.50000000e+01, 7.60000000e+01,\n",
            "       7.70000000e+01, 7.80000000e+01, 7.90000000e+01, 8.00000000e+01,\n",
            "       8.10000000e+01, 8.20000000e+01, 8.30000000e+01, 8.40000000e+01,\n",
            "       8.50000000e+01, 8.60000000e+01, 8.70000000e+01, 8.80000000e+01,\n",
            "       8.90000000e+01, 9.00000000e+01, 9.10000000e+01, 9.20000000e+01,\n",
            "       9.30000000e+01, 9.40000000e+01, 9.50000000e+01, 9.60000000e+01,\n",
            "       9.70000000e+01, 9.80000000e+01, 9.90000000e+01, 1.00000000e+02,\n",
            "       1.01000000e+02, 1.02000000e+02, 1.03000000e+02, 1.04000000e+02,\n",
            "       1.05000000e+02, 1.06000000e+02, 1.07000000e+02, 1.08000000e+02,\n",
            "       1.09000000e+02, 1.10000000e+02, 1.11000000e+02, 1.12000000e+02,\n",
            "       1.13000000e+02, 1.14000000e+02, 1.15000000e+02, 1.16000000e+02,\n",
            "       1.17000000e+02, 1.18000000e+02, 1.19000000e+02, 1.20000000e+02,\n",
            "       1.21000000e+02, 1.22000000e+02, 1.23000000e+02, 1.24000000e+02,\n",
            "       1.25000000e+02, 1.26000000e+02, 1.27000000e+02, 1.28000000e+02,\n",
            "       1.29000000e+02, 1.30000000e+02, 1.31000000e+02, 1.32000000e+02,\n",
            "       1.33000000e+02, 1.34000000e+02, 1.35000000e+02, 1.36000000e+02,\n",
            "       1.37000000e+02, 1.38000000e+02, 1.39000000e+02, 1.40000000e+02,\n",
            "       1.41000000e+02, 1.42000000e+02, 1.43000000e+02, 1.44000000e+02,\n",
            "       1.45000000e+02, 1.46000000e+02, 1.47000000e+02, 1.48000000e+02,\n",
            "       1.49000000e+02, 1.50000000e+02, 1.51000000e+02, 1.52000000e+02,\n",
            "       1.53000000e+02, 1.54000000e+02, 1.55000000e+02, 1.56000000e+02,\n",
            "       1.57000000e+02, 1.58000000e+02, 1.59000000e+02, 1.60000000e+02,\n",
            "       1.61000000e+02, 1.62000000e+02, 1.63000000e+02, 1.64000000e+02,\n",
            "       1.65000000e+02, 1.66000000e+02, 1.67000000e+02, 1.68000000e+02,\n",
            "       1.69000000e+02, 1.70000000e+02, 1.71000000e+02, 1.72000000e+02,\n",
            "       1.73000000e+02, 1.74000000e+02, 1.75000000e+02, 1.76000000e+02,\n",
            "       1.77000000e+02, 1.78000000e+02, 1.79000000e+02, 1.80000000e+02,\n",
            "       1.81000000e+02, 1.82000000e+02, 1.83000000e+02, 1.84000000e+02,\n",
            "       1.85000000e+02, 1.86000000e+02, 1.87000000e+02, 1.88000000e+02,\n",
            "       1.89000000e+02, 1.90000000e+02, 1.91000000e+02, 1.92000000e+02,\n",
            "       1.93000000e+02, 1.94000000e+02, 1.95000000e+02, 1.96000000e+02,\n",
            "       1.97000000e+02, 1.98000000e+02, 1.99000000e+02, 2.00000000e+02,\n",
            "       2.01000000e+02, 2.02000000e+02, 2.03000000e+02, 2.04000000e+02,\n",
            "       2.05000000e+02, 2.06000000e+02, 2.07000000e+02, 2.08000000e+02,\n",
            "       2.09000000e+02, 2.10000000e+02, 2.11000000e+02, 2.12000000e+02,\n",
            "       2.13000000e+02, 2.14000000e+02, 2.15000000e+02, 2.16000000e+02,\n",
            "       2.17000000e+02, 2.18000000e+02, 2.19000000e+02, 2.20000000e+02,\n",
            "       2.21000000e+02, 2.22000000e+02, 2.23000000e+02, 2.24000000e+02,\n",
            "       2.25000000e+02, 2.26000000e+02, 2.27000000e+02, 2.28000000e+02,\n",
            "       2.29000000e+02, 2.30000000e+02, 2.31000000e+02, 2.32000000e+02,\n",
            "       2.33000000e+02, 2.34000000e+02, 2.35000000e+02, 2.36000000e+02,\n",
            "       2.37000000e+02, 2.38000000e+02, 2.39000000e+02, 2.40000000e+02,\n",
            "       2.41000000e+02, 2.42000000e+02, 2.43000000e+02, 2.44000000e+02,\n",
            "       2.45000000e+02, 2.46000000e+02, 2.47000000e+02, 2.48000000e+02,\n",
            "       2.49000000e+02, 2.50000000e+02, 2.51000000e+02, 2.52000000e+02,\n",
            "       2.53000000e+02, 2.54000000e+02, 2.55000000e+02, 2.56000000e+02,\n",
            "       2.57000000e+02, 2.58000000e+02, 2.59000000e+02, 2.60000000e+02,\n",
            "       2.61000000e+02, 2.62000000e+02, 2.63000000e+02, 2.64000000e+02,\n",
            "       2.65000000e+02, 2.67000000e+02, 2.68000000e+02, 2.69000000e+02,\n",
            "       2.70000000e+02, 2.71000000e+02, 2.72000000e+02, 2.73000000e+02,\n",
            "       2.75000000e+02, 2.76000000e+02, 2.77000000e+02, 2.78000000e+02,\n",
            "       2.79000000e+02, 2.81000000e+02, 2.82000000e+02, 2.83000000e+02,\n",
            "       2.84000000e+02, 2.86000000e+02, 2.87000000e+02, 2.88000000e+02,\n",
            "       2.90000000e+02, 2.91000000e+02, 2.92000000e+02, 2.94000000e+02,\n",
            "       2.95000000e+02, 2.96000000e+02, 2.98000000e+02, 2.99000000e+02,\n",
            "       3.01000000e+02, 3.02000000e+02, 3.03000000e+02, 3.05000000e+02,\n",
            "       3.06000000e+02, 3.08000000e+02, 3.09000000e+02, 3.11000000e+02,\n",
            "       3.13000000e+02, 3.14000000e+02, 3.16000000e+02, 3.17000000e+02,\n",
            "       3.19000000e+02, 3.21000000e+02, 3.22000000e+02, 3.24000000e+02,\n",
            "       3.26000000e+02, 3.27000000e+02, 3.29000000e+02, 3.31000000e+02,\n",
            "       3.32000000e+02, 3.34000000e+02, 3.36000000e+02, 3.38000000e+02,\n",
            "       3.40000000e+02, 3.42000000e+02, 3.43000000e+02, 3.45000000e+02,\n",
            "       3.47000000e+02, 3.49000000e+02, 3.51000000e+02, 3.53000000e+02,\n",
            "       3.55000000e+02, 3.57000000e+02, 3.60000000e+02, 3.62000000e+02,\n",
            "       3.64000000e+02, 3.66000000e+02, 3.68000000e+02, 3.70000000e+02,\n",
            "       3.73000000e+02, 3.75000000e+02, 3.77000000e+02, 3.80000000e+02,\n",
            "       3.82000000e+02, 3.84000000e+02, 3.87000000e+02, 3.89000000e+02,\n",
            "       3.92000000e+02, 3.94000000e+02, 3.97000000e+02, 4.00000000e+02,\n",
            "       4.02000000e+02, 4.05000000e+02, 4.08000000e+02, 4.11000000e+02,\n",
            "       4.14000000e+02, 4.17000000e+02, 4.19000000e+02, 4.22000000e+02,\n",
            "       4.25000000e+02, 4.29000000e+02, 4.32000000e+02, 4.35000000e+02,\n",
            "       4.38000000e+02, 4.41000000e+02, 4.45000000e+02, 4.48000000e+02,\n",
            "       4.52000000e+02, 4.55000000e+02, 4.59000000e+02, 4.62000000e+02,\n",
            "       4.66000000e+02, 4.70000000e+02, 4.74000000e+02, 4.78000000e+02,\n",
            "       4.82000000e+02, 4.86000000e+02, 4.90000000e+02, 4.94000000e+02,\n",
            "       4.98000000e+02, 5.03000000e+02, 5.07000000e+02, 5.12000000e+02,\n",
            "       5.16000000e+02, 5.21000000e+02, 5.26000000e+02, 5.31000000e+02,\n",
            "       5.36000000e+02, 5.41000000e+02, 5.46000000e+02, 5.52000000e+02,\n",
            "       5.57000000e+02, 5.63000000e+02, 5.69000000e+02, 5.75000000e+02,\n",
            "       5.81000000e+02, 5.87000000e+02, 5.93000000e+02, 6.00000000e+02,\n",
            "       6.06000000e+02, 6.13000000e+02, 6.20000000e+02, 6.27000000e+02,\n",
            "       6.35000000e+02, 6.42000000e+02, 6.50000000e+02, 6.57000000e+02,\n",
            "       6.66000000e+02, 6.74000000e+02, 6.82000000e+02, 6.91000000e+02,\n",
            "       7.00000000e+02, 7.09000000e+02, 7.19000000e+02, 7.28000000e+02,\n",
            "       7.38000000e+02, 7.49000000e+02, 7.59000000e+02, 7.70000000e+02,\n",
            "       7.81000000e+02, 7.93000000e+02, 8.04000000e+02, 8.17000000e+02,\n",
            "       8.29000000e+02, 8.42000000e+02, 8.55000000e+02, 8.69000000e+02,\n",
            "       8.83000000e+02, 8.97000000e+02, 9.12000000e+02, 9.28000000e+02,\n",
            "       9.44000000e+02, 9.60000000e+02, 9.77000000e+02, 9.95000000e+02,\n",
            "       1.01300000e+03, 1.03200000e+03, 1.05100000e+03, 1.07100000e+03,\n",
            "       1.09100000e+03, 1.11300000e+03, 1.13500000e+03, 1.15800000e+03,\n",
            "       1.18100000e+03, 1.20600000e+03, 1.23200000e+03, 1.25800000e+03,\n",
            "       1.28500000e+03, 1.31300000e+03, 1.34200000e+03, 1.37300000e+03,\n",
            "       1.40400000e+03, 1.43600000e+03, 1.47000000e+03, 1.50552750e+03,\n",
            "       1.54200000e+03, 1.58000000e+03, 1.61900000e+03, 1.66000000e+03,\n",
            "       1.70300000e+03, 1.74700000e+03, 1.79400000e+03, 1.84100000e+03,\n",
            "       1.89100000e+03, 1.94200000e+03, 1.99600000e+03, 2.05200000e+03,\n",
            "       2.11000000e+03, 2.17000000e+03, 2.23300000e+03, 2.29900000e+03,\n",
            "       2.36700000e+03, 2.43700000e+03, 2.51200000e+03, 2.58800000e+03,\n",
            "       2.66800000e+03, 2.75100000e+03, 2.83700000e+03, 2.92700000e+03,\n",
            "       3.01900000e+03, 3.11600000e+03, 3.21500000e+03, 3.32000000e+03,\n",
            "       3.42800000e+03, 3.53900000e+03, 3.65600000e+03, 3.77600000e+03,\n",
            "       3.90100000e+03, 4.03100000e+03, 4.16600000e+03, 4.30700000e+03,\n",
            "       4.45400000e+03, 4.60500000e+03, 4.76200000e+03, 4.92400000e+03,\n",
            "       5.09400000e+03, 5.26800000e+03, 5.44800000e+03, 5.63500000e+03,\n",
            "       5.82900000e+03, 6.03100000e+03, 6.23900000e+03, 6.45300000e+03,\n",
            "       6.67500000e+03, 6.90500000e+03, 7.14200000e+03, 7.38700000e+03,\n",
            "       7.63900000e+03, 7.89900000e+03, 8.17000000e+03, 8.44952950e+03,\n",
            "       8.73900000e+03, 9.03700000e+03, 9.34976175e+03, 9.67100000e+03,\n",
            "       1.00040000e+04, 1.03530000e+04, 1.07150000e+04, 1.10830000e+04,\n",
            "       1.14700000e+04, 1.18670000e+04, 1.22800000e+04, 1.27010000e+04,\n",
            "       1.31350000e+04, 1.35800000e+04, 1.40330000e+04, 1.45000000e+04,\n",
            "       1.49720000e+04, 1.54550000e+04, 1.59510000e+04, 1.64660000e+04,\n",
            "       1.69830000e+04, 1.75110000e+04, 1.80390000e+04, 1.85920000e+04,\n",
            "       1.91690000e+04, 1.97580000e+04, 2.03770000e+04, 2.10170000e+04,\n",
            "       2.16690000e+04, 2.23480000e+04, 2.30390000e+04, 2.37450000e+04,\n",
            "       2.44420000e+04, 2.51710000e+04, 2.59120000e+04, 2.66530000e+04,\n",
            "       2.74060000e+04, 2.81650000e+04, 2.89240000e+04, 2.96960000e+04,\n",
            "       3.04600000e+04, 3.12300000e+04, 3.19960000e+04, 3.27690000e+04,\n",
            "       3.35320000e+04, 3.42920000e+04, 3.50510000e+04, 3.58090000e+04,\n",
            "       3.65736562e+04, 3.73370000e+04, 3.80960000e+04, 3.88640000e+04,\n",
            "       3.96240000e+04, 4.03800000e+04, 4.11210000e+04, 4.18245315e+04,\n",
            "       4.24750000e+04, 4.30340000e+04, 4.36590000e+04, 4.44490000e+04,\n",
            "       4.53220000e+04, 4.62390000e+04, 4.71900000e+04, 4.81590000e+04,\n",
            "       4.91590000e+04, 5.01930000e+04, 5.12600000e+04, 5.23670000e+04,\n",
            "       5.35070000e+04, 5.46620000e+04, 5.58510000e+04, 5.70470000e+04,\n",
            "       5.82620000e+04, 5.95090000e+04, 6.07460000e+04, 6.19830000e+04,\n",
            "       6.32270000e+04, 6.44640000e+04, 6.56830000e+04, 6.69140000e+04,\n",
            "       6.81080000e+04, 6.92862110e+04, 7.04660000e+04, 7.16370000e+04,\n",
            "       7.27820000e+04, 7.39170000e+04, 7.50240000e+04, 7.60770000e+04,\n",
            "       7.70880000e+04, 7.80530000e+04, 7.89730000e+04, 7.98510000e+04,\n",
            "       8.06740000e+04, 8.14450000e+04, 8.21650000e+04, 8.28340000e+04,\n",
            "       8.34530000e+04, 8.40290000e+04, 8.45530000e+04, 8.50160000e+04,\n",
            "       8.54310000e+04, 8.58110000e+04, 8.61880000e+04, 8.66470000e+04,\n",
            "       8.72520000e+04, 8.79760000e+04, 8.88170000e+04, 8.97790000e+04,\n",
            "       9.08650000e+04, 9.21240000e+04, 9.35500000e+04, 9.51890000e+04,\n",
            "       9.70160000e+04, 9.90910000e+04, 1.01394000e+05, 1.03927177e+05,\n",
            "       1.06743000e+05, 1.09872000e+05, 1.13236000e+05, 1.16839000e+05,\n",
            "       1.20583230e+05, 1.24351641e+05, 1.28089000e+05, 1.31473000e+05,\n",
            "       1.35804873e+05, 1.40659000e+05, 1.46009000e+05, 1.51386000e+05,\n",
            "       1.56500000e+05, 1.61245000e+05, 1.65384338e+05, 1.68881000e+05,\n",
            "       1.71582000e+05, 1.73794000e+05, 1.77656000e+05, 1.83263000e+05,\n",
            "       1.91037802e+05, 2.00715213e+05, 2.11258000e+05, 2.20887035e+05,\n",
            "       2.32777000e+05, 2.44140000e+05, 2.53205000e+05, 2.58621000e+05,\n",
            "       2.65363176e+05, 2.79177998e+05, 2.98121000e+05, 3.16673321e+05,\n",
            "       3.35656731e+05, 3.46015142e+05, 3.63709105e+05, 3.93204000e+05,\n",
            "       4.22820374e+05, 4.39883785e+05, 4.78831783e+05, 5.15728000e+05,\n",
            "       5.52501069e+05, 6.01715000e+05, 6.51781677e+05, 7.15807743e+05,\n",
            "       7.99764660e+05, 9.03471355e+05, 1.02596185e+06, 1.16173171e+06,\n",
            "       1.33369761e+06, 1.57748370e+06, 1.89953762e+06, 2.34824228e+06,\n",
            "       2.99556873e+06, 3.99615435e+06, 5.63316470e+06, 8.59478303e+06,\n",
            "       1.45834597e+07, 8.38842610e+07]), 'zero_task_etc': True, 'n_bins': []}\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usZkCk1yVYo5"
      },
      "source": [
        ""
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gIEWr8V6sgf"
      },
      "source": [
        "transformer = create_model_separate_input(config)\n",
        "# tf.keras.utils.plot_model(transformer, os.path.join(OUTPUT_FOLDER, \"model_plot.png\"), show_shapes=True)"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DiW6F6Rv66fx"
      },
      "source": [
        "## Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWAf5VTW66fz"
      },
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "  def __init__(self, d_model, warmup_steps=4000):\n",
        "    super(CustomSchedule, self).__init__()\n",
        "    \n",
        "    self.d_model = d_model\n",
        "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "    self.warmup_steps = warmup_steps\n",
        "  def __call__(self, step):\n",
        "    arg1 = tf.math.rsqrt(step)\n",
        "    arg2 = step * (self.warmup_steps ** -1.5)\n",
        "    \n",
        "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYjhA2aa66f2"
      },
      "source": [
        "learning_rate = CustomSchedule(config[\"d_model\"])\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.999, \n",
        "                                      epsilon=1e-9)"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVVIhusN66f5"
      },
      "source": [
        "## Loss and metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdEZ2qRz66f6"
      },
      "source": [
        "Since the target sequences are padded, it is important to apply a padding mask when calculating the loss."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNgoEGX666f6"
      },
      "source": [
        "# Loss and metric\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "accuracy_object = tf.keras.metrics.sparse_categorical_accuracy\n",
        "\n",
        "train_auc= tf.keras.metrics.AUC()\n",
        "val_auc= tf.keras.metrics.AUC()"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_Bm57bt66f9"
      },
      "source": [
        "def loss_function(real, pred): # batch_size x seq_size x 1 vs  batch_size x seq_size x 3\n",
        "    mask = tf.math.logical_not(tf.math.equal(tf.squeeze(real), N_response)) # batch_size x seq_size\n",
        "    loss_ = loss_object(real, pred) # batch_size x seq_size\n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "    \n",
        "    loss_ *= mask \n",
        "    loss_ = tf.reduce_sum(loss_)/tf.reduce_sum(mask) #loss becomes one value! (from all batches)\n",
        "    return loss_"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahEaU3kN66f_"
      },
      "source": [
        "def metric_function(real, pred, auc_object): # batch_size x seq_size x 1 vs  batch_size x seq_size x 3\n",
        "    # Predict accuracy\n",
        "    mask = tf.math.logical_not(tf.math.equal(tf.squeeze(real), N_response)) # batch_size x seq_size\n",
        "    accuracy = accuracy_object(real, pred) # batch_size x seq_size\n",
        "    mask = tf.cast(mask, dtype=accuracy.dtype)\n",
        "    \n",
        "    accuracy *= mask\n",
        "    accuracy = 100*tf.reduce_sum(accuracy)/tf.reduce_sum(mask)\n",
        "    \n",
        "    # A work-around to predict AUC => is it stable?\n",
        "    pred = tf.nn.softmax(pred)\n",
        "    pred = pred[:,:,1] # pred that answer is correct\n",
        "    real = tf.keras.backend.flatten(real)\n",
        "    pred = tf.keras.backend.flatten(pred)\n",
        "    \n",
        "    idxs = tf.math.logical_not(tf.math.equal(real, N_response))\n",
        "    real = real[idxs]\n",
        "    pred = pred[idxs]\n",
        "    auc = auc_object(real, pred)\n",
        "    return accuracy"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cm9x2sLp66gC"
      },
      "source": [
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.Mean(name='train_accuracy')\n",
        "\n",
        "val_loss = tf.keras.metrics.Mean(name='val_loss')\n",
        "val_accuracy = tf.keras.metrics.Mean(name='val_accuracy')"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aeHumfr7zmMa"
      },
      "source": [
        "## Training and checkpointing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fzuf06YZp66w"
      },
      "source": [
        "Create the checkpoint path and the checkpoint manager. This will be used to save checkpoints every `n` epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNhuYfllndLZ"
      },
      "source": [
        "checkpoint_path = os.path.join(OUTPUT_FOLDER, \"checkpoints/\")\n",
        "ckpt = tf.train.Checkpoint(transformer=transformer,\n",
        "                           optimizer=optimizer)\n",
        "\n",
        "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=1)\n",
        "\n",
        "# https://stackoverflow.com/questions/62919208/how-to-restore-a-specific-checkpoint-in-tensorflow2-to-implement-early-stopping\n",
        "\n",
        "# # if a checkpoint exists, restore the latest checkpoint.\n",
        "# if ckpt_manager.latest_checkpoint:\n",
        "#   ckpt.restore(ckpt_manager.latest_checkpoint)\n",
        "#   print ('Latest checkpoint restored!!')"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxjpegZH_311"
      },
      "source": [
        "# train_step_signature = [\r\n",
        "#     tf.TensorSpec(shape=(None, THR_E), dtype=tf.int32),\r\n",
        "#     tf.TensorSpec(shape=(None, THR_E), dtype=tf.int32),\r\n",
        "#     tf.TensorSpec(shape=(None, THR_E), dtype=tf.int32),\r\n",
        "#     tf.TensorSpec(shape=(None, THR_E), dtype=tf.int32),\r\n",
        "#     tf.TensorSpec(shape=(None, THR_E), dtype=tf.int32),\r\n",
        "#     tf.TensorSpec(shape=(None, THR_E), dtype=tf.int32),\r\n",
        "#     tf.TensorSpec(shape=(None, THR_E), dtype=tf.int32),\r\n",
        "# ]"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nsLZJ6FznKF"
      },
      "source": [
        "@tf.function()\n",
        "def train_step(tar_real, *inputs):\n",
        "    \n",
        "    with tf.GradientTape() as tape: \n",
        "        predictions = transformer(inputs, training=True)\n",
        "        tar_real = tf.expand_dims(tar_real, -1) # IMPORTANT! DOESN'T WORK WITHOUT IT. ALWAYS GIVES ERROR INCOMPATIBLE SHAPE. E.G. (32,169) vs. (32,169,3)\n",
        "        \n",
        "        loss = loss_function(tar_real, predictions)\n",
        "        accuracy = metric_function(tar_real, predictions, auc_object = train_auc)\n",
        "    \n",
        "    gradients = tape.gradient(loss, transformer.trainable_variables)    \n",
        "    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
        "\n",
        "    train_loss(loss)\n",
        "    train_accuracy(accuracy)\n",
        "\n",
        "@tf.function()\n",
        "def val_step(tar_real, *inputs):\n",
        "    predictions = transformer(inputs, training=False)\n",
        "    tar_real = tf.expand_dims(tar_real, -1) # IMPORTANT! DOESN'T WORK WITHOUT IT. ALWAYS GIVES ERROR INCOMPATIBLE SHAPE. E.G. (32,169) vs. (32,169,3)\n",
        "    \n",
        "    loss = loss_function(tar_real, predictions)\n",
        "    accuracy = metric_function(tar_real, predictions, auc_object = val_auc)\n",
        "\n",
        "    val_loss(loss)\n",
        "    val_accuracy(accuracy)"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbvmaKNiznHZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62be7ded-1ca9-46c0-afda-6d66538ecebe"
      },
      "source": [
        "best_auc = 0\n",
        "for epoch in range(EPOCHS):\n",
        "    train_dataset = create_train_dataset(N_SELECT_PER_EPOCH, PROBS_TRAIN) # create train for each epoch\n",
        "    start = time.time()\n",
        "\n",
        "    train_loss.reset_states()\n",
        "    train_accuracy.reset_states()\n",
        "    train_auc.reset_states()\n",
        "    \n",
        "    val_loss.reset_states()\n",
        "    val_accuracy.reset_states()\n",
        "    val_auc.reset_states()\n",
        "\n",
        "    # Train\n",
        "    for (batch, (features)) in enumerate(train_dataset):\n",
        "        E, tar, rest = features[0], features[1], features[2:] \n",
        "        tar_inp = tar[:, :-1]\n",
        "        tar_real = tar[:, 1:]\n",
        "\n",
        "        inputs = [E, tar_inp] + list(rest)        \n",
        "        train_step(tar_real, inputs)\n",
        "        \n",
        "        if batch % PRINT_EVERY_N_BATCHES == 0:\n",
        "            print ('Epoch {} TRAIN Batch {} Loss {:.4f} Accuracy {:.4f} AUC {:.4f}'.format(\n",
        "              epoch + 1, batch, train_loss.result(), train_accuracy.result(), train_auc.result()))\n",
        "\n",
        "    logging.info('Epoch TRAIN {} Loss {:.4f} Accuracy {:.4f} AUC {:.4f}'.format(epoch + 1, \n",
        "                                                train_loss.result(), \n",
        "                                                train_accuracy.result(),\n",
        "                                                train_auc.result()\n",
        "                                                ))\n",
        "    \n",
        "    # Validate and save model\n",
        "    if (epoch + 1) % VAL_EVERY_N_EPOCHS == 0: \n",
        "      for (batch, (features)) in enumerate(val_dataset):\n",
        "          E, tar, rest = features[0], features[1], features[2:] \n",
        "          tar_inp = tar[:, :-1]\n",
        "          tar_real = tar[:, 1:]\n",
        "\n",
        "          inputs = [E, tar_inp] + list(rest)          \n",
        "          val_step(tar_real, inputs)\n",
        "\n",
        "          if batch % PRINT_EVERY_N_BATCHES == 0:\n",
        "              print ('Epoch {} VAL Batch {} Loss {:.4f} Accuracy {:.4f} AUC {:.4f}'.format(\n",
        "                epoch + 1, batch, val_loss.result(), val_accuracy.result(), val_auc.result()))\n",
        "      \n",
        "      logging.info('Epoch VAL {} Loss {:.4f} Accuracy {:.4f} AUC {:.4f}'.format(epoch + 1, \n",
        "                                          val_loss.result(), \n",
        "                                          val_accuracy.result(),\n",
        "                                          val_auc.result()\n",
        "                                          ))    \n",
        "       \n",
        "      if val_auc.result() > best_auc:\n",
        "          best_auc = val_auc.result()\n",
        "          ckpt_save_path = ckpt_manager.save()\n",
        "          logging.info('Saving checkpoint for epoch {} at {}'.format(epoch+1,\n",
        "                                                            ckpt_save_path))\n",
        "        \n",
        "    print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 TRAIN Batch 0 Loss 1.5221 Accuracy 17.0190 AUC 0.4985\n",
            "Epoch 1 TRAIN Batch 50 Loss 0.9485 Accuracy 50.5526 AUC 0.5038\n",
            "Epoch 1 TRAIN Batch 100 Loss 0.8259 Accuracy 56.0689 AUC 0.5037\n",
            "Epoch 1 TRAIN Batch 150 Loss 0.7767 Accuracy 58.4479 AUC 0.5049\n",
            "Epoch 1 TRAIN Batch 200 Loss 0.7484 Accuracy 59.9272 AUC 0.5063\n",
            "Epoch 1 TRAIN Batch 250 Loss 0.7295 Accuracy 60.9893 AUC 0.5078\n",
            "Epoch 1 TRAIN Batch 300 Loss 0.7156 Accuracy 61.8328 AUC 0.5096\n",
            "Epoch 1 TRAIN Batch 350 Loss 0.7048 Accuracy 62.5083 AUC 0.5119\n",
            "Epoch 1 TRAIN Batch 400 Loss 0.6963 Accuracy 63.0206 AUC 0.5154\n",
            "Epoch 1 TRAIN Batch 450 Loss 0.6891 Accuracy 63.4237 AUC 0.5201\n",
            "Epoch 1 TRAIN Batch 500 Loss 0.6829 Accuracy 63.7858 AUC 0.5257\n",
            "Epoch 1 TRAIN Batch 550 Loss 0.6776 Accuracy 64.0833 AUC 0.5311\n",
            "Epoch 1 TRAIN Batch 600 Loss 0.6729 Accuracy 64.3537 AUC 0.5365\n",
            "Epoch 1 TRAIN Batch 650 Loss 0.6688 Accuracy 64.5765 AUC 0.5417\n",
            "Epoch 1 TRAIN Batch 700 Loss 0.6652 Accuracy 64.7773 AUC 0.5465\n",
            "Epoch 1 TRAIN Batch 750 Loss 0.6618 Accuracy 64.9666 AUC 0.5511\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "31-12 11:55 root         INFO     Epoch TRAIN 1 Loss 0.6601 Accuracy 65.0604 AUC 0.5535\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time taken for 1 epoch: 210.32253122329712 secs\n",
            "\n",
            "Epoch 2 TRAIN Batch 0 Loss 0.6137 Accuracy 67.5559 AUC 0.6228\n",
            "Epoch 2 TRAIN Batch 50 Loss 0.6145 Accuracy 67.4872 AUC 0.6209\n",
            "Epoch 2 TRAIN Batch 100 Loss 0.6129 Accuracy 67.5833 AUC 0.6251\n",
            "Epoch 2 TRAIN Batch 150 Loss 0.6119 Accuracy 67.6615 AUC 0.6269\n",
            "Epoch 2 TRAIN Batch 200 Loss 0.6113 Accuracy 67.6970 AUC 0.6276\n",
            "Epoch 2 TRAIN Batch 250 Loss 0.6105 Accuracy 67.7266 AUC 0.6297\n",
            "Epoch 2 TRAIN Batch 300 Loss 0.6100 Accuracy 67.7169 AUC 0.6315\n",
            "Epoch 2 TRAIN Batch 350 Loss 0.6093 Accuracy 67.7393 AUC 0.6327\n",
            "Epoch 2 TRAIN Batch 400 Loss 0.6089 Accuracy 67.7464 AUC 0.6336\n",
            "Epoch 2 TRAIN Batch 450 Loss 0.6085 Accuracy 67.7594 AUC 0.6343\n",
            "Epoch 2 TRAIN Batch 500 Loss 0.6082 Accuracy 67.7626 AUC 0.6352\n",
            "Epoch 2 TRAIN Batch 550 Loss 0.6078 Accuracy 67.7641 AUC 0.6362\n",
            "Epoch 2 TRAIN Batch 600 Loss 0.6073 Accuracy 67.7865 AUC 0.6373\n",
            "Epoch 2 TRAIN Batch 650 Loss 0.6068 Accuracy 67.8159 AUC 0.6385\n",
            "Epoch 2 TRAIN Batch 700 Loss 0.6063 Accuracy 67.8311 AUC 0.6398\n",
            "Epoch 2 TRAIN Batch 750 Loss 0.6059 Accuracy 67.8455 AUC 0.6410\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "31-12 11:59 root         INFO     Epoch TRAIN 2 Loss 0.6055 Accuracy 67.8641 AUC 0.6420\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time taken for 1 epoch: 202.99348497390747 secs\n",
            "\n",
            "Epoch 3 TRAIN Batch 0 Loss 0.5956 Accuracy 67.7794 AUC 0.6865\n",
            "Epoch 3 TRAIN Batch 50 Loss 0.5741 Accuracy 70.1881 AUC 0.7074\n",
            "Epoch 3 TRAIN Batch 100 Loss 0.5652 Accuracy 70.8922 AUC 0.7200\n",
            "Epoch 3 TRAIN Batch 150 Loss 0.5587 Accuracy 71.3665 AUC 0.7295\n",
            "Epoch 3 TRAIN Batch 200 Loss 0.5544 Accuracy 71.6473 AUC 0.7356\n",
            "Epoch 3 TRAIN Batch 250 Loss 0.5517 Accuracy 71.8241 AUC 0.7398\n",
            "Epoch 3 TRAIN Batch 300 Loss 0.5494 Accuracy 71.9612 AUC 0.7428\n",
            "Epoch 3 TRAIN Batch 350 Loss 0.5477 Accuracy 72.0615 AUC 0.7453\n",
            "Epoch 3 TRAIN Batch 400 Loss 0.5460 Accuracy 72.1791 AUC 0.7473\n",
            "Epoch 3 TRAIN Batch 450 Loss 0.5444 Accuracy 72.2877 AUC 0.7491\n",
            "Epoch 3 TRAIN Batch 500 Loss 0.5432 Accuracy 72.3635 AUC 0.7507\n",
            "Epoch 3 TRAIN Batch 550 Loss 0.5426 Accuracy 72.3915 AUC 0.7516\n",
            "Epoch 3 TRAIN Batch 600 Loss 0.5418 Accuracy 72.4433 AUC 0.7526\n",
            "Epoch 3 TRAIN Batch 650 Loss 0.5413 Accuracy 72.4761 AUC 0.7533\n",
            "Epoch 3 TRAIN Batch 700 Loss 0.5405 Accuracy 72.5168 AUC 0.7541\n",
            "Epoch 3 TRAIN Batch 750 Loss 0.5400 Accuracy 72.5513 AUC 0.7548\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "31-12 12:02 root         INFO     Epoch TRAIN 3 Loss 0.5396 Accuracy 72.5777 AUC 0.7552\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time taken for 1 epoch: 201.78356504440308 secs\n",
            "\n",
            "Epoch 4 TRAIN Batch 0 Loss 0.5280 Accuracy 73.4982 AUC 0.7649\n",
            "Epoch 4 TRAIN Batch 50 Loss 0.5338 Accuracy 72.9084 AUC 0.7631\n",
            "Epoch 4 TRAIN Batch 100 Loss 0.5326 Accuracy 72.9980 AUC 0.7641\n",
            "Epoch 4 TRAIN Batch 150 Loss 0.5327 Accuracy 72.9994 AUC 0.7639\n",
            "Epoch 4 TRAIN Batch 200 Loss 0.5325 Accuracy 73.0143 AUC 0.7640\n",
            "Epoch 4 TRAIN Batch 250 Loss 0.5323 Accuracy 73.0272 AUC 0.7643\n",
            "Epoch 4 TRAIN Batch 300 Loss 0.5322 Accuracy 73.0360 AUC 0.7645\n",
            "Epoch 4 TRAIN Batch 350 Loss 0.5321 Accuracy 73.0420 AUC 0.7648\n",
            "Epoch 4 TRAIN Batch 400 Loss 0.5319 Accuracy 73.0605 AUC 0.7649\n",
            "Epoch 4 TRAIN Batch 450 Loss 0.5317 Accuracy 73.0700 AUC 0.7649\n",
            "Epoch 4 TRAIN Batch 500 Loss 0.5316 Accuracy 73.0791 AUC 0.7650\n",
            "Epoch 4 TRAIN Batch 550 Loss 0.5316 Accuracy 73.0787 AUC 0.7651\n",
            "Epoch 4 TRAIN Batch 600 Loss 0.5314 Accuracy 73.0936 AUC 0.7652\n",
            "Epoch 4 TRAIN Batch 650 Loss 0.5313 Accuracy 73.1014 AUC 0.7653\n",
            "Epoch 4 TRAIN Batch 700 Loss 0.5311 Accuracy 73.1189 AUC 0.7656\n",
            "Epoch 4 TRAIN Batch 750 Loss 0.5311 Accuracy 73.1228 AUC 0.7657\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "31-12 12:05 root         INFO     Epoch TRAIN 4 Loss 0.5311 Accuracy 73.1214 AUC 0.7658\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time taken for 1 epoch: 202.3347990512848 secs\n",
            "\n",
            "Epoch 5 TRAIN Batch 0 Loss 0.5437 Accuracy 72.4818 AUC 0.7665\n",
            "Epoch 5 TRAIN Batch 50 Loss 0.5309 Accuracy 73.0550 AUC 0.7656\n",
            "Epoch 5 TRAIN Batch 100 Loss 0.5292 Accuracy 73.2209 AUC 0.7666\n",
            "Epoch 5 TRAIN Batch 150 Loss 0.5284 Accuracy 73.3147 AUC 0.7678\n",
            "Epoch 5 TRAIN Batch 200 Loss 0.5281 Accuracy 73.3329 AUC 0.7681\n",
            "Epoch 5 TRAIN Batch 250 Loss 0.5284 Accuracy 73.2967 AUC 0.7680\n",
            "Epoch 5 TRAIN Batch 300 Loss 0.5280 Accuracy 73.3346 AUC 0.7682\n",
            "Epoch 5 TRAIN Batch 350 Loss 0.5278 Accuracy 73.3384 AUC 0.7681\n",
            "Epoch 5 TRAIN Batch 400 Loss 0.5281 Accuracy 73.3164 AUC 0.7679\n",
            "Epoch 5 TRAIN Batch 450 Loss 0.5282 Accuracy 73.3112 AUC 0.7679\n",
            "Epoch 5 TRAIN Batch 500 Loss 0.5283 Accuracy 73.3085 AUC 0.7680\n",
            "Epoch 5 TRAIN Batch 550 Loss 0.5284 Accuracy 73.3012 AUC 0.7680\n",
            "Epoch 5 TRAIN Batch 600 Loss 0.5285 Accuracy 73.2879 AUC 0.7679\n",
            "Epoch 5 TRAIN Batch 650 Loss 0.5286 Accuracy 73.2819 AUC 0.7678\n",
            "Epoch 5 TRAIN Batch 700 Loss 0.5285 Accuracy 73.2897 AUC 0.7680\n",
            "Epoch 5 TRAIN Batch 750 Loss 0.5284 Accuracy 73.3009 AUC 0.7682\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "31-12 12:09 root         INFO     Epoch TRAIN 5 Loss 0.5284 Accuracy 73.3012 AUC 0.7682\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 5 VAL Batch 0 Loss 0.5219 Accuracy 73.4222 AUC 0.7809\n",
            "Epoch 5 VAL Batch 50 Loss 0.5228 Accuracy 73.6237 AUC 0.7736\n",
            "Epoch 5 VAL Batch 100 Loss 0.5231 Accuracy 73.6314 AUC 0.7733\n",
            "Epoch 5 VAL Batch 150 Loss 0.5228 Accuracy 73.6379 AUC 0.7728\n",
            "Epoch 5 VAL Batch 200 Loss 0.5231 Accuracy 73.6291 AUC 0.7726\n",
            "Epoch 5 VAL Batch 250 Loss 0.5231 Accuracy 73.6316 AUC 0.7727\n",
            "Epoch 5 VAL Batch 300 Loss 0.5233 Accuracy 73.6217 AUC 0.7725\n",
            "Epoch 5 VAL Batch 350 Loss 0.5235 Accuracy 73.6165 AUC 0.7724\n",
            "Epoch 5 VAL Batch 400 Loss 0.5238 Accuracy 73.6009 AUC 0.7722\n",
            "Epoch 5 VAL Batch 450 Loss 0.5241 Accuracy 73.5779 AUC 0.7721\n",
            "Epoch 5 VAL Batch 500 Loss 0.5242 Accuracy 73.5686 AUC 0.7720\n",
            "Epoch 5 VAL Batch 550 Loss 0.5242 Accuracy 73.5712 AUC 0.7720\n",
            "Epoch 5 VAL Batch 600 Loss 0.5241 Accuracy 73.5775 AUC 0.7720\n",
            "Epoch 5 VAL Batch 650 Loss 0.5241 Accuracy 73.5794 AUC 0.7721\n",
            "Epoch 5 VAL Batch 700 Loss 0.5241 Accuracy 73.5805 AUC 0.7721\n",
            "Epoch 5 VAL Batch 750 Loss 0.5241 Accuracy 73.5800 AUC 0.7720\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "31-12 12:12 root         INFO     Epoch VAL 5 Loss 0.5241 Accuracy 73.5736 AUC 0.7720\n",
            "31-12 12:12 root         INFO     Saving checkpoint for epoch 5 at 31-Dec-riiid-3/checkpoints/ckpt-1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time taken for 1 epoch: 384.82783818244934 secs\n",
            "\n",
            "Epoch 6 TRAIN Batch 0 Loss 0.5360 Accuracy 72.9430 AUC 0.7594\n",
            "Epoch 6 TRAIN Batch 50 Loss 0.5259 Accuracy 73.5048 AUC 0.7711\n",
            "Epoch 6 TRAIN Batch 100 Loss 0.5266 Accuracy 73.4504 AUC 0.7705\n",
            "Epoch 6 TRAIN Batch 150 Loss 0.5275 Accuracy 73.3747 AUC 0.7696\n",
            "Epoch 6 TRAIN Batch 200 Loss 0.5275 Accuracy 73.3799 AUC 0.7693\n",
            "Epoch 6 TRAIN Batch 250 Loss 0.5274 Accuracy 73.3646 AUC 0.7694\n",
            "Epoch 6 TRAIN Batch 300 Loss 0.5273 Accuracy 73.3784 AUC 0.7696\n",
            "Epoch 6 TRAIN Batch 350 Loss 0.5273 Accuracy 73.3691 AUC 0.7697\n",
            "Epoch 6 TRAIN Batch 400 Loss 0.5267 Accuracy 73.3983 AUC 0.7701\n",
            "Epoch 6 TRAIN Batch 450 Loss 0.5268 Accuracy 73.4043 AUC 0.7699\n",
            "Epoch 6 TRAIN Batch 500 Loss 0.5267 Accuracy 73.4080 AUC 0.7701\n",
            "Epoch 6 TRAIN Batch 550 Loss 0.5267 Accuracy 73.3951 AUC 0.7702\n",
            "Epoch 6 TRAIN Batch 600 Loss 0.5267 Accuracy 73.3988 AUC 0.7702\n",
            "Epoch 6 TRAIN Batch 650 Loss 0.5267 Accuracy 73.4041 AUC 0.7702\n",
            "Epoch 6 TRAIN Batch 700 Loss 0.5268 Accuracy 73.3886 AUC 0.7702\n",
            "Epoch 6 TRAIN Batch 750 Loss 0.5267 Accuracy 73.3986 AUC 0.7704\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "31-12 12:15 root         INFO     Epoch TRAIN 6 Loss 0.5266 Accuracy 73.4019 AUC 0.7705\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time taken for 1 epoch: 199.7354760169983 secs\n",
            "\n",
            "Epoch 7 TRAIN Batch 0 Loss 0.5477 Accuracy 71.8630 AUC 0.7593\n",
            "Epoch 7 TRAIN Batch 50 Loss 0.5261 Accuracy 73.4473 AUC 0.7714\n",
            "Epoch 7 TRAIN Batch 100 Loss 0.5252 Accuracy 73.4843 AUC 0.7713\n",
            "Epoch 7 TRAIN Batch 150 Loss 0.5252 Accuracy 73.4955 AUC 0.7716\n",
            "Epoch 7 TRAIN Batch 200 Loss 0.5256 Accuracy 73.4734 AUC 0.7713\n",
            "Epoch 7 TRAIN Batch 250 Loss 0.5252 Accuracy 73.5000 AUC 0.7715\n",
            "Epoch 7 TRAIN Batch 300 Loss 0.5251 Accuracy 73.5044 AUC 0.7718\n",
            "Epoch 7 TRAIN Batch 350 Loss 0.5250 Accuracy 73.5062 AUC 0.7720\n",
            "Epoch 7 TRAIN Batch 400 Loss 0.5248 Accuracy 73.5169 AUC 0.7722\n",
            "Epoch 7 TRAIN Batch 450 Loss 0.5248 Accuracy 73.5202 AUC 0.7724\n",
            "Epoch 7 TRAIN Batch 500 Loss 0.5248 Accuracy 73.5193 AUC 0.7724\n",
            "Epoch 7 TRAIN Batch 550 Loss 0.5250 Accuracy 73.5072 AUC 0.7724\n",
            "Epoch 7 TRAIN Batch 600 Loss 0.5248 Accuracy 73.5092 AUC 0.7725\n",
            "Epoch 7 TRAIN Batch 650 Loss 0.5248 Accuracy 73.5109 AUC 0.7726\n",
            "Epoch 7 TRAIN Batch 700 Loss 0.5248 Accuracy 73.5113 AUC 0.7728\n",
            "Epoch 7 TRAIN Batch 750 Loss 0.5247 Accuracy 73.5160 AUC 0.7728\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "31-12 12:18 root         INFO     Epoch TRAIN 7 Loss 0.5246 Accuracy 73.5194 AUC 0.7728\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time taken for 1 epoch: 200.5329978466034 secs\n",
            "\n",
            "Epoch 8 TRAIN Batch 0 Loss 0.5346 Accuracy 72.6407 AUC 0.7729\n",
            "Epoch 8 TRAIN Batch 50 Loss 0.5237 Accuracy 73.5129 AUC 0.7749\n",
            "Epoch 8 TRAIN Batch 100 Loss 0.5238 Accuracy 73.5395 AUC 0.7740\n",
            "Epoch 8 TRAIN Batch 150 Loss 0.5235 Accuracy 73.5681 AUC 0.7744\n",
            "Epoch 8 TRAIN Batch 200 Loss 0.5233 Accuracy 73.5908 AUC 0.7745\n",
            "Epoch 8 TRAIN Batch 250 Loss 0.5229 Accuracy 73.6279 AUC 0.7749\n",
            "Epoch 8 TRAIN Batch 300 Loss 0.5230 Accuracy 73.6251 AUC 0.7748\n",
            "Epoch 8 TRAIN Batch 350 Loss 0.5230 Accuracy 73.6208 AUC 0.7750\n",
            "Epoch 8 TRAIN Batch 400 Loss 0.5227 Accuracy 73.6351 AUC 0.7751\n",
            "Epoch 8 TRAIN Batch 450 Loss 0.5227 Accuracy 73.6381 AUC 0.7751\n",
            "Epoch 8 TRAIN Batch 500 Loss 0.5224 Accuracy 73.6599 AUC 0.7753\n",
            "Epoch 8 TRAIN Batch 550 Loss 0.5224 Accuracy 73.6596 AUC 0.7753\n",
            "Epoch 8 TRAIN Batch 600 Loss 0.5222 Accuracy 73.6690 AUC 0.7754\n",
            "Epoch 8 TRAIN Batch 650 Loss 0.5222 Accuracy 73.6613 AUC 0.7753\n",
            "Epoch 8 TRAIN Batch 700 Loss 0.5220 Accuracy 73.6701 AUC 0.7756\n",
            "Epoch 8 TRAIN Batch 750 Loss 0.5220 Accuracy 73.6699 AUC 0.7756\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "31-12 12:22 root         INFO     Epoch TRAIN 8 Loss 0.5219 Accuracy 73.6778 AUC 0.7758\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time taken for 1 epoch: 200.28191924095154 secs\n",
            "\n",
            "Epoch 9 TRAIN Batch 0 Loss 0.5130 Accuracy 73.9209 AUC 0.7826\n",
            "Epoch 9 TRAIN Batch 50 Loss 0.5228 Accuracy 73.6035 AUC 0.7757\n",
            "Epoch 9 TRAIN Batch 100 Loss 0.5215 Accuracy 73.6981 AUC 0.7757\n",
            "Epoch 9 TRAIN Batch 150 Loss 0.5215 Accuracy 73.6960 AUC 0.7760\n",
            "Epoch 9 TRAIN Batch 200 Loss 0.5209 Accuracy 73.7212 AUC 0.7766\n",
            "Epoch 9 TRAIN Batch 250 Loss 0.5211 Accuracy 73.7201 AUC 0.7762\n",
            "Epoch 9 TRAIN Batch 300 Loss 0.5208 Accuracy 73.7432 AUC 0.7767\n",
            "Epoch 9 TRAIN Batch 350 Loss 0.5208 Accuracy 73.7402 AUC 0.7767\n",
            "Epoch 9 TRAIN Batch 400 Loss 0.5211 Accuracy 73.7138 AUC 0.7765\n",
            "Epoch 9 TRAIN Batch 450 Loss 0.5208 Accuracy 73.7289 AUC 0.7768\n",
            "Epoch 9 TRAIN Batch 500 Loss 0.5208 Accuracy 73.7282 AUC 0.7769\n",
            "Epoch 9 TRAIN Batch 550 Loss 0.5207 Accuracy 73.7383 AUC 0.7770\n",
            "Epoch 9 TRAIN Batch 600 Loss 0.5205 Accuracy 73.7451 AUC 0.7771\n",
            "Epoch 9 TRAIN Batch 650 Loss 0.5205 Accuracy 73.7465 AUC 0.7772\n",
            "Epoch 9 TRAIN Batch 700 Loss 0.5204 Accuracy 73.7511 AUC 0.7773\n",
            "Epoch 9 TRAIN Batch 750 Loss 0.5203 Accuracy 73.7564 AUC 0.7774\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "31-12 12:25 root         INFO     Epoch TRAIN 9 Loss 0.5202 Accuracy 73.7634 AUC 0.7774\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time taken for 1 epoch: 201.83191204071045 secs\n",
            "\n",
            "Epoch 10 TRAIN Batch 0 Loss 0.5195 Accuracy 73.9753 AUC 0.7767\n",
            "Epoch 10 TRAIN Batch 50 Loss 0.5205 Accuracy 73.7504 AUC 0.7786\n",
            "Epoch 10 TRAIN Batch 100 Loss 0.5207 Accuracy 73.7256 AUC 0.7783\n",
            "Epoch 10 TRAIN Batch 150 Loss 0.5198 Accuracy 73.7912 AUC 0.7784\n",
            "Epoch 10 TRAIN Batch 200 Loss 0.5195 Accuracy 73.8012 AUC 0.7786\n",
            "Epoch 10 TRAIN Batch 250 Loss 0.5196 Accuracy 73.7934 AUC 0.7785\n",
            "Epoch 10 TRAIN Batch 300 Loss 0.5194 Accuracy 73.8105 AUC 0.7787\n",
            "Epoch 10 TRAIN Batch 350 Loss 0.5197 Accuracy 73.7819 AUC 0.7785\n",
            "Epoch 10 TRAIN Batch 400 Loss 0.5194 Accuracy 73.7970 AUC 0.7788\n",
            "Epoch 10 TRAIN Batch 450 Loss 0.5194 Accuracy 73.7921 AUC 0.7788\n",
            "Epoch 10 TRAIN Batch 500 Loss 0.5194 Accuracy 73.7930 AUC 0.7787\n",
            "Epoch 10 TRAIN Batch 550 Loss 0.5194 Accuracy 73.7860 AUC 0.7788\n",
            "Epoch 10 TRAIN Batch 600 Loss 0.5194 Accuracy 73.7944 AUC 0.7789\n",
            "Epoch 10 TRAIN Batch 650 Loss 0.5194 Accuracy 73.7983 AUC 0.7788\n",
            "Epoch 10 TRAIN Batch 700 Loss 0.5193 Accuracy 73.8018 AUC 0.7790\n",
            "Epoch 10 TRAIN Batch 750 Loss 0.5192 Accuracy 73.8105 AUC 0.7791\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "31-12 12:29 root         INFO     Epoch TRAIN 10 Loss 0.5191 Accuracy 73.8169 AUC 0.7791\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 10 VAL Batch 0 Loss 0.5143 Accuracy 74.2008 AUC 0.7898\n",
            "Epoch 10 VAL Batch 50 Loss 0.5146 Accuracy 74.1385 AUC 0.7833\n",
            "Epoch 10 VAL Batch 100 Loss 0.5150 Accuracy 74.1251 AUC 0.7829\n",
            "Epoch 10 VAL Batch 150 Loss 0.5146 Accuracy 74.1517 AUC 0.7825\n",
            "Epoch 10 VAL Batch 200 Loss 0.5150 Accuracy 74.1315 AUC 0.7822\n",
            "Epoch 10 VAL Batch 250 Loss 0.5150 Accuracy 74.1392 AUC 0.7823\n",
            "Epoch 10 VAL Batch 300 Loss 0.5153 Accuracy 74.1227 AUC 0.7821\n",
            "Epoch 10 VAL Batch 350 Loss 0.5155 Accuracy 74.1153 AUC 0.7819\n",
            "Epoch 10 VAL Batch 400 Loss 0.5157 Accuracy 74.0950 AUC 0.7818\n",
            "Epoch 10 VAL Batch 450 Loss 0.5160 Accuracy 74.0718 AUC 0.7818\n",
            "Epoch 10 VAL Batch 500 Loss 0.5161 Accuracy 74.0609 AUC 0.7816\n",
            "Epoch 10 VAL Batch 550 Loss 0.5161 Accuracy 74.0618 AUC 0.7816\n",
            "Epoch 10 VAL Batch 600 Loss 0.5160 Accuracy 74.0720 AUC 0.7816\n",
            "Epoch 10 VAL Batch 650 Loss 0.5160 Accuracy 74.0692 AUC 0.7817\n",
            "Epoch 10 VAL Batch 700 Loss 0.5159 Accuracy 74.0713 AUC 0.7817\n",
            "Epoch 10 VAL Batch 750 Loss 0.5159 Accuracy 74.0720 AUC 0.7817\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "31-12 12:29 root         INFO     Epoch VAL 10 Loss 0.5160 Accuracy 74.0649 AUC 0.7817\n",
            "31-12 12:29 root         INFO     Saving checkpoint for epoch 10 at 31-Dec-riiid-3/checkpoints/ckpt-2\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time taken for 1 epoch: 228.84489846229553 secs\n",
            "\n",
            "Epoch 11 TRAIN Batch 0 Loss 0.5221 Accuracy 73.8376 AUC 0.7786\n",
            "Epoch 11 TRAIN Batch 50 Loss 0.5176 Accuracy 73.8827 AUC 0.7803\n",
            "Epoch 11 TRAIN Batch 100 Loss 0.5171 Accuracy 73.9200 AUC 0.7803\n",
            "Epoch 11 TRAIN Batch 150 Loss 0.5176 Accuracy 73.8955 AUC 0.7799\n",
            "Epoch 11 TRAIN Batch 200 Loss 0.5178 Accuracy 73.8783 AUC 0.7799\n",
            "Epoch 11 TRAIN Batch 250 Loss 0.5173 Accuracy 73.9079 AUC 0.7801\n",
            "Epoch 11 TRAIN Batch 300 Loss 0.5173 Accuracy 73.9122 AUC 0.7801\n",
            "Epoch 11 TRAIN Batch 350 Loss 0.5174 Accuracy 73.8994 AUC 0.7801\n",
            "Epoch 11 TRAIN Batch 400 Loss 0.5177 Accuracy 73.8865 AUC 0.7800\n",
            "Epoch 11 TRAIN Batch 450 Loss 0.5178 Accuracy 73.8750 AUC 0.7800\n",
            "Epoch 11 TRAIN Batch 500 Loss 0.5178 Accuracy 73.8808 AUC 0.7801\n",
            "Epoch 11 TRAIN Batch 550 Loss 0.5178 Accuracy 73.8821 AUC 0.7802\n",
            "Epoch 11 TRAIN Batch 600 Loss 0.5178 Accuracy 73.8807 AUC 0.7802\n",
            "Epoch 11 TRAIN Batch 650 Loss 0.5178 Accuracy 73.8882 AUC 0.7803\n",
            "Epoch 11 TRAIN Batch 700 Loss 0.5179 Accuracy 73.8812 AUC 0.7803\n",
            "Epoch 11 TRAIN Batch 750 Loss 0.5178 Accuracy 73.8846 AUC 0.7804\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "31-12 12:32 root         INFO     Epoch TRAIN 11 Loss 0.5177 Accuracy 73.8929 AUC 0.7805\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time taken for 1 epoch: 199.1168167591095 secs\n",
            "\n",
            "Epoch 12 TRAIN Batch 0 Loss 0.5281 Accuracy 73.1643 AUC 0.7779\n",
            "Epoch 12 TRAIN Batch 50 Loss 0.5167 Accuracy 74.0055 AUC 0.7815\n",
            "Epoch 12 TRAIN Batch 100 Loss 0.5157 Accuracy 74.0823 AUC 0.7814\n",
            "Epoch 12 TRAIN Batch 150 Loss 0.5159 Accuracy 74.0574 AUC 0.7814\n",
            "Epoch 12 TRAIN Batch 200 Loss 0.5164 Accuracy 74.0066 AUC 0.7811\n",
            "Epoch 12 TRAIN Batch 250 Loss 0.5167 Accuracy 73.9902 AUC 0.7810\n",
            "Epoch 12 TRAIN Batch 300 Loss 0.5170 Accuracy 73.9613 AUC 0.7809\n",
            "Epoch 12 TRAIN Batch 350 Loss 0.5166 Accuracy 73.9955 AUC 0.7811\n",
            "Epoch 12 TRAIN Batch 400 Loss 0.5166 Accuracy 73.9939 AUC 0.7812\n",
            "Epoch 12 TRAIN Batch 450 Loss 0.5165 Accuracy 73.9964 AUC 0.7813\n",
            "Epoch 12 TRAIN Batch 500 Loss 0.5166 Accuracy 73.9849 AUC 0.7815\n",
            "Epoch 12 TRAIN Batch 550 Loss 0.5169 Accuracy 73.9654 AUC 0.7815\n",
            "Epoch 12 TRAIN Batch 600 Loss 0.5169 Accuracy 73.9592 AUC 0.7815\n",
            "Epoch 12 TRAIN Batch 650 Loss 0.5169 Accuracy 73.9562 AUC 0.7815\n",
            "Epoch 12 TRAIN Batch 700 Loss 0.5168 Accuracy 73.9629 AUC 0.7816\n",
            "Epoch 12 TRAIN Batch 750 Loss 0.5168 Accuracy 73.9635 AUC 0.7817\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "31-12 12:36 root         INFO     Epoch TRAIN 12 Loss 0.5167 Accuracy 73.9725 AUC 0.7817\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time taken for 1 epoch: 195.91711115837097 secs\n",
            "\n",
            "Epoch 13 TRAIN Batch 0 Loss 0.5138 Accuracy 74.0866 AUC 0.7920\n",
            "Epoch 13 TRAIN Batch 50 Loss 0.5172 Accuracy 73.9486 AUC 0.7816\n",
            "Epoch 13 TRAIN Batch 100 Loss 0.5171 Accuracy 73.9315 AUC 0.7822\n",
            "Epoch 13 TRAIN Batch 150 Loss 0.5166 Accuracy 73.9489 AUC 0.7823\n",
            "Epoch 13 TRAIN Batch 200 Loss 0.5164 Accuracy 73.9606 AUC 0.7823\n",
            "Epoch 13 TRAIN Batch 250 Loss 0.5161 Accuracy 73.9757 AUC 0.7825\n",
            "Epoch 13 TRAIN Batch 300 Loss 0.5157 Accuracy 74.0095 AUC 0.7827\n",
            "Epoch 13 TRAIN Batch 350 Loss 0.5158 Accuracy 74.0031 AUC 0.7827\n",
            "Epoch 13 TRAIN Batch 400 Loss 0.5157 Accuracy 74.0066 AUC 0.7828\n",
            "Epoch 13 TRAIN Batch 450 Loss 0.5156 Accuracy 74.0281 AUC 0.7829\n",
            "Epoch 13 TRAIN Batch 500 Loss 0.5156 Accuracy 74.0247 AUC 0.7828\n",
            "Epoch 13 TRAIN Batch 550 Loss 0.5153 Accuracy 74.0445 AUC 0.7829\n",
            "Epoch 13 TRAIN Batch 600 Loss 0.5154 Accuracy 74.0429 AUC 0.7828\n",
            "Epoch 13 TRAIN Batch 650 Loss 0.5153 Accuracy 74.0500 AUC 0.7830\n",
            "Epoch 13 TRAIN Batch 700 Loss 0.5152 Accuracy 74.0554 AUC 0.7831\n",
            "Epoch 13 TRAIN Batch 750 Loss 0.5152 Accuracy 74.0496 AUC 0.7831\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "31-12 12:39 root         INFO     Epoch TRAIN 13 Loss 0.5153 Accuracy 74.0460 AUC 0.7831\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time taken for 1 epoch: 196.82003927230835 secs\n",
            "\n",
            "Epoch 14 TRAIN Batch 0 Loss 0.5275 Accuracy 73.0647 AUC 0.7716\n",
            "Epoch 14 TRAIN Batch 50 Loss 0.5170 Accuracy 73.9624 AUC 0.7825\n",
            "Epoch 14 TRAIN Batch 100 Loss 0.5161 Accuracy 73.9983 AUC 0.7830\n",
            "Epoch 14 TRAIN Batch 150 Loss 0.5154 Accuracy 74.0410 AUC 0.7837\n",
            "Epoch 14 TRAIN Batch 200 Loss 0.5149 Accuracy 74.0754 AUC 0.7836\n",
            "Epoch 14 TRAIN Batch 250 Loss 0.5152 Accuracy 74.0453 AUC 0.7835\n",
            "Epoch 14 TRAIN Batch 300 Loss 0.5154 Accuracy 74.0334 AUC 0.7834\n",
            "Epoch 14 TRAIN Batch 350 Loss 0.5153 Accuracy 74.0306 AUC 0.7835\n",
            "Epoch 14 TRAIN Batch 400 Loss 0.5150 Accuracy 74.0538 AUC 0.7836\n",
            "Epoch 14 TRAIN Batch 450 Loss 0.5149 Accuracy 74.0560 AUC 0.7836\n",
            "Epoch 14 TRAIN Batch 500 Loss 0.5150 Accuracy 74.0472 AUC 0.7837\n",
            "Epoch 14 TRAIN Batch 550 Loss 0.5149 Accuracy 74.0465 AUC 0.7837\n",
            "Epoch 14 TRAIN Batch 600 Loss 0.5148 Accuracy 74.0607 AUC 0.7838\n",
            "Epoch 14 TRAIN Batch 650 Loss 0.5146 Accuracy 74.0663 AUC 0.7839\n",
            "Epoch 14 TRAIN Batch 700 Loss 0.5146 Accuracy 74.0678 AUC 0.7839\n",
            "Epoch 14 TRAIN Batch 750 Loss 0.5146 Accuracy 74.0664 AUC 0.7839\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "31-12 12:42 root         INFO     Epoch TRAIN 14 Loss 0.5148 Accuracy 74.0598 AUC 0.7839\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time taken for 1 epoch: 196.32991313934326 secs\n",
            "\n",
            "Epoch 15 TRAIN Batch 0 Loss 0.5157 Accuracy 73.7760 AUC 0.7887\n",
            "Epoch 15 TRAIN Batch 50 Loss 0.5150 Accuracy 73.9491 AUC 0.7849\n",
            "Epoch 15 TRAIN Batch 100 Loss 0.5148 Accuracy 74.0113 AUC 0.7844\n",
            "Epoch 15 TRAIN Batch 150 Loss 0.5144 Accuracy 74.0543 AUC 0.7849\n",
            "Epoch 15 TRAIN Batch 200 Loss 0.5137 Accuracy 74.1091 AUC 0.7851\n",
            "Epoch 15 TRAIN Batch 250 Loss 0.5136 Accuracy 74.1176 AUC 0.7850\n",
            "Epoch 15 TRAIN Batch 300 Loss 0.5134 Accuracy 74.1377 AUC 0.7850\n",
            "Epoch 15 TRAIN Batch 350 Loss 0.5135 Accuracy 74.1376 AUC 0.7851\n",
            "Epoch 15 TRAIN Batch 400 Loss 0.5132 Accuracy 74.1602 AUC 0.7852\n",
            "Epoch 15 TRAIN Batch 450 Loss 0.5131 Accuracy 74.1693 AUC 0.7853\n",
            "Epoch 15 TRAIN Batch 500 Loss 0.5131 Accuracy 74.1636 AUC 0.7853\n",
            "Epoch 15 TRAIN Batch 550 Loss 0.5130 Accuracy 74.1729 AUC 0.7853\n",
            "Epoch 15 TRAIN Batch 600 Loss 0.5132 Accuracy 74.1613 AUC 0.7852\n",
            "Epoch 15 TRAIN Batch 650 Loss 0.5132 Accuracy 74.1572 AUC 0.7852\n",
            "Epoch 15 TRAIN Batch 700 Loss 0.5133 Accuracy 74.1468 AUC 0.7852\n",
            "Epoch 15 TRAIN Batch 750 Loss 0.5134 Accuracy 74.1415 AUC 0.7852\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "31-12 12:45 root         INFO     Epoch TRAIN 15 Loss 0.5133 Accuracy 74.1478 AUC 0.7852\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 15 VAL Batch 0 Loss 0.5072 Accuracy 74.3250 AUC 0.7972\n",
            "Epoch 15 VAL Batch 50 Loss 0.5094 Accuracy 74.4285 AUC 0.7891\n",
            "Epoch 15 VAL Batch 100 Loss 0.5098 Accuracy 74.4073 AUC 0.7887\n",
            "Epoch 15 VAL Batch 150 Loss 0.5095 Accuracy 74.4140 AUC 0.7883\n",
            "Epoch 15 VAL Batch 200 Loss 0.5098 Accuracy 74.4052 AUC 0.7880\n",
            "Epoch 15 VAL Batch 250 Loss 0.5098 Accuracy 74.4247 AUC 0.7881\n",
            "Epoch 15 VAL Batch 300 Loss 0.5100 Accuracy 74.4172 AUC 0.7880\n",
            "Epoch 15 VAL Batch 350 Loss 0.5102 Accuracy 74.4067 AUC 0.7879\n",
            "Epoch 15 VAL Batch 400 Loss 0.5104 Accuracy 74.3800 AUC 0.7877\n",
            "Epoch 15 VAL Batch 450 Loss 0.5107 Accuracy 74.3598 AUC 0.7877\n",
            "Epoch 15 VAL Batch 500 Loss 0.5108 Accuracy 74.3550 AUC 0.7876\n",
            "Epoch 15 VAL Batch 550 Loss 0.5108 Accuracy 74.3575 AUC 0.7876\n",
            "Epoch 15 VAL Batch 600 Loss 0.5107 Accuracy 74.3629 AUC 0.7876\n",
            "Epoch 15 VAL Batch 650 Loss 0.5107 Accuracy 74.3587 AUC 0.7876\n",
            "Epoch 15 VAL Batch 700 Loss 0.5107 Accuracy 74.3591 AUC 0.7876\n",
            "Epoch 15 VAL Batch 750 Loss 0.5107 Accuracy 74.3574 AUC 0.7876\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "31-12 12:46 root         INFO     Epoch VAL 15 Loss 0.5107 Accuracy 74.3533 AUC 0.7876\n",
            "31-12 12:46 root         INFO     Saving checkpoint for epoch 15 at 31-Dec-riiid-3/checkpoints/ckpt-3\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time taken for 1 epoch: 219.27755117416382 secs\n",
            "\n",
            "Epoch 16 TRAIN Batch 0 Loss 0.4879 Accuracy 76.0062 AUC 0.8058\n",
            "Epoch 16 TRAIN Batch 50 Loss 0.5133 Accuracy 74.1806 AUC 0.7859\n",
            "Epoch 16 TRAIN Batch 100 Loss 0.5138 Accuracy 74.1199 AUC 0.7851\n",
            "Epoch 16 TRAIN Batch 150 Loss 0.5137 Accuracy 74.1367 AUC 0.7855\n",
            "Epoch 16 TRAIN Batch 200 Loss 0.5133 Accuracy 74.1516 AUC 0.7856\n",
            "Epoch 16 TRAIN Batch 250 Loss 0.5133 Accuracy 74.1511 AUC 0.7858\n",
            "Epoch 16 TRAIN Batch 300 Loss 0.5129 Accuracy 74.1826 AUC 0.7860\n",
            "Epoch 16 TRAIN Batch 350 Loss 0.5125 Accuracy 74.1973 AUC 0.7862\n",
            "Epoch 16 TRAIN Batch 400 Loss 0.5123 Accuracy 74.2152 AUC 0.7864\n",
            "Epoch 16 TRAIN Batch 450 Loss 0.5125 Accuracy 74.2036 AUC 0.7864\n",
            "Epoch 16 TRAIN Batch 500 Loss 0.5125 Accuracy 74.2005 AUC 0.7863\n",
            "Epoch 16 TRAIN Batch 550 Loss 0.5124 Accuracy 74.2074 AUC 0.7864\n",
            "Epoch 16 TRAIN Batch 600 Loss 0.5124 Accuracy 74.2040 AUC 0.7864\n",
            "Epoch 16 TRAIN Batch 650 Loss 0.5124 Accuracy 74.2062 AUC 0.7864\n",
            "Epoch 16 TRAIN Batch 700 Loss 0.5123 Accuracy 74.2166 AUC 0.7865\n",
            "Epoch 16 TRAIN Batch 750 Loss 0.5122 Accuracy 74.2173 AUC 0.7865\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "31-12 12:49 root         INFO     Epoch TRAIN 16 Loss 0.5121 Accuracy 74.2276 AUC 0.7866\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time taken for 1 epoch: 196.80764174461365 secs\n",
            "\n",
            "Epoch 17 TRAIN Batch 0 Loss 0.5114 Accuracy 74.6196 AUC 0.7860\n",
            "Epoch 17 TRAIN Batch 50 Loss 0.5120 Accuracy 74.1850 AUC 0.7860\n",
            "Epoch 17 TRAIN Batch 100 Loss 0.5123 Accuracy 74.1700 AUC 0.7860\n",
            "Epoch 17 TRAIN Batch 150 Loss 0.5116 Accuracy 74.2360 AUC 0.7867\n",
            "Epoch 17 TRAIN Batch 200 Loss 0.5118 Accuracy 74.2219 AUC 0.7865\n",
            "Epoch 17 TRAIN Batch 250 Loss 0.5118 Accuracy 74.2177 AUC 0.7865\n",
            "Epoch 17 TRAIN Batch 300 Loss 0.5119 Accuracy 74.2044 AUC 0.7865\n",
            "Epoch 17 TRAIN Batch 350 Loss 0.5117 Accuracy 74.2129 AUC 0.7866\n",
            "Epoch 17 TRAIN Batch 400 Loss 0.5116 Accuracy 74.2335 AUC 0.7868\n",
            "Epoch 17 TRAIN Batch 450 Loss 0.5115 Accuracy 74.2337 AUC 0.7869\n",
            "Epoch 17 TRAIN Batch 500 Loss 0.5116 Accuracy 74.2266 AUC 0.7867\n",
            "Epoch 17 TRAIN Batch 550 Loss 0.5114 Accuracy 74.2393 AUC 0.7869\n",
            "Epoch 17 TRAIN Batch 600 Loss 0.5114 Accuracy 74.2388 AUC 0.7870\n",
            "Epoch 17 TRAIN Batch 650 Loss 0.5115 Accuracy 74.2432 AUC 0.7870\n",
            "Epoch 17 TRAIN Batch 700 Loss 0.5115 Accuracy 74.2369 AUC 0.7870\n",
            "Epoch 17 TRAIN Batch 750 Loss 0.5114 Accuracy 74.2453 AUC 0.7870\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "31-12 12:52 root         INFO     Epoch TRAIN 17 Loss 0.5114 Accuracy 74.2468 AUC 0.7871\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time taken for 1 epoch: 195.18970823287964 secs\n",
            "\n",
            "Epoch 18 TRAIN Batch 0 Loss 0.5104 Accuracy 74.3004 AUC 0.7878\n",
            "Epoch 18 TRAIN Batch 50 Loss 0.5087 Accuracy 74.4725 AUC 0.7887\n",
            "Epoch 18 TRAIN Batch 100 Loss 0.5097 Accuracy 74.3903 AUC 0.7881\n",
            "Epoch 18 TRAIN Batch 150 Loss 0.5101 Accuracy 74.3642 AUC 0.7880\n",
            "Epoch 18 TRAIN Batch 200 Loss 0.5101 Accuracy 74.3423 AUC 0.7882\n",
            "Epoch 18 TRAIN Batch 250 Loss 0.5105 Accuracy 74.3081 AUC 0.7880\n",
            "Epoch 18 TRAIN Batch 300 Loss 0.5106 Accuracy 74.2984 AUC 0.7879\n",
            "Epoch 18 TRAIN Batch 350 Loss 0.5106 Accuracy 74.2897 AUC 0.7878\n",
            "Epoch 18 TRAIN Batch 400 Loss 0.5104 Accuracy 74.3052 AUC 0.7878\n",
            "Epoch 18 TRAIN Batch 450 Loss 0.5106 Accuracy 74.2968 AUC 0.7879\n",
            "Epoch 18 TRAIN Batch 500 Loss 0.5108 Accuracy 74.2810 AUC 0.7878\n",
            "Epoch 18 TRAIN Batch 550 Loss 0.5108 Accuracy 74.2781 AUC 0.7878\n",
            "Epoch 18 TRAIN Batch 600 Loss 0.5107 Accuracy 74.2852 AUC 0.7879\n",
            "Epoch 18 TRAIN Batch 650 Loss 0.5106 Accuracy 74.2918 AUC 0.7879\n",
            "Epoch 18 TRAIN Batch 700 Loss 0.5105 Accuracy 74.2964 AUC 0.7879\n",
            "Epoch 18 TRAIN Batch 750 Loss 0.5105 Accuracy 74.3052 AUC 0.7879\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "31-12 12:56 root         INFO     Epoch TRAIN 18 Loss 0.5105 Accuracy 74.3047 AUC 0.7878\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time taken for 1 epoch: 196.85558581352234 secs\n",
            "\n",
            "Epoch 19 TRAIN Batch 0 Loss 0.5104 Accuracy 74.5400 AUC 0.7833\n",
            "Epoch 19 TRAIN Batch 50 Loss 0.5106 Accuracy 74.1925 AUC 0.7861\n",
            "Epoch 19 TRAIN Batch 100 Loss 0.5104 Accuracy 74.2489 AUC 0.7878\n",
            "Epoch 19 TRAIN Batch 150 Loss 0.5103 Accuracy 74.2664 AUC 0.7883\n",
            "Epoch 19 TRAIN Batch 200 Loss 0.5100 Accuracy 74.3088 AUC 0.7885\n",
            "Epoch 19 TRAIN Batch 250 Loss 0.5099 Accuracy 74.3319 AUC 0.7886\n",
            "Epoch 19 TRAIN Batch 300 Loss 0.5100 Accuracy 74.3282 AUC 0.7885\n",
            "Epoch 19 TRAIN Batch 350 Loss 0.5099 Accuracy 74.3371 AUC 0.7886\n",
            "Epoch 19 TRAIN Batch 400 Loss 0.5100 Accuracy 74.3262 AUC 0.7885\n",
            "Epoch 19 TRAIN Batch 450 Loss 0.5098 Accuracy 74.3276 AUC 0.7885\n",
            "Epoch 19 TRAIN Batch 500 Loss 0.5100 Accuracy 74.3174 AUC 0.7885\n",
            "Epoch 19 TRAIN Batch 550 Loss 0.5099 Accuracy 74.3210 AUC 0.7886\n",
            "Epoch 19 TRAIN Batch 600 Loss 0.5100 Accuracy 74.3060 AUC 0.7885\n",
            "Epoch 19 TRAIN Batch 650 Loss 0.5100 Accuracy 74.3072 AUC 0.7885\n",
            "Epoch 19 TRAIN Batch 700 Loss 0.5100 Accuracy 74.3121 AUC 0.7886\n",
            "Epoch 19 TRAIN Batch 750 Loss 0.5101 Accuracy 74.3104 AUC 0.7887\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "31-12 12:59 root         INFO     Epoch TRAIN 19 Loss 0.5100 Accuracy 74.3120 AUC 0.7887\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time taken for 1 epoch: 195.83557415008545 secs\n",
            "\n",
            "Epoch 20 TRAIN Batch 0 Loss 0.5190 Accuracy 73.6334 AUC 0.7861\n",
            "Epoch 20 TRAIN Batch 50 Loss 0.5103 Accuracy 74.2942 AUC 0.7882\n",
            "Epoch 20 TRAIN Batch 100 Loss 0.5098 Accuracy 74.3562 AUC 0.7882\n",
            "Epoch 20 TRAIN Batch 150 Loss 0.5097 Accuracy 74.3555 AUC 0.7888\n",
            "Epoch 20 TRAIN Batch 200 Loss 0.5093 Accuracy 74.3971 AUC 0.7892\n",
            "Epoch 20 TRAIN Batch 250 Loss 0.5095 Accuracy 74.3742 AUC 0.7894\n",
            "Epoch 20 TRAIN Batch 300 Loss 0.5096 Accuracy 74.3596 AUC 0.7893\n",
            "Epoch 20 TRAIN Batch 350 Loss 0.5096 Accuracy 74.3578 AUC 0.7892\n",
            "Epoch 20 TRAIN Batch 400 Loss 0.5096 Accuracy 74.3578 AUC 0.7892\n",
            "Epoch 20 TRAIN Batch 450 Loss 0.5096 Accuracy 74.3615 AUC 0.7894\n",
            "Epoch 20 TRAIN Batch 500 Loss 0.5097 Accuracy 74.3497 AUC 0.7893\n",
            "Epoch 20 TRAIN Batch 550 Loss 0.5097 Accuracy 74.3395 AUC 0.7893\n",
            "Epoch 20 TRAIN Batch 600 Loss 0.5096 Accuracy 74.3443 AUC 0.7893\n",
            "Epoch 20 TRAIN Batch 650 Loss 0.5096 Accuracy 74.3418 AUC 0.7893\n",
            "Epoch 20 TRAIN Batch 700 Loss 0.5095 Accuracy 74.3465 AUC 0.7894\n",
            "Epoch 20 TRAIN Batch 750 Loss 0.5095 Accuracy 74.3472 AUC 0.7893\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "31-12 13:02 root         INFO     Epoch TRAIN 20 Loss 0.5096 Accuracy 74.3419 AUC 0.7894\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 20 VAL Batch 0 Loss 0.5049 Accuracy 74.4327 AUC 0.7997\n",
            "Epoch 20 VAL Batch 50 Loss 0.5064 Accuracy 74.5952 AUC 0.7921\n",
            "Epoch 20 VAL Batch 100 Loss 0.5067 Accuracy 74.5704 AUC 0.7919\n",
            "Epoch 20 VAL Batch 150 Loss 0.5064 Accuracy 74.5742 AUC 0.7915\n",
            "Epoch 20 VAL Batch 200 Loss 0.5068 Accuracy 74.5492 AUC 0.7912\n",
            "Epoch 20 VAL Batch 250 Loss 0.5067 Accuracy 74.5576 AUC 0.7913\n",
            "Epoch 20 VAL Batch 300 Loss 0.5069 Accuracy 74.5461 AUC 0.7911\n",
            "Epoch 20 VAL Batch 350 Loss 0.5071 Accuracy 74.5369 AUC 0.7910\n",
            "Epoch 20 VAL Batch 400 Loss 0.5073 Accuracy 74.5112 AUC 0.7909\n",
            "Epoch 20 VAL Batch 450 Loss 0.5076 Accuracy 74.4910 AUC 0.7909\n",
            "Epoch 20 VAL Batch 500 Loss 0.5077 Accuracy 74.4856 AUC 0.7907\n",
            "Epoch 20 VAL Batch 550 Loss 0.5077 Accuracy 74.4906 AUC 0.7907\n",
            "Epoch 20 VAL Batch 600 Loss 0.5075 Accuracy 74.4975 AUC 0.7908\n",
            "Epoch 20 VAL Batch 650 Loss 0.5076 Accuracy 74.4947 AUC 0.7908\n",
            "Epoch 20 VAL Batch 700 Loss 0.5075 Accuracy 74.4974 AUC 0.7908\n",
            "Epoch 20 VAL Batch 750 Loss 0.5075 Accuracy 74.4946 AUC 0.7908\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "31-12 13:02 root         INFO     Epoch VAL 20 Loss 0.5075 Accuracy 74.4901 AUC 0.7908\n",
            "31-12 13:02 root         INFO     Saving checkpoint for epoch 20 at 31-Dec-riiid-3/checkpoints/ckpt-4\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time taken for 1 epoch: 218.3480839729309 secs\n",
            "\n",
            "Epoch 21 TRAIN Batch 0 Loss 0.4999 Accuracy 74.7590 AUC 0.7846\n",
            "Epoch 21 TRAIN Batch 50 Loss 0.5089 Accuracy 74.4702 AUC 0.7903\n",
            "Epoch 21 TRAIN Batch 100 Loss 0.5108 Accuracy 74.2886 AUC 0.7888\n",
            "Epoch 21 TRAIN Batch 150 Loss 0.5103 Accuracy 74.3136 AUC 0.7893\n",
            "Epoch 21 TRAIN Batch 200 Loss 0.5103 Accuracy 74.3119 AUC 0.7891\n",
            "Epoch 21 TRAIN Batch 250 Loss 0.5099 Accuracy 74.3481 AUC 0.7893\n",
            "Epoch 21 TRAIN Batch 300 Loss 0.5098 Accuracy 74.3499 AUC 0.7894\n",
            "Epoch 21 TRAIN Batch 350 Loss 0.5097 Accuracy 74.3458 AUC 0.7893\n",
            "Epoch 21 TRAIN Batch 400 Loss 0.5097 Accuracy 74.3496 AUC 0.7893\n",
            "Epoch 21 TRAIN Batch 450 Loss 0.5096 Accuracy 74.3554 AUC 0.7893\n",
            "Epoch 21 TRAIN Batch 500 Loss 0.5097 Accuracy 74.3495 AUC 0.7892\n",
            "Epoch 21 TRAIN Batch 550 Loss 0.5097 Accuracy 74.3430 AUC 0.7893\n",
            "Epoch 21 TRAIN Batch 600 Loss 0.5098 Accuracy 74.3343 AUC 0.7893\n",
            "Epoch 21 TRAIN Batch 650 Loss 0.5098 Accuracy 74.3348 AUC 0.7893\n",
            "Epoch 21 TRAIN Batch 700 Loss 0.5098 Accuracy 74.3320 AUC 0.7894\n",
            "Epoch 21 TRAIN Batch 750 Loss 0.5098 Accuracy 74.3301 AUC 0.7894\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "31-12 13:06 root         INFO     Epoch TRAIN 21 Loss 0.5097 Accuracy 74.3356 AUC 0.7894\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time taken for 1 epoch: 196.58749270439148 secs\n",
            "\n",
            "Epoch 22 TRAIN Batch 0 Loss 0.5108 Accuracy 74.3803 AUC 0.7912\n",
            "Epoch 22 TRAIN Batch 50 Loss 0.5084 Accuracy 74.3346 AUC 0.7901\n",
            "Epoch 22 TRAIN Batch 100 Loss 0.5089 Accuracy 74.3511 AUC 0.7900\n",
            "Epoch 22 TRAIN Batch 150 Loss 0.5093 Accuracy 74.3254 AUC 0.7900\n",
            "Epoch 22 TRAIN Batch 200 Loss 0.5089 Accuracy 74.3660 AUC 0.7901\n",
            "Epoch 22 TRAIN Batch 250 Loss 0.5092 Accuracy 74.3480 AUC 0.7898\n",
            "Epoch 22 TRAIN Batch 300 Loss 0.5090 Accuracy 74.3601 AUC 0.7900\n",
            "Epoch 22 TRAIN Batch 350 Loss 0.5092 Accuracy 74.3539 AUC 0.7899\n",
            "Epoch 22 TRAIN Batch 400 Loss 0.5090 Accuracy 74.3723 AUC 0.7900\n",
            "Epoch 22 TRAIN Batch 450 Loss 0.5090 Accuracy 74.3680 AUC 0.7900\n",
            "Epoch 22 TRAIN Batch 500 Loss 0.5089 Accuracy 74.3676 AUC 0.7901\n",
            "Epoch 22 TRAIN Batch 550 Loss 0.5089 Accuracy 74.3723 AUC 0.7901\n",
            "Epoch 22 TRAIN Batch 600 Loss 0.5089 Accuracy 74.3758 AUC 0.7902\n",
            "Epoch 22 TRAIN Batch 650 Loss 0.5089 Accuracy 74.3767 AUC 0.7902\n",
            "Epoch 22 TRAIN Batch 700 Loss 0.5089 Accuracy 74.3788 AUC 0.7902\n",
            "Epoch 22 TRAIN Batch 750 Loss 0.5089 Accuracy 74.3804 AUC 0.7902\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "31-12 13:09 root         INFO     Epoch TRAIN 22 Loss 0.5088 Accuracy 74.3846 AUC 0.7902\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time taken for 1 epoch: 196.36259770393372 secs\n",
            "\n",
            "Epoch 23 TRAIN Batch 0 Loss 0.4932 Accuracy 75.4487 AUC 0.7981\n",
            "Epoch 23 TRAIN Batch 50 Loss 0.5087 Accuracy 74.2842 AUC 0.7898\n",
            "Epoch 23 TRAIN Batch 100 Loss 0.5087 Accuracy 74.3199 AUC 0.7900\n",
            "Epoch 23 TRAIN Batch 150 Loss 0.5091 Accuracy 74.3136 AUC 0.7899\n",
            "Epoch 23 TRAIN Batch 200 Loss 0.5090 Accuracy 74.3247 AUC 0.7899\n",
            "Epoch 23 TRAIN Batch 250 Loss 0.5087 Accuracy 74.3561 AUC 0.7901\n",
            "Epoch 23 TRAIN Batch 300 Loss 0.5082 Accuracy 74.3916 AUC 0.7906\n",
            "Epoch 23 TRAIN Batch 350 Loss 0.5082 Accuracy 74.4000 AUC 0.7906\n",
            "Epoch 23 TRAIN Batch 400 Loss 0.5081 Accuracy 74.4123 AUC 0.7906\n",
            "Epoch 23 TRAIN Batch 450 Loss 0.5081 Accuracy 74.4155 AUC 0.7907\n",
            "Epoch 23 TRAIN Batch 500 Loss 0.5082 Accuracy 74.4066 AUC 0.7906\n",
            "Epoch 23 TRAIN Batch 550 Loss 0.5081 Accuracy 74.4202 AUC 0.7907\n",
            "Epoch 23 TRAIN Batch 600 Loss 0.5080 Accuracy 74.4285 AUC 0.7907\n",
            "Epoch 23 TRAIN Batch 650 Loss 0.5079 Accuracy 74.4343 AUC 0.7908\n",
            "Epoch 23 TRAIN Batch 700 Loss 0.5080 Accuracy 74.4283 AUC 0.7908\n",
            "Epoch 23 TRAIN Batch 750 Loss 0.5079 Accuracy 74.4413 AUC 0.7909\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "31-12 13:12 root         INFO     Epoch TRAIN 23 Loss 0.5078 Accuracy 74.4438 AUC 0.7909\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time taken for 1 epoch: 195.65279746055603 secs\n",
            "\n",
            "Epoch 24 TRAIN Batch 0 Loss 0.5132 Accuracy 74.2969 AUC 0.7892\n",
            "Epoch 24 TRAIN Batch 50 Loss 0.5087 Accuracy 74.3644 AUC 0.7898\n",
            "Epoch 24 TRAIN Batch 100 Loss 0.5078 Accuracy 74.4266 AUC 0.7902\n",
            "Epoch 24 TRAIN Batch 150 Loss 0.5076 Accuracy 74.4452 AUC 0.7910\n",
            "Epoch 24 TRAIN Batch 200 Loss 0.5077 Accuracy 74.4439 AUC 0.7909\n",
            "Epoch 24 TRAIN Batch 250 Loss 0.5077 Accuracy 74.4459 AUC 0.7909\n",
            "Epoch 24 TRAIN Batch 300 Loss 0.5075 Accuracy 74.4538 AUC 0.7911\n",
            "Epoch 24 TRAIN Batch 350 Loss 0.5072 Accuracy 74.4669 AUC 0.7914\n",
            "Epoch 24 TRAIN Batch 400 Loss 0.5074 Accuracy 74.4557 AUC 0.7912\n",
            "Epoch 24 TRAIN Batch 450 Loss 0.5075 Accuracy 74.4527 AUC 0.7912\n",
            "Epoch 24 TRAIN Batch 500 Loss 0.5076 Accuracy 74.4405 AUC 0.7912\n",
            "Epoch 24 TRAIN Batch 550 Loss 0.5075 Accuracy 74.4515 AUC 0.7913\n",
            "Epoch 24 TRAIN Batch 600 Loss 0.5074 Accuracy 74.4572 AUC 0.7913\n",
            "Epoch 24 TRAIN Batch 650 Loss 0.5073 Accuracy 74.4693 AUC 0.7913\n",
            "Epoch 24 TRAIN Batch 700 Loss 0.5073 Accuracy 74.4685 AUC 0.7914\n",
            "Epoch 24 TRAIN Batch 750 Loss 0.5072 Accuracy 74.4731 AUC 0.7915\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "31-12 13:16 root         INFO     Epoch TRAIN 24 Loss 0.5071 Accuracy 74.4795 AUC 0.7916\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time taken for 1 epoch: 195.82401061058044 secs\n",
            "\n",
            "Epoch 25 TRAIN Batch 0 Loss 0.5016 Accuracy 74.9958 AUC 0.7918\n",
            "Epoch 25 TRAIN Batch 50 Loss 0.5076 Accuracy 74.4340 AUC 0.7928\n",
            "Epoch 25 TRAIN Batch 100 Loss 0.5073 Accuracy 74.4502 AUC 0.7925\n",
            "Epoch 25 TRAIN Batch 150 Loss 0.5077 Accuracy 74.4342 AUC 0.7922\n",
            "Epoch 25 TRAIN Batch 200 Loss 0.5076 Accuracy 74.4549 AUC 0.7918\n",
            "Epoch 25 TRAIN Batch 250 Loss 0.5075 Accuracy 74.4572 AUC 0.7919\n",
            "Epoch 25 TRAIN Batch 300 Loss 0.5072 Accuracy 74.4721 AUC 0.7919\n",
            "Epoch 25 TRAIN Batch 350 Loss 0.5073 Accuracy 74.4600 AUC 0.7918\n",
            "Epoch 25 TRAIN Batch 400 Loss 0.5073 Accuracy 74.4639 AUC 0.7918\n",
            "Epoch 25 TRAIN Batch 450 Loss 0.5072 Accuracy 74.4719 AUC 0.7918\n",
            "Epoch 25 TRAIN Batch 500 Loss 0.5072 Accuracy 74.4762 AUC 0.7918\n",
            "Epoch 25 TRAIN Batch 550 Loss 0.5070 Accuracy 74.4848 AUC 0.7918\n",
            "Epoch 25 TRAIN Batch 600 Loss 0.5071 Accuracy 74.4779 AUC 0.7918\n",
            "Epoch 25 TRAIN Batch 650 Loss 0.5071 Accuracy 74.4799 AUC 0.7918\n",
            "Epoch 25 TRAIN Batch 700 Loss 0.5071 Accuracy 74.4772 AUC 0.7918\n",
            "Epoch 25 TRAIN Batch 750 Loss 0.5072 Accuracy 74.4684 AUC 0.7918\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "31-12 13:19 root         INFO     Epoch TRAIN 25 Loss 0.5072 Accuracy 74.4674 AUC 0.7918\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 25 VAL Batch 0 Loss 0.5022 Accuracy 74.9048 AUC 0.8018\n",
            "Epoch 25 VAL Batch 50 Loss 0.5042 Accuracy 74.7234 AUC 0.7939\n",
            "Epoch 25 VAL Batch 100 Loss 0.5046 Accuracy 74.6935 AUC 0.7937\n",
            "Epoch 25 VAL Batch 150 Loss 0.5042 Accuracy 74.7171 AUC 0.7934\n",
            "Epoch 25 VAL Batch 200 Loss 0.5045 Accuracy 74.6918 AUC 0.7931\n",
            "Epoch 25 VAL Batch 250 Loss 0.5045 Accuracy 74.7063 AUC 0.7932\n",
            "Epoch 25 VAL Batch 300 Loss 0.5047 Accuracy 74.6941 AUC 0.7930\n",
            "Epoch 25 VAL Batch 350 Loss 0.5049 Accuracy 74.6816 AUC 0.7929\n",
            "Epoch 25 VAL Batch 400 Loss 0.5051 Accuracy 74.6542 AUC 0.7928\n",
            "Epoch 25 VAL Batch 450 Loss 0.5053 Accuracy 74.6384 AUC 0.7928\n",
            "Epoch 25 VAL Batch 500 Loss 0.5054 Accuracy 74.6341 AUC 0.7927\n",
            "Epoch 25 VAL Batch 550 Loss 0.5054 Accuracy 74.6401 AUC 0.7926\n",
            "Epoch 25 VAL Batch 600 Loss 0.5053 Accuracy 74.6475 AUC 0.7927\n",
            "Epoch 25 VAL Batch 650 Loss 0.5054 Accuracy 74.6451 AUC 0.7927\n",
            "Epoch 25 VAL Batch 700 Loss 0.5053 Accuracy 74.6470 AUC 0.7927\n",
            "Epoch 25 VAL Batch 750 Loss 0.5053 Accuracy 74.6470 AUC 0.7927\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "31-12 13:19 root         INFO     Epoch VAL 25 Loss 0.5053 Accuracy 74.6427 AUC 0.7927\n",
            "31-12 13:19 root         INFO     Saving checkpoint for epoch 25 at 31-Dec-riiid-3/checkpoints/ckpt-5\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time taken for 1 epoch: 217.63783931732178 secs\n",
            "\n",
            "Epoch 26 TRAIN Batch 0 Loss 0.5231 Accuracy 73.2428 AUC 0.7807\n",
            "Epoch 26 TRAIN Batch 50 Loss 0.5081 Accuracy 74.3801 AUC 0.7909\n",
            "Epoch 26 TRAIN Batch 100 Loss 0.5066 Accuracy 74.4790 AUC 0.7923\n",
            "Epoch 26 TRAIN Batch 150 Loss 0.5071 Accuracy 74.4724 AUC 0.7921\n",
            "Epoch 26 TRAIN Batch 200 Loss 0.5073 Accuracy 74.4488 AUC 0.7918\n",
            "Epoch 26 TRAIN Batch 250 Loss 0.5068 Accuracy 74.4907 AUC 0.7922\n",
            "Epoch 26 TRAIN Batch 300 Loss 0.5066 Accuracy 74.4991 AUC 0.7922\n",
            "Epoch 26 TRAIN Batch 350 Loss 0.5066 Accuracy 74.5116 AUC 0.7921\n",
            "Epoch 26 TRAIN Batch 400 Loss 0.5066 Accuracy 74.5110 AUC 0.7921\n",
            "Epoch 26 TRAIN Batch 450 Loss 0.5066 Accuracy 74.5105 AUC 0.7921\n",
            "Epoch 26 TRAIN Batch 500 Loss 0.5065 Accuracy 74.5134 AUC 0.7920\n",
            "Epoch 26 TRAIN Batch 550 Loss 0.5065 Accuracy 74.5109 AUC 0.7920\n",
            "Epoch 26 TRAIN Batch 600 Loss 0.5066 Accuracy 74.5027 AUC 0.7920\n",
            "Epoch 26 TRAIN Batch 650 Loss 0.5065 Accuracy 74.5035 AUC 0.7920\n",
            "Epoch 26 TRAIN Batch 700 Loss 0.5064 Accuracy 74.5142 AUC 0.7921\n",
            "Epoch 26 TRAIN Batch 750 Loss 0.5064 Accuracy 74.5145 AUC 0.7921\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "31-12 13:22 root         INFO     Epoch TRAIN 26 Loss 0.5065 Accuracy 74.5039 AUC 0.7921\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time taken for 1 epoch: 195.75177359580994 secs\n",
            "\n",
            "Epoch 27 TRAIN Batch 0 Loss 0.4976 Accuracy 74.7908 AUC 0.7947\n",
            "Epoch 27 TRAIN Batch 50 Loss 0.5049 Accuracy 74.6675 AUC 0.7927\n",
            "Epoch 27 TRAIN Batch 100 Loss 0.5059 Accuracy 74.5499 AUC 0.7925\n",
            "Epoch 27 TRAIN Batch 150 Loss 0.5054 Accuracy 74.6015 AUC 0.7929\n",
            "Epoch 27 TRAIN Batch 200 Loss 0.5054 Accuracy 74.5953 AUC 0.7929\n",
            "Epoch 27 TRAIN Batch 250 Loss 0.5053 Accuracy 74.6075 AUC 0.7930\n",
            "Epoch 27 TRAIN Batch 300 Loss 0.5053 Accuracy 74.6054 AUC 0.7929\n",
            "Epoch 27 TRAIN Batch 350 Loss 0.5051 Accuracy 74.6126 AUC 0.7930\n",
            "Epoch 27 TRAIN Batch 400 Loss 0.5051 Accuracy 74.6167 AUC 0.7930\n",
            "Epoch 27 TRAIN Batch 450 Loss 0.5052 Accuracy 74.6091 AUC 0.7930\n",
            "Epoch 27 TRAIN Batch 500 Loss 0.5053 Accuracy 74.6044 AUC 0.7930\n",
            "Epoch 27 TRAIN Batch 550 Loss 0.5054 Accuracy 74.6014 AUC 0.7929\n",
            "Epoch 27 TRAIN Batch 600 Loss 0.5056 Accuracy 74.5925 AUC 0.7929\n",
            "Epoch 27 TRAIN Batch 650 Loss 0.5055 Accuracy 74.5915 AUC 0.7929\n",
            "Epoch 27 TRAIN Batch 700 Loss 0.5056 Accuracy 74.5886 AUC 0.7930\n",
            "Epoch 27 TRAIN Batch 750 Loss 0.5056 Accuracy 74.5845 AUC 0.7929\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "31-12 13:26 root         INFO     Epoch TRAIN 27 Loss 0.5057 Accuracy 74.5782 AUC 0.7929\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time taken for 1 epoch: 195.52091193199158 secs\n",
            "\n",
            "Epoch 28 TRAIN Batch 0 Loss 0.5083 Accuracy 74.5389 AUC 0.7896\n",
            "Epoch 28 TRAIN Batch 50 Loss 0.5066 Accuracy 74.4924 AUC 0.7911\n",
            "Epoch 28 TRAIN Batch 100 Loss 0.5067 Accuracy 74.4957 AUC 0.7919\n",
            "Epoch 28 TRAIN Batch 150 Loss 0.5066 Accuracy 74.4879 AUC 0.7919\n",
            "Epoch 28 TRAIN Batch 200 Loss 0.5062 Accuracy 74.5291 AUC 0.7923\n",
            "Epoch 28 TRAIN Batch 250 Loss 0.5064 Accuracy 74.5085 AUC 0.7923\n",
            "Epoch 28 TRAIN Batch 300 Loss 0.5063 Accuracy 74.5353 AUC 0.7925\n",
            "Epoch 28 TRAIN Batch 350 Loss 0.5062 Accuracy 74.5473 AUC 0.7927\n",
            "Epoch 28 TRAIN Batch 400 Loss 0.5060 Accuracy 74.5569 AUC 0.7929\n",
            "Epoch 28 TRAIN Batch 450 Loss 0.5059 Accuracy 74.5614 AUC 0.7930\n",
            "Epoch 28 TRAIN Batch 500 Loss 0.5056 Accuracy 74.5790 AUC 0.7931\n",
            "Epoch 28 TRAIN Batch 550 Loss 0.5058 Accuracy 74.5691 AUC 0.7929\n",
            "Epoch 28 TRAIN Batch 600 Loss 0.5059 Accuracy 74.5613 AUC 0.7929\n",
            "Epoch 28 TRAIN Batch 650 Loss 0.5060 Accuracy 74.5505 AUC 0.7928\n",
            "Epoch 28 TRAIN Batch 700 Loss 0.5059 Accuracy 74.5537 AUC 0.7929\n",
            "Epoch 28 TRAIN Batch 750 Loss 0.5059 Accuracy 74.5532 AUC 0.7929\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "31-12 13:29 root         INFO     Epoch TRAIN 28 Loss 0.5059 Accuracy 74.5533 AUC 0.7929\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time taken for 1 epoch: 196.24184584617615 secs\n",
            "\n",
            "Epoch 29 TRAIN Batch 0 Loss 0.4988 Accuracy 75.2403 AUC 0.7978\n",
            "Epoch 29 TRAIN Batch 50 Loss 0.5057 Accuracy 74.5517 AUC 0.7940\n",
            "Epoch 29 TRAIN Batch 100 Loss 0.5051 Accuracy 74.5727 AUC 0.7941\n",
            "Epoch 29 TRAIN Batch 150 Loss 0.5061 Accuracy 74.5059 AUC 0.7933\n",
            "Epoch 29 TRAIN Batch 200 Loss 0.5060 Accuracy 74.5226 AUC 0.7934\n",
            "Epoch 29 TRAIN Batch 250 Loss 0.5062 Accuracy 74.5106 AUC 0.7932\n",
            "Epoch 29 TRAIN Batch 300 Loss 0.5062 Accuracy 74.5122 AUC 0.7932\n",
            "Epoch 29 TRAIN Batch 350 Loss 0.5061 Accuracy 74.5241 AUC 0.7933\n",
            "Epoch 29 TRAIN Batch 400 Loss 0.5060 Accuracy 74.5367 AUC 0.7932\n",
            "Epoch 29 TRAIN Batch 450 Loss 0.5059 Accuracy 74.5386 AUC 0.7932\n",
            "Epoch 29 TRAIN Batch 500 Loss 0.5061 Accuracy 74.5283 AUC 0.7932\n",
            "Epoch 29 TRAIN Batch 550 Loss 0.5059 Accuracy 74.5395 AUC 0.7933\n",
            "Epoch 29 TRAIN Batch 600 Loss 0.5057 Accuracy 74.5536 AUC 0.7934\n",
            "Epoch 29 TRAIN Batch 650 Loss 0.5059 Accuracy 74.5381 AUC 0.7932\n",
            "Epoch 29 TRAIN Batch 700 Loss 0.5060 Accuracy 74.5316 AUC 0.7931\n",
            "Epoch 29 TRAIN Batch 750 Loss 0.5058 Accuracy 74.5475 AUC 0.7932\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "31-12 13:32 root         INFO     Epoch TRAIN 29 Loss 0.5057 Accuracy 74.5501 AUC 0.7932\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time taken for 1 epoch: 196.11861109733582 secs\n",
            "\n",
            "Epoch 30 TRAIN Batch 0 Loss 0.5214 Accuracy 73.6856 AUC 0.7840\n",
            "Epoch 30 TRAIN Batch 50 Loss 0.5059 Accuracy 74.5546 AUC 0.7933\n",
            "Epoch 30 TRAIN Batch 100 Loss 0.5059 Accuracy 74.5498 AUC 0.7928\n",
            "Epoch 30 TRAIN Batch 150 Loss 0.5060 Accuracy 74.5416 AUC 0.7929\n",
            "Epoch 30 TRAIN Batch 200 Loss 0.5059 Accuracy 74.5456 AUC 0.7927\n",
            "Epoch 30 TRAIN Batch 250 Loss 0.5060 Accuracy 74.5475 AUC 0.7927\n",
            "Epoch 30 TRAIN Batch 300 Loss 0.5058 Accuracy 74.5603 AUC 0.7927\n",
            "Epoch 30 TRAIN Batch 350 Loss 0.5058 Accuracy 74.5602 AUC 0.7929\n",
            "Epoch 30 TRAIN Batch 400 Loss 0.5060 Accuracy 74.5484 AUC 0.7929\n",
            "Epoch 30 TRAIN Batch 450 Loss 0.5060 Accuracy 74.5478 AUC 0.7929\n",
            "Epoch 30 TRAIN Batch 500 Loss 0.5061 Accuracy 74.5329 AUC 0.7930\n",
            "Epoch 30 TRAIN Batch 550 Loss 0.5059 Accuracy 74.5411 AUC 0.7931\n",
            "Epoch 30 TRAIN Batch 600 Loss 0.5058 Accuracy 74.5532 AUC 0.7932\n",
            "Epoch 30 TRAIN Batch 650 Loss 0.5057 Accuracy 74.5601 AUC 0.7932\n",
            "Epoch 30 TRAIN Batch 700 Loss 0.5058 Accuracy 74.5499 AUC 0.7931\n",
            "Epoch 30 TRAIN Batch 750 Loss 0.5056 Accuracy 74.5643 AUC 0.7932\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "31-12 13:36 root         INFO     Epoch TRAIN 30 Loss 0.5057 Accuracy 74.5620 AUC 0.7932\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 30 VAL Batch 0 Loss 0.5005 Accuracy 74.8054 AUC 0.8036\n",
            "Epoch 30 VAL Batch 50 Loss 0.5022 Accuracy 74.7597 AUC 0.7956\n",
            "Epoch 30 VAL Batch 100 Loss 0.5024 Accuracy 74.7674 AUC 0.7954\n",
            "Epoch 30 VAL Batch 150 Loss 0.5021 Accuracy 74.7836 AUC 0.7951\n",
            "Epoch 30 VAL Batch 200 Loss 0.5025 Accuracy 74.7567 AUC 0.7949\n",
            "Epoch 30 VAL Batch 250 Loss 0.5024 Accuracy 74.7719 AUC 0.7950\n",
            "Epoch 30 VAL Batch 300 Loss 0.5026 Accuracy 74.7603 AUC 0.7948\n",
            "Epoch 30 VAL Batch 350 Loss 0.5028 Accuracy 74.7483 AUC 0.7947\n",
            "Epoch 30 VAL Batch 400 Loss 0.5030 Accuracy 74.7290 AUC 0.7946\n",
            "Epoch 30 VAL Batch 450 Loss 0.5032 Accuracy 74.7117 AUC 0.7946\n",
            "Epoch 30 VAL Batch 500 Loss 0.5033 Accuracy 74.7051 AUC 0.7944\n",
            "Epoch 30 VAL Batch 550 Loss 0.5033 Accuracy 74.7063 AUC 0.7944\n",
            "Epoch 30 VAL Batch 600 Loss 0.5032 Accuracy 74.7112 AUC 0.7945\n",
            "Epoch 30 VAL Batch 650 Loss 0.5032 Accuracy 74.7122 AUC 0.7945\n",
            "Epoch 30 VAL Batch 700 Loss 0.5032 Accuracy 74.7140 AUC 0.7945\n",
            "Epoch 30 VAL Batch 750 Loss 0.5031 Accuracy 74.7147 AUC 0.7945\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "31-12 13:36 root         INFO     Epoch VAL 30 Loss 0.5031 Accuracy 74.7106 AUC 0.7945\n",
            "31-12 13:36 root         INFO     Saving checkpoint for epoch 30 at 31-Dec-riiid-3/checkpoints/ckpt-6\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time taken for 1 epoch: 218.28388738632202 secs\n",
            "\n",
            "Epoch 31 TRAIN Batch 0 Loss 0.5003 Accuracy 75.1393 AUC 0.7974\n",
            "Epoch 31 TRAIN Batch 50 Loss 0.5058 Accuracy 74.5085 AUC 0.7927\n",
            "Epoch 31 TRAIN Batch 100 Loss 0.5044 Accuracy 74.6450 AUC 0.7937\n",
            "Epoch 31 TRAIN Batch 150 Loss 0.5052 Accuracy 74.5898 AUC 0.7938\n",
            "Epoch 31 TRAIN Batch 200 Loss 0.5049 Accuracy 74.6158 AUC 0.7940\n",
            "Epoch 31 TRAIN Batch 250 Loss 0.5044 Accuracy 74.6376 AUC 0.7940\n",
            "Epoch 31 TRAIN Batch 300 Loss 0.5043 Accuracy 74.6460 AUC 0.7940\n",
            "Epoch 31 TRAIN Batch 350 Loss 0.5045 Accuracy 74.6398 AUC 0.7939\n",
            "Epoch 31 TRAIN Batch 400 Loss 0.5047 Accuracy 74.6323 AUC 0.7939\n",
            "Epoch 31 TRAIN Batch 450 Loss 0.5047 Accuracy 74.6206 AUC 0.7938\n",
            "Epoch 31 TRAIN Batch 500 Loss 0.5049 Accuracy 74.6025 AUC 0.7938\n",
            "Epoch 31 TRAIN Batch 550 Loss 0.5048 Accuracy 74.6054 AUC 0.7938\n",
            "Epoch 31 TRAIN Batch 600 Loss 0.5050 Accuracy 74.5969 AUC 0.7938\n",
            "Epoch 31 TRAIN Batch 650 Loss 0.5049 Accuracy 74.6007 AUC 0.7939\n",
            "Epoch 31 TRAIN Batch 700 Loss 0.5050 Accuracy 74.5926 AUC 0.7938\n",
            "Epoch 31 TRAIN Batch 750 Loss 0.5051 Accuracy 74.5824 AUC 0.7937\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "31-12 13:39 root         INFO     Epoch TRAIN 31 Loss 0.5052 Accuracy 74.5775 AUC 0.7937\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time taken for 1 epoch: 195.99514865875244 secs\n",
            "\n",
            "Epoch 32 TRAIN Batch 0 Loss 0.5058 Accuracy 74.1250 AUC 0.7962\n",
            "Epoch 32 TRAIN Batch 50 Loss 0.5046 Accuracy 74.5436 AUC 0.7937\n",
            "Epoch 32 TRAIN Batch 100 Loss 0.5051 Accuracy 74.5491 AUC 0.7934\n",
            "Epoch 32 TRAIN Batch 150 Loss 0.5042 Accuracy 74.6205 AUC 0.7940\n",
            "Epoch 32 TRAIN Batch 200 Loss 0.5038 Accuracy 74.6511 AUC 0.7944\n",
            "Epoch 32 TRAIN Batch 250 Loss 0.5042 Accuracy 74.6253 AUC 0.7942\n",
            "Epoch 32 TRAIN Batch 300 Loss 0.5045 Accuracy 74.6131 AUC 0.7941\n",
            "Epoch 32 TRAIN Batch 350 Loss 0.5046 Accuracy 74.6056 AUC 0.7941\n",
            "Epoch 32 TRAIN Batch 400 Loss 0.5050 Accuracy 74.5846 AUC 0.7939\n",
            "Epoch 32 TRAIN Batch 450 Loss 0.5050 Accuracy 74.5893 AUC 0.7938\n",
            "Epoch 32 TRAIN Batch 500 Loss 0.5047 Accuracy 74.6087 AUC 0.7940\n",
            "Epoch 32 TRAIN Batch 550 Loss 0.5047 Accuracy 74.6089 AUC 0.7940\n",
            "Epoch 32 TRAIN Batch 600 Loss 0.5045 Accuracy 74.6195 AUC 0.7940\n",
            "Epoch 32 TRAIN Batch 650 Loss 0.5047 Accuracy 74.6096 AUC 0.7939\n",
            "Epoch 32 TRAIN Batch 700 Loss 0.5046 Accuracy 74.6111 AUC 0.7940\n",
            "Epoch 32 TRAIN Batch 750 Loss 0.5047 Accuracy 74.6065 AUC 0.7939\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "31-12 13:42 root         INFO     Epoch TRAIN 32 Loss 0.5047 Accuracy 74.6028 AUC 0.7939\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time taken for 1 epoch: 196.65276765823364 secs\n",
            "\n",
            "Epoch 33 TRAIN Batch 0 Loss 0.5033 Accuracy 74.6952 AUC 0.7942\n",
            "Epoch 33 TRAIN Batch 50 Loss 0.5062 Accuracy 74.5590 AUC 0.7922\n",
            "Epoch 33 TRAIN Batch 100 Loss 0.5053 Accuracy 74.5574 AUC 0.7933\n",
            "Epoch 33 TRAIN Batch 150 Loss 0.5047 Accuracy 74.5861 AUC 0.7937\n",
            "Epoch 33 TRAIN Batch 200 Loss 0.5048 Accuracy 74.5988 AUC 0.7937\n",
            "Epoch 33 TRAIN Batch 250 Loss 0.5050 Accuracy 74.5780 AUC 0.7937\n",
            "Epoch 33 TRAIN Batch 300 Loss 0.5050 Accuracy 74.5818 AUC 0.7939\n",
            "Epoch 33 TRAIN Batch 350 Loss 0.5050 Accuracy 74.5866 AUC 0.7940\n",
            "Epoch 33 TRAIN Batch 400 Loss 0.5051 Accuracy 74.5798 AUC 0.7939\n",
            "Epoch 33 TRAIN Batch 450 Loss 0.5051 Accuracy 74.5859 AUC 0.7939\n",
            "Epoch 33 TRAIN Batch 500 Loss 0.5050 Accuracy 74.5893 AUC 0.7940\n",
            "Epoch 33 TRAIN Batch 550 Loss 0.5051 Accuracy 74.5869 AUC 0.7940\n",
            "Epoch 33 TRAIN Batch 600 Loss 0.5050 Accuracy 74.5908 AUC 0.7941\n",
            "Epoch 33 TRAIN Batch 650 Loss 0.5049 Accuracy 74.6091 AUC 0.7942\n",
            "Epoch 33 TRAIN Batch 700 Loss 0.5049 Accuracy 74.6090 AUC 0.7942\n",
            "Epoch 33 TRAIN Batch 750 Loss 0.5049 Accuracy 74.6007 AUC 0.7942\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "31-12 13:46 root         INFO     Epoch TRAIN 33 Loss 0.5049 Accuracy 74.6010 AUC 0.7941\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time taken for 1 epoch: 196.8093011379242 secs\n",
            "\n",
            "Epoch 34 TRAIN Batch 0 Loss 0.4999 Accuracy 74.8368 AUC 0.8031\n",
            "Epoch 34 TRAIN Batch 50 Loss 0.5047 Accuracy 74.6313 AUC 0.7944\n",
            "Epoch 34 TRAIN Batch 100 Loss 0.5044 Accuracy 74.6135 AUC 0.7947\n",
            "Epoch 34 TRAIN Batch 150 Loss 0.5047 Accuracy 74.5953 AUC 0.7945\n",
            "Epoch 34 TRAIN Batch 200 Loss 0.5045 Accuracy 74.6069 AUC 0.7945\n",
            "Epoch 34 TRAIN Batch 250 Loss 0.5044 Accuracy 74.6144 AUC 0.7945\n",
            "Epoch 34 TRAIN Batch 300 Loss 0.5044 Accuracy 74.6197 AUC 0.7947\n",
            "Epoch 34 TRAIN Batch 350 Loss 0.5043 Accuracy 74.6277 AUC 0.7947\n",
            "Epoch 34 TRAIN Batch 400 Loss 0.5042 Accuracy 74.6390 AUC 0.7948\n",
            "Epoch 34 TRAIN Batch 450 Loss 0.5043 Accuracy 74.6284 AUC 0.7948\n",
            "Epoch 34 TRAIN Batch 500 Loss 0.5043 Accuracy 74.6283 AUC 0.7947\n",
            "Epoch 34 TRAIN Batch 550 Loss 0.5044 Accuracy 74.6138 AUC 0.7947\n",
            "Epoch 34 TRAIN Batch 600 Loss 0.5045 Accuracy 74.6043 AUC 0.7947\n",
            "Epoch 34 TRAIN Batch 650 Loss 0.5045 Accuracy 74.6032 AUC 0.7947\n",
            "Epoch 34 TRAIN Batch 700 Loss 0.5045 Accuracy 74.6070 AUC 0.7947\n",
            "Epoch 34 TRAIN Batch 750 Loss 0.5046 Accuracy 74.6025 AUC 0.7946\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "31-12 13:49 root         INFO     Epoch TRAIN 34 Loss 0.5047 Accuracy 74.5997 AUC 0.7947\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time taken for 1 epoch: 195.74109840393066 secs\n",
            "\n",
            "Epoch 35 TRAIN Batch 0 Loss 0.5102 Accuracy 74.4782 AUC 0.7923\n",
            "Epoch 35 TRAIN Batch 50 Loss 0.5042 Accuracy 74.7075 AUC 0.7938\n",
            "Epoch 35 TRAIN Batch 100 Loss 0.5048 Accuracy 74.6188 AUC 0.7941\n",
            "Epoch 35 TRAIN Batch 150 Loss 0.5054 Accuracy 74.5635 AUC 0.7941\n",
            "Epoch 35 TRAIN Batch 200 Loss 0.5045 Accuracy 74.6250 AUC 0.7948\n",
            "Epoch 35 TRAIN Batch 250 Loss 0.5042 Accuracy 74.6471 AUC 0.7949\n",
            "Epoch 35 TRAIN Batch 300 Loss 0.5041 Accuracy 74.6470 AUC 0.7950\n",
            "Epoch 35 TRAIN Batch 350 Loss 0.5041 Accuracy 74.6533 AUC 0.7950\n",
            "Epoch 35 TRAIN Batch 400 Loss 0.5041 Accuracy 74.6561 AUC 0.7948\n",
            "Epoch 35 TRAIN Batch 450 Loss 0.5043 Accuracy 74.6373 AUC 0.7948\n",
            "Epoch 35 TRAIN Batch 500 Loss 0.5044 Accuracy 74.6347 AUC 0.7947\n",
            "Epoch 35 TRAIN Batch 550 Loss 0.5044 Accuracy 74.6292 AUC 0.7947\n",
            "Epoch 35 TRAIN Batch 600 Loss 0.5043 Accuracy 74.6400 AUC 0.7947\n",
            "Epoch 35 TRAIN Batch 650 Loss 0.5042 Accuracy 74.6499 AUC 0.7949\n",
            "Epoch 35 TRAIN Batch 700 Loss 0.5042 Accuracy 74.6419 AUC 0.7948\n",
            "Epoch 35 TRAIN Batch 750 Loss 0.5043 Accuracy 74.6404 AUC 0.7948\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "31-12 13:52 root         INFO     Epoch TRAIN 35 Loss 0.5042 Accuracy 74.6440 AUC 0.7948\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 35 VAL Batch 0 Loss 0.4996 Accuracy 74.6729 AUC 0.8040\n",
            "Epoch 35 VAL Batch 50 Loss 0.5020 Accuracy 74.8479 AUC 0.7963\n",
            "Epoch 35 VAL Batch 100 Loss 0.5023 Accuracy 74.8208 AUC 0.7961\n",
            "Epoch 35 VAL Batch 150 Loss 0.5018 Accuracy 74.8473 AUC 0.7959\n",
            "Epoch 35 VAL Batch 200 Loss 0.5022 Accuracy 74.8249 AUC 0.7956\n",
            "Epoch 35 VAL Batch 250 Loss 0.5021 Accuracy 74.8440 AUC 0.7958\n",
            "Epoch 35 VAL Batch 300 Loss 0.5024 Accuracy 74.8315 AUC 0.7956\n",
            "Epoch 35 VAL Batch 350 Loss 0.5025 Accuracy 74.8166 AUC 0.7955\n",
            "Epoch 35 VAL Batch 400 Loss 0.5028 Accuracy 74.7955 AUC 0.7953\n",
            "Epoch 35 VAL Batch 450 Loss 0.5030 Accuracy 74.7808 AUC 0.7953\n",
            "Epoch 35 VAL Batch 500 Loss 0.5031 Accuracy 74.7703 AUC 0.7952\n",
            "Epoch 35 VAL Batch 550 Loss 0.5031 Accuracy 74.7696 AUC 0.7951\n",
            "Epoch 35 VAL Batch 600 Loss 0.5030 Accuracy 74.7751 AUC 0.7952\n",
            "Epoch 35 VAL Batch 650 Loss 0.5030 Accuracy 74.7773 AUC 0.7952\n",
            "Epoch 35 VAL Batch 700 Loss 0.5030 Accuracy 74.7799 AUC 0.7952\n",
            "Epoch 35 VAL Batch 750 Loss 0.5030 Accuracy 74.7805 AUC 0.7952\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "31-12 13:53 root         INFO     Epoch VAL 35 Loss 0.5030 Accuracy 74.7768 AUC 0.7952\n",
            "31-12 13:53 root         INFO     Saving checkpoint for epoch 35 at 31-Dec-riiid-3/checkpoints/ckpt-7\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time taken for 1 epoch: 218.69503092765808 secs\n",
            "\n",
            "Epoch 36 TRAIN Batch 0 Loss 0.5067 Accuracy 74.5782 AUC 0.7912\n",
            "Epoch 36 TRAIN Batch 50 Loss 0.5055 Accuracy 74.6075 AUC 0.7940\n",
            "Epoch 36 TRAIN Batch 100 Loss 0.5042 Accuracy 74.6599 AUC 0.7945\n",
            "Epoch 36 TRAIN Batch 150 Loss 0.5042 Accuracy 74.6408 AUC 0.7949\n",
            "Epoch 36 TRAIN Batch 200 Loss 0.5038 Accuracy 74.6819 AUC 0.7951\n",
            "Epoch 36 TRAIN Batch 250 Loss 0.5039 Accuracy 74.6717 AUC 0.7951\n",
            "Epoch 36 TRAIN Batch 300 Loss 0.5038 Accuracy 74.6808 AUC 0.7952\n",
            "Epoch 36 TRAIN Batch 350 Loss 0.5039 Accuracy 74.6631 AUC 0.7950\n",
            "Epoch 36 TRAIN Batch 400 Loss 0.5040 Accuracy 74.6530 AUC 0.7949\n",
            "Epoch 36 TRAIN Batch 450 Loss 0.5038 Accuracy 74.6644 AUC 0.7949\n",
            "Epoch 36 TRAIN Batch 500 Loss 0.5038 Accuracy 74.6637 AUC 0.7949\n",
            "Epoch 36 TRAIN Batch 550 Loss 0.5038 Accuracy 74.6612 AUC 0.7949\n",
            "Epoch 36 TRAIN Batch 600 Loss 0.5038 Accuracy 74.6610 AUC 0.7949\n",
            "Epoch 36 TRAIN Batch 650 Loss 0.5039 Accuracy 74.6613 AUC 0.7949\n",
            "Epoch 36 TRAIN Batch 700 Loss 0.5037 Accuracy 74.6667 AUC 0.7950\n",
            "Epoch 36 TRAIN Batch 750 Loss 0.5037 Accuracy 74.6699 AUC 0.7951\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "31-12 13:56 root         INFO     Epoch TRAIN 36 Loss 0.5037 Accuracy 74.6712 AUC 0.7951\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time taken for 1 epoch: 196.82392692565918 secs\n",
            "\n",
            "Epoch 37 TRAIN Batch 0 Loss 0.5254 Accuracy 72.8366 AUC 0.7788\n",
            "Epoch 37 TRAIN Batch 50 Loss 0.5043 Accuracy 74.5643 AUC 0.7954\n",
            "Epoch 37 TRAIN Batch 100 Loss 0.5049 Accuracy 74.5620 AUC 0.7946\n",
            "Epoch 37 TRAIN Batch 150 Loss 0.5040 Accuracy 74.6131 AUC 0.7949\n",
            "Epoch 37 TRAIN Batch 200 Loss 0.5038 Accuracy 74.6310 AUC 0.7949\n",
            "Epoch 37 TRAIN Batch 250 Loss 0.5034 Accuracy 74.6683 AUC 0.7952\n",
            "Epoch 37 TRAIN Batch 300 Loss 0.5037 Accuracy 74.6462 AUC 0.7950\n",
            "Epoch 37 TRAIN Batch 350 Loss 0.5039 Accuracy 74.6326 AUC 0.7949\n",
            "Epoch 37 TRAIN Batch 400 Loss 0.5039 Accuracy 74.6383 AUC 0.7949\n",
            "Epoch 37 TRAIN Batch 450 Loss 0.5039 Accuracy 74.6458 AUC 0.7950\n",
            "Epoch 37 TRAIN Batch 500 Loss 0.5038 Accuracy 74.6568 AUC 0.7951\n",
            "Epoch 37 TRAIN Batch 550 Loss 0.5037 Accuracy 74.6671 AUC 0.7952\n",
            "Epoch 37 TRAIN Batch 600 Loss 0.5036 Accuracy 74.6731 AUC 0.7952\n",
            "Epoch 37 TRAIN Batch 650 Loss 0.5037 Accuracy 74.6715 AUC 0.7952\n",
            "Epoch 37 TRAIN Batch 700 Loss 0.5037 Accuracy 74.6693 AUC 0.7952\n",
            "Epoch 37 TRAIN Batch 750 Loss 0.5037 Accuracy 74.6661 AUC 0.7952\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "31-12 13:59 root         INFO     Epoch TRAIN 37 Loss 0.5037 Accuracy 74.6633 AUC 0.7951\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time taken for 1 epoch: 195.8105776309967 secs\n",
            "\n",
            "Epoch 38 TRAIN Batch 0 Loss 0.4946 Accuracy 75.2419 AUC 0.7950\n",
            "Epoch 38 TRAIN Batch 50 Loss 0.5061 Accuracy 74.5112 AUC 0.7944\n",
            "Epoch 38 TRAIN Batch 100 Loss 0.5036 Accuracy 74.7001 AUC 0.7956\n",
            "Epoch 38 TRAIN Batch 150 Loss 0.5030 Accuracy 74.7421 AUC 0.7957\n",
            "Epoch 38 TRAIN Batch 200 Loss 0.5032 Accuracy 74.7037 AUC 0.7954\n",
            "Epoch 38 TRAIN Batch 250 Loss 0.5029 Accuracy 74.7332 AUC 0.7957\n",
            "Epoch 38 TRAIN Batch 300 Loss 0.5031 Accuracy 74.7149 AUC 0.7957\n",
            "Epoch 38 TRAIN Batch 350 Loss 0.5029 Accuracy 74.7200 AUC 0.7958\n",
            "Epoch 38 TRAIN Batch 400 Loss 0.5029 Accuracy 74.7233 AUC 0.7958\n",
            "Epoch 38 TRAIN Batch 450 Loss 0.5029 Accuracy 74.7261 AUC 0.7958\n",
            "Epoch 38 TRAIN Batch 500 Loss 0.5031 Accuracy 74.7084 AUC 0.7957\n",
            "Epoch 38 TRAIN Batch 550 Loss 0.5032 Accuracy 74.7051 AUC 0.7957\n",
            "Epoch 38 TRAIN Batch 600 Loss 0.5033 Accuracy 74.6951 AUC 0.7956\n",
            "Epoch 38 TRAIN Batch 650 Loss 0.5032 Accuracy 74.7052 AUC 0.7957\n",
            "Epoch 38 TRAIN Batch 700 Loss 0.5032 Accuracy 74.7020 AUC 0.7957\n",
            "Epoch 38 TRAIN Batch 750 Loss 0.5032 Accuracy 74.6967 AUC 0.7956\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "31-12 14:03 root         INFO     Epoch TRAIN 38 Loss 0.5032 Accuracy 74.6971 AUC 0.7956\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time taken for 1 epoch: 197.2874264717102 secs\n",
            "\n",
            "Epoch 39 TRAIN Batch 0 Loss 0.5140 Accuracy 73.6571 AUC 0.7886\n",
            "Epoch 39 TRAIN Batch 50 Loss 0.5022 Accuracy 74.8018 AUC 0.7968\n",
            "Epoch 39 TRAIN Batch 100 Loss 0.5032 Accuracy 74.6943 AUC 0.7960\n",
            "Epoch 39 TRAIN Batch 150 Loss 0.5030 Accuracy 74.7244 AUC 0.7961\n",
            "Epoch 39 TRAIN Batch 200 Loss 0.5035 Accuracy 74.6811 AUC 0.7960\n",
            "Epoch 39 TRAIN Batch 250 Loss 0.5035 Accuracy 74.6899 AUC 0.7961\n",
            "Epoch 39 TRAIN Batch 300 Loss 0.5032 Accuracy 74.7017 AUC 0.7962\n",
            "Epoch 39 TRAIN Batch 350 Loss 0.5031 Accuracy 74.7056 AUC 0.7962\n",
            "Epoch 39 TRAIN Batch 400 Loss 0.5030 Accuracy 74.7020 AUC 0.7960\n",
            "Epoch 39 TRAIN Batch 450 Loss 0.5031 Accuracy 74.7018 AUC 0.7960\n",
            "Epoch 39 TRAIN Batch 500 Loss 0.5032 Accuracy 74.6965 AUC 0.7959\n",
            "Epoch 39 TRAIN Batch 550 Loss 0.5033 Accuracy 74.6819 AUC 0.7958\n",
            "Epoch 39 TRAIN Batch 600 Loss 0.5035 Accuracy 74.6728 AUC 0.7957\n",
            "Epoch 39 TRAIN Batch 650 Loss 0.5035 Accuracy 74.6785 AUC 0.7957\n",
            "Epoch 39 TRAIN Batch 700 Loss 0.5034 Accuracy 74.6834 AUC 0.7957\n",
            "Epoch 39 TRAIN Batch 750 Loss 0.5034 Accuracy 74.6831 AUC 0.7957\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "31-12 14:06 root         INFO     Epoch TRAIN 39 Loss 0.5033 Accuracy 74.6907 AUC 0.7958\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time taken for 1 epoch: 197.40949845314026 secs\n",
            "\n",
            "Epoch 40 TRAIN Batch 0 Loss 0.5027 Accuracy 74.8632 AUC 0.7954\n",
            "Epoch 40 TRAIN Batch 50 Loss 0.5021 Accuracy 74.8032 AUC 0.7967\n",
            "Epoch 40 TRAIN Batch 100 Loss 0.5032 Accuracy 74.6888 AUC 0.7960\n",
            "Epoch 40 TRAIN Batch 150 Loss 0.5030 Accuracy 74.7084 AUC 0.7957\n",
            "Epoch 40 TRAIN Batch 200 Loss 0.5033 Accuracy 74.6796 AUC 0.7956\n",
            "Epoch 40 TRAIN Batch 250 Loss 0.5032 Accuracy 74.6858 AUC 0.7958\n",
            "Epoch 40 TRAIN Batch 300 Loss 0.5031 Accuracy 74.6946 AUC 0.7957\n",
            "Epoch 40 TRAIN Batch 350 Loss 0.5029 Accuracy 74.7155 AUC 0.7958\n",
            "Epoch 40 TRAIN Batch 400 Loss 0.5030 Accuracy 74.7117 AUC 0.7958\n",
            "Epoch 40 TRAIN Batch 450 Loss 0.5029 Accuracy 74.7141 AUC 0.7959\n",
            "Epoch 40 TRAIN Batch 500 Loss 0.5029 Accuracy 74.7161 AUC 0.7960\n",
            "Epoch 40 TRAIN Batch 550 Loss 0.5029 Accuracy 74.7244 AUC 0.7960\n",
            "Epoch 40 TRAIN Batch 600 Loss 0.5028 Accuracy 74.7302 AUC 0.7960\n",
            "Epoch 40 TRAIN Batch 650 Loss 0.5027 Accuracy 74.7344 AUC 0.7961\n",
            "Epoch 40 TRAIN Batch 700 Loss 0.5027 Accuracy 74.7357 AUC 0.7961\n",
            "Epoch 40 TRAIN Batch 750 Loss 0.5027 Accuracy 74.7334 AUC 0.7962\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "31-12 14:09 root         INFO     Epoch TRAIN 40 Loss 0.5027 Accuracy 74.7293 AUC 0.7961\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 40 VAL Batch 0 Loss 0.4971 Accuracy 75.0456 AUC 0.8068\n",
            "Epoch 40 VAL Batch 50 Loss 0.5003 Accuracy 74.8719 AUC 0.7975\n",
            "Epoch 40 VAL Batch 100 Loss 0.5005 Accuracy 74.8682 AUC 0.7975\n",
            "Epoch 40 VAL Batch 150 Loss 0.5001 Accuracy 74.8964 AUC 0.7972\n",
            "Epoch 40 VAL Batch 200 Loss 0.5005 Accuracy 74.8812 AUC 0.7969\n",
            "Epoch 40 VAL Batch 250 Loss 0.5004 Accuracy 74.8985 AUC 0.7970\n",
            "Epoch 40 VAL Batch 300 Loss 0.5007 Accuracy 74.8859 AUC 0.7968\n",
            "Epoch 40 VAL Batch 350 Loss 0.5008 Accuracy 74.8740 AUC 0.7967\n",
            "Epoch 40 VAL Batch 400 Loss 0.5010 Accuracy 74.8569 AUC 0.7967\n",
            "Epoch 40 VAL Batch 450 Loss 0.5012 Accuracy 74.8386 AUC 0.7966\n",
            "Epoch 40 VAL Batch 500 Loss 0.5013 Accuracy 74.8330 AUC 0.7965\n",
            "Epoch 40 VAL Batch 550 Loss 0.5013 Accuracy 74.8344 AUC 0.7964\n",
            "Epoch 40 VAL Batch 600 Loss 0.5012 Accuracy 74.8376 AUC 0.7965\n",
            "Epoch 40 VAL Batch 650 Loss 0.5013 Accuracy 74.8380 AUC 0.7965\n",
            "Epoch 40 VAL Batch 700 Loss 0.5012 Accuracy 74.8423 AUC 0.7965\n",
            "Epoch 40 VAL Batch 750 Loss 0.5012 Accuracy 74.8418 AUC 0.7965\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "31-12 14:09 root         INFO     Epoch VAL 40 Loss 0.5012 Accuracy 74.8374 AUC 0.7965\n",
            "31-12 14:09 root         INFO     Saving checkpoint for epoch 40 at 31-Dec-riiid-3/checkpoints/ckpt-8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time taken for 1 epoch: 218.11007714271545 secs\n",
            "\n",
            "Epoch 41 TRAIN Batch 0 Loss 0.5017 Accuracy 74.9323 AUC 0.8008\n",
            "Epoch 41 TRAIN Batch 50 Loss 0.5006 Accuracy 74.9063 AUC 0.7968\n",
            "Epoch 41 TRAIN Batch 100 Loss 0.5018 Accuracy 74.7839 AUC 0.7961\n",
            "Epoch 41 TRAIN Batch 150 Loss 0.5025 Accuracy 74.7164 AUC 0.7960\n",
            "Epoch 41 TRAIN Batch 200 Loss 0.5028 Accuracy 74.7104 AUC 0.7959\n",
            "Epoch 41 TRAIN Batch 250 Loss 0.5029 Accuracy 74.6995 AUC 0.7961\n",
            "Epoch 41 TRAIN Batch 300 Loss 0.5030 Accuracy 74.7027 AUC 0.7961\n",
            "Epoch 41 TRAIN Batch 350 Loss 0.5030 Accuracy 74.7148 AUC 0.7960\n",
            "Epoch 41 TRAIN Batch 400 Loss 0.5029 Accuracy 74.7219 AUC 0.7961\n",
            "Epoch 41 TRAIN Batch 450 Loss 0.5030 Accuracy 74.7226 AUC 0.7961\n",
            "Epoch 41 TRAIN Batch 500 Loss 0.5031 Accuracy 74.7080 AUC 0.7961\n",
            "Epoch 41 TRAIN Batch 550 Loss 0.5028 Accuracy 74.7210 AUC 0.7962\n",
            "Epoch 41 TRAIN Batch 600 Loss 0.5030 Accuracy 74.7115 AUC 0.7962\n",
            "Epoch 41 TRAIN Batch 650 Loss 0.5030 Accuracy 74.7086 AUC 0.7962\n",
            "Epoch 41 TRAIN Batch 700 Loss 0.5031 Accuracy 74.7026 AUC 0.7963\n",
            "Epoch 41 TRAIN Batch 750 Loss 0.5030 Accuracy 74.7010 AUC 0.7963\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "31-12 14:13 root         INFO     Epoch TRAIN 41 Loss 0.5031 Accuracy 74.6967 AUC 0.7963\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time taken for 1 epoch: 196.52827787399292 secs\n",
            "\n",
            "Epoch 42 TRAIN Batch 0 Loss 0.4991 Accuracy 75.0806 AUC 0.7901\n",
            "Epoch 42 TRAIN Batch 50 Loss 0.5004 Accuracy 74.9003 AUC 0.7961\n",
            "Epoch 42 TRAIN Batch 100 Loss 0.5012 Accuracy 74.8245 AUC 0.7968\n",
            "Epoch 42 TRAIN Batch 150 Loss 0.5021 Accuracy 74.7600 AUC 0.7964\n",
            "Epoch 42 TRAIN Batch 200 Loss 0.5022 Accuracy 74.7662 AUC 0.7964\n",
            "Epoch 42 TRAIN Batch 250 Loss 0.5019 Accuracy 74.8021 AUC 0.7965\n",
            "Epoch 42 TRAIN Batch 300 Loss 0.5019 Accuracy 74.7960 AUC 0.7965\n",
            "Epoch 42 TRAIN Batch 350 Loss 0.5020 Accuracy 74.7860 AUC 0.7965\n",
            "Epoch 42 TRAIN Batch 400 Loss 0.5019 Accuracy 74.7920 AUC 0.7966\n",
            "Epoch 42 TRAIN Batch 450 Loss 0.5020 Accuracy 74.7787 AUC 0.7965\n",
            "Epoch 42 TRAIN Batch 500 Loss 0.5021 Accuracy 74.7768 AUC 0.7965\n",
            "Epoch 42 TRAIN Batch 550 Loss 0.5019 Accuracy 74.7934 AUC 0.7966\n",
            "Epoch 42 TRAIN Batch 600 Loss 0.5018 Accuracy 74.7980 AUC 0.7967\n",
            "Epoch 42 TRAIN Batch 650 Loss 0.5019 Accuracy 74.7904 AUC 0.7967\n",
            "Epoch 42 TRAIN Batch 700 Loss 0.5020 Accuracy 74.7852 AUC 0.7967\n",
            "Epoch 42 TRAIN Batch 750 Loss 0.5020 Accuracy 74.7821 AUC 0.7967\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "31-12 14:16 root         INFO     Epoch TRAIN 42 Loss 0.5020 Accuracy 74.7821 AUC 0.7967\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time taken for 1 epoch: 196.6010947227478 secs\n",
            "\n",
            "Epoch 43 TRAIN Batch 0 Loss 0.5018 Accuracy 74.6598 AUC 0.7992\n",
            "Epoch 43 TRAIN Batch 50 Loss 0.5024 Accuracy 74.7419 AUC 0.7965\n",
            "Epoch 43 TRAIN Batch 100 Loss 0.5012 Accuracy 74.8133 AUC 0.7972\n",
            "Epoch 43 TRAIN Batch 150 Loss 0.5012 Accuracy 74.8035 AUC 0.7971\n",
            "Epoch 43 TRAIN Batch 200 Loss 0.5016 Accuracy 74.7899 AUC 0.7969\n",
            "Epoch 43 TRAIN Batch 250 Loss 0.5020 Accuracy 74.7501 AUC 0.7968\n",
            "Epoch 43 TRAIN Batch 300 Loss 0.5019 Accuracy 74.7621 AUC 0.7969\n",
            "Epoch 43 TRAIN Batch 350 Loss 0.5019 Accuracy 74.7645 AUC 0.7969\n",
            "Epoch 43 TRAIN Batch 400 Loss 0.5019 Accuracy 74.7752 AUC 0.7969\n",
            "Epoch 43 TRAIN Batch 450 Loss 0.5019 Accuracy 74.7659 AUC 0.7969\n",
            "Epoch 43 TRAIN Batch 500 Loss 0.5020 Accuracy 74.7653 AUC 0.7969\n",
            "Epoch 43 TRAIN Batch 550 Loss 0.5018 Accuracy 74.7719 AUC 0.7968\n",
            "Epoch 43 TRAIN Batch 600 Loss 0.5019 Accuracy 74.7671 AUC 0.7968\n",
            "Epoch 43 TRAIN Batch 650 Loss 0.5020 Accuracy 74.7603 AUC 0.7968\n",
            "Epoch 43 TRAIN Batch 700 Loss 0.5020 Accuracy 74.7573 AUC 0.7969\n",
            "Epoch 43 TRAIN Batch 750 Loss 0.5020 Accuracy 74.7574 AUC 0.7968\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "31-12 14:19 root         INFO     Epoch TRAIN 43 Loss 0.5020 Accuracy 74.7594 AUC 0.7969\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time taken for 1 epoch: 196.2353000640869 secs\n",
            "\n",
            "Epoch 44 TRAIN Batch 0 Loss 0.5052 Accuracy 74.5083 AUC 0.7995\n",
            "Epoch 44 TRAIN Batch 50 Loss 0.5035 Accuracy 74.6598 AUC 0.7960\n",
            "Epoch 44 TRAIN Batch 100 Loss 0.5038 Accuracy 74.6227 AUC 0.7957\n",
            "Epoch 44 TRAIN Batch 150 Loss 0.5034 Accuracy 74.6450 AUC 0.7960\n",
            "Epoch 44 TRAIN Batch 200 Loss 0.5033 Accuracy 74.6583 AUC 0.7961\n",
            "Epoch 44 TRAIN Batch 250 Loss 0.5031 Accuracy 74.6716 AUC 0.7962\n",
            "Epoch 44 TRAIN Batch 300 Loss 0.5029 Accuracy 74.6951 AUC 0.7963\n",
            "Epoch 44 TRAIN Batch 350 Loss 0.5025 Accuracy 74.7222 AUC 0.7965\n",
            "Epoch 44 TRAIN Batch 400 Loss 0.5025 Accuracy 74.7267 AUC 0.7964\n",
            "Epoch 44 TRAIN Batch 450 Loss 0.5023 Accuracy 74.7410 AUC 0.7965\n",
            "Epoch 44 TRAIN Batch 500 Loss 0.5025 Accuracy 74.7202 AUC 0.7965\n",
            "Epoch 44 TRAIN Batch 550 Loss 0.5024 Accuracy 74.7322 AUC 0.7965\n",
            "Epoch 44 TRAIN Batch 600 Loss 0.5023 Accuracy 74.7437 AUC 0.7966\n",
            "Epoch 44 TRAIN Batch 650 Loss 0.5022 Accuracy 74.7521 AUC 0.7967\n",
            "Epoch 44 TRAIN Batch 700 Loss 0.5023 Accuracy 74.7462 AUC 0.7966\n",
            "Epoch 44 TRAIN Batch 750 Loss 0.5024 Accuracy 74.7439 AUC 0.7965\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "31-12 14:23 root         INFO     Epoch TRAIN 44 Loss 0.5022 Accuracy 74.7538 AUC 0.7966\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time taken for 1 epoch: 194.99177193641663 secs\n",
            "\n",
            "Epoch 45 TRAIN Batch 0 Loss 0.5156 Accuracy 73.9052 AUC 0.7891\n",
            "Epoch 45 TRAIN Batch 50 Loss 0.5020 Accuracy 74.7260 AUC 0.7961\n",
            "Epoch 45 TRAIN Batch 100 Loss 0.5016 Accuracy 74.7830 AUC 0.7970\n",
            "Epoch 45 TRAIN Batch 150 Loss 0.5019 Accuracy 74.7721 AUC 0.7968\n",
            "Epoch 45 TRAIN Batch 200 Loss 0.5016 Accuracy 74.7960 AUC 0.7969\n",
            "Epoch 45 TRAIN Batch 250 Loss 0.5015 Accuracy 74.7895 AUC 0.7969\n",
            "Epoch 45 TRAIN Batch 300 Loss 0.5015 Accuracy 74.7855 AUC 0.7970\n",
            "Epoch 45 TRAIN Batch 350 Loss 0.5011 Accuracy 74.8185 AUC 0.7973\n",
            "Epoch 45 TRAIN Batch 400 Loss 0.5013 Accuracy 74.8104 AUC 0.7971\n",
            "Epoch 45 TRAIN Batch 450 Loss 0.5013 Accuracy 74.8137 AUC 0.7971\n",
            "Epoch 45 TRAIN Batch 500 Loss 0.5013 Accuracy 74.8143 AUC 0.7971\n",
            "Epoch 45 TRAIN Batch 550 Loss 0.5012 Accuracy 74.8177 AUC 0.7972\n",
            "Epoch 45 TRAIN Batch 600 Loss 0.5013 Accuracy 74.8176 AUC 0.7971\n",
            "Epoch 45 TRAIN Batch 650 Loss 0.5012 Accuracy 74.8279 AUC 0.7973\n",
            "Epoch 45 TRAIN Batch 700 Loss 0.5013 Accuracy 74.8249 AUC 0.7973\n",
            "Epoch 45 TRAIN Batch 750 Loss 0.5014 Accuracy 74.8195 AUC 0.7973\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "31-12 14:26 root         INFO     Epoch TRAIN 45 Loss 0.5015 Accuracy 74.8092 AUC 0.7972\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 45 VAL Batch 0 Loss 0.4975 Accuracy 74.9876 AUC 0.8065\n",
            "Epoch 45 VAL Batch 50 Loss 0.5007 Accuracy 74.8590 AUC 0.7981\n",
            "Epoch 45 VAL Batch 100 Loss 0.5009 Accuracy 74.8719 AUC 0.7980\n",
            "Epoch 45 VAL Batch 150 Loss 0.5005 Accuracy 74.8994 AUC 0.7977\n",
            "Epoch 45 VAL Batch 200 Loss 0.5009 Accuracy 74.8798 AUC 0.7974\n",
            "Epoch 45 VAL Batch 250 Loss 0.5008 Accuracy 74.8922 AUC 0.7975\n",
            "Epoch 45 VAL Batch 300 Loss 0.5011 Accuracy 74.8795 AUC 0.7973\n",
            "Epoch 45 VAL Batch 350 Loss 0.5012 Accuracy 74.8690 AUC 0.7973\n",
            "Epoch 45 VAL Batch 400 Loss 0.5014 Accuracy 74.8486 AUC 0.7971\n",
            "Epoch 45 VAL Batch 450 Loss 0.5017 Accuracy 74.8315 AUC 0.7971\n",
            "Epoch 45 VAL Batch 500 Loss 0.5018 Accuracy 74.8251 AUC 0.7969\n",
            "Epoch 45 VAL Batch 550 Loss 0.5019 Accuracy 74.8278 AUC 0.7969\n",
            "Epoch 45 VAL Batch 600 Loss 0.5017 Accuracy 74.8355 AUC 0.7969\n",
            "Epoch 45 VAL Batch 650 Loss 0.5018 Accuracy 74.8344 AUC 0.7969\n",
            "Epoch 45 VAL Batch 700 Loss 0.5017 Accuracy 74.8376 AUC 0.7969\n",
            "Epoch 45 VAL Batch 750 Loss 0.5017 Accuracy 74.8380 AUC 0.7969\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "31-12 14:26 root         INFO     Epoch VAL 45 Loss 0.5018 Accuracy 74.8330 AUC 0.7969\n",
            "31-12 14:26 root         INFO     Saving checkpoint for epoch 45 at 31-Dec-riiid-3/checkpoints/ckpt-9\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time taken for 1 epoch: 217.95168447494507 secs\n",
            "\n",
            "Epoch 46 TRAIN Batch 0 Loss 0.5036 Accuracy 74.9243 AUC 0.7941\n",
            "Epoch 46 TRAIN Batch 50 Loss 0.5001 Accuracy 74.9171 AUC 0.7978\n",
            "Epoch 46 TRAIN Batch 100 Loss 0.5006 Accuracy 74.8788 AUC 0.7974\n",
            "Epoch 46 TRAIN Batch 150 Loss 0.5016 Accuracy 74.7930 AUC 0.7974\n",
            "Epoch 46 TRAIN Batch 200 Loss 0.5017 Accuracy 74.7848 AUC 0.7973\n",
            "Epoch 46 TRAIN Batch 250 Loss 0.5017 Accuracy 74.7944 AUC 0.7973\n",
            "Epoch 46 TRAIN Batch 300 Loss 0.5013 Accuracy 74.8129 AUC 0.7974\n",
            "Epoch 46 TRAIN Batch 350 Loss 0.5015 Accuracy 74.8013 AUC 0.7973\n",
            "Epoch 46 TRAIN Batch 400 Loss 0.5017 Accuracy 74.7939 AUC 0.7972\n",
            "Epoch 46 TRAIN Batch 450 Loss 0.5017 Accuracy 74.7954 AUC 0.7970\n",
            "Epoch 46 TRAIN Batch 500 Loss 0.5017 Accuracy 74.7978 AUC 0.7971\n",
            "Epoch 46 TRAIN Batch 550 Loss 0.5018 Accuracy 74.7959 AUC 0.7970\n",
            "Epoch 46 TRAIN Batch 600 Loss 0.5017 Accuracy 74.7985 AUC 0.7970\n",
            "Epoch 46 TRAIN Batch 650 Loss 0.5016 Accuracy 74.8024 AUC 0.7971\n",
            "Epoch 46 TRAIN Batch 700 Loss 0.5014 Accuracy 74.8224 AUC 0.7972\n",
            "Epoch 46 TRAIN Batch 750 Loss 0.5014 Accuracy 74.8128 AUC 0.7971\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "31-12 14:29 root         INFO     Epoch TRAIN 46 Loss 0.5014 Accuracy 74.8179 AUC 0.7971\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time taken for 1 epoch: 196.7039954662323 secs\n",
            "\n",
            "Epoch 47 TRAIN Batch 0 Loss 0.5110 Accuracy 74.0054 AUC 0.7910\n",
            "Epoch 47 TRAIN Batch 50 Loss 0.5016 Accuracy 74.7459 AUC 0.7970\n",
            "Epoch 47 TRAIN Batch 100 Loss 0.5022 Accuracy 74.7325 AUC 0.7966\n",
            "Epoch 47 TRAIN Batch 150 Loss 0.5025 Accuracy 74.6979 AUC 0.7964\n",
            "Epoch 47 TRAIN Batch 200 Loss 0.5019 Accuracy 74.7464 AUC 0.7969\n",
            "Epoch 47 TRAIN Batch 250 Loss 0.5018 Accuracy 74.7698 AUC 0.7968\n",
            "Epoch 47 TRAIN Batch 300 Loss 0.5018 Accuracy 74.7669 AUC 0.7969\n",
            "Epoch 47 TRAIN Batch 350 Loss 0.5017 Accuracy 74.7738 AUC 0.7969\n",
            "Epoch 47 TRAIN Batch 400 Loss 0.5016 Accuracy 74.7806 AUC 0.7971\n",
            "Epoch 47 TRAIN Batch 450 Loss 0.5012 Accuracy 74.8119 AUC 0.7973\n",
            "Epoch 47 TRAIN Batch 500 Loss 0.5012 Accuracy 74.8074 AUC 0.7973\n",
            "Epoch 47 TRAIN Batch 550 Loss 0.5010 Accuracy 74.8242 AUC 0.7974\n",
            "Epoch 47 TRAIN Batch 600 Loss 0.5010 Accuracy 74.8169 AUC 0.7974\n",
            "Epoch 47 TRAIN Batch 650 Loss 0.5010 Accuracy 74.8153 AUC 0.7974\n",
            "Epoch 47 TRAIN Batch 700 Loss 0.5011 Accuracy 74.8122 AUC 0.7975\n",
            "Epoch 47 TRAIN Batch 750 Loss 0.5011 Accuracy 74.8118 AUC 0.7974\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "31-12 14:33 root         INFO     Epoch TRAIN 47 Loss 0.5013 Accuracy 74.8006 AUC 0.7974\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time taken for 1 epoch: 196.67973494529724 secs\n",
            "\n",
            "Epoch 48 TRAIN Batch 0 Loss 0.4952 Accuracy 75.4078 AUC 0.7994\n",
            "Epoch 48 TRAIN Batch 50 Loss 0.5003 Accuracy 74.8815 AUC 0.7984\n",
            "Epoch 48 TRAIN Batch 100 Loss 0.5005 Accuracy 74.9035 AUC 0.7982\n",
            "Epoch 48 TRAIN Batch 150 Loss 0.5008 Accuracy 74.8665 AUC 0.7981\n",
            "Epoch 48 TRAIN Batch 200 Loss 0.5006 Accuracy 74.8749 AUC 0.7985\n",
            "Epoch 48 TRAIN Batch 250 Loss 0.5007 Accuracy 74.8725 AUC 0.7983\n",
            "Epoch 48 TRAIN Batch 300 Loss 0.5004 Accuracy 74.8790 AUC 0.7984\n",
            "Epoch 48 TRAIN Batch 350 Loss 0.5005 Accuracy 74.8764 AUC 0.7983\n",
            "Epoch 48 TRAIN Batch 400 Loss 0.5004 Accuracy 74.8856 AUC 0.7983\n",
            "Epoch 48 TRAIN Batch 450 Loss 0.5005 Accuracy 74.8807 AUC 0.7981\n",
            "Epoch 48 TRAIN Batch 500 Loss 0.5005 Accuracy 74.8733 AUC 0.7981\n",
            "Epoch 48 TRAIN Batch 550 Loss 0.5006 Accuracy 74.8635 AUC 0.7980\n",
            "Epoch 48 TRAIN Batch 600 Loss 0.5005 Accuracy 74.8694 AUC 0.7980\n",
            "Epoch 48 TRAIN Batch 650 Loss 0.5007 Accuracy 74.8555 AUC 0.7979\n",
            "Epoch 48 TRAIN Batch 700 Loss 0.5006 Accuracy 74.8612 AUC 0.7978\n",
            "Epoch 48 TRAIN Batch 750 Loss 0.5006 Accuracy 74.8610 AUC 0.7978\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "31-12 14:36 root         INFO     Epoch TRAIN 48 Loss 0.5006 Accuracy 74.8609 AUC 0.7979\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time taken for 1 epoch: 196.34443140029907 secs\n",
            "\n",
            "Epoch 49 TRAIN Batch 0 Loss 0.5101 Accuracy 73.7583 AUC 0.7924\n",
            "Epoch 49 TRAIN Batch 50 Loss 0.5027 Accuracy 74.6506 AUC 0.7969\n",
            "Epoch 49 TRAIN Batch 100 Loss 0.5017 Accuracy 74.7413 AUC 0.7977\n",
            "Epoch 49 TRAIN Batch 150 Loss 0.5008 Accuracy 74.8011 AUC 0.7980\n",
            "Epoch 49 TRAIN Batch 200 Loss 0.5012 Accuracy 74.7815 AUC 0.7979\n",
            "Epoch 49 TRAIN Batch 250 Loss 0.5015 Accuracy 74.7667 AUC 0.7976\n",
            "Epoch 49 TRAIN Batch 300 Loss 0.5016 Accuracy 74.7619 AUC 0.7973\n",
            "Epoch 49 TRAIN Batch 350 Loss 0.5017 Accuracy 74.7434 AUC 0.7973\n",
            "Epoch 49 TRAIN Batch 400 Loss 0.5016 Accuracy 74.7605 AUC 0.7974\n",
            "Epoch 49 TRAIN Batch 450 Loss 0.5015 Accuracy 74.7716 AUC 0.7976\n",
            "Epoch 49 TRAIN Batch 500 Loss 0.5015 Accuracy 74.7680 AUC 0.7975\n",
            "Epoch 49 TRAIN Batch 550 Loss 0.5014 Accuracy 74.7830 AUC 0.7975\n",
            "Epoch 49 TRAIN Batch 600 Loss 0.5014 Accuracy 74.7762 AUC 0.7975\n",
            "Epoch 49 TRAIN Batch 650 Loss 0.5014 Accuracy 74.7740 AUC 0.7975\n",
            "Epoch 49 TRAIN Batch 700 Loss 0.5014 Accuracy 74.7809 AUC 0.7975\n",
            "Epoch 49 TRAIN Batch 750 Loss 0.5013 Accuracy 74.7844 AUC 0.7976\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "31-12 14:39 root         INFO     Epoch TRAIN 49 Loss 0.5013 Accuracy 74.7859 AUC 0.7976\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time taken for 1 epoch: 196.43826413154602 secs\n",
            "\n",
            "Epoch 50 TRAIN Batch 0 Loss 0.4975 Accuracy 75.2771 AUC 0.7957\n",
            "Epoch 50 TRAIN Batch 50 Loss 0.5007 Accuracy 74.8399 AUC 0.7985\n",
            "Epoch 50 TRAIN Batch 100 Loss 0.5003 Accuracy 74.8635 AUC 0.7985\n",
            "Epoch 50 TRAIN Batch 150 Loss 0.4997 Accuracy 74.9081 AUC 0.7986\n",
            "Epoch 50 TRAIN Batch 200 Loss 0.4998 Accuracy 74.9048 AUC 0.7985\n",
            "Epoch 50 TRAIN Batch 250 Loss 0.4999 Accuracy 74.8871 AUC 0.7984\n",
            "Epoch 50 TRAIN Batch 300 Loss 0.5000 Accuracy 74.8698 AUC 0.7983\n",
            "Epoch 50 TRAIN Batch 350 Loss 0.5003 Accuracy 74.8470 AUC 0.7981\n",
            "Epoch 50 TRAIN Batch 400 Loss 0.5007 Accuracy 74.8266 AUC 0.7978\n",
            "Epoch 50 TRAIN Batch 450 Loss 0.5008 Accuracy 74.8181 AUC 0.7977\n",
            "Epoch 50 TRAIN Batch 500 Loss 0.5010 Accuracy 74.8046 AUC 0.7976\n",
            "Epoch 50 TRAIN Batch 550 Loss 0.5010 Accuracy 74.8064 AUC 0.7977\n",
            "Epoch 50 TRAIN Batch 600 Loss 0.5011 Accuracy 74.8006 AUC 0.7977\n",
            "Epoch 50 TRAIN Batch 650 Loss 0.5011 Accuracy 74.7968 AUC 0.7977\n",
            "Epoch 50 TRAIN Batch 700 Loss 0.5011 Accuracy 74.8037 AUC 0.7977\n",
            "Epoch 50 TRAIN Batch 750 Loss 0.5011 Accuracy 74.8028 AUC 0.7977\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "31-12 14:43 root         INFO     Epoch TRAIN 50 Loss 0.5011 Accuracy 74.8057 AUC 0.7977\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 50 VAL Batch 0 Loss 0.4976 Accuracy 74.9296 AUC 0.8065\n",
            "Epoch 50 VAL Batch 50 Loss 0.4991 Accuracy 74.9589 AUC 0.7989\n",
            "Epoch 50 VAL Batch 100 Loss 0.4992 Accuracy 74.9657 AUC 0.7989\n",
            "Epoch 50 VAL Batch 150 Loss 0.4989 Accuracy 74.9757 AUC 0.7986\n",
            "Epoch 50 VAL Batch 200 Loss 0.4993 Accuracy 74.9559 AUC 0.7983\n",
            "Epoch 50 VAL Batch 250 Loss 0.4992 Accuracy 74.9619 AUC 0.7983\n",
            "Epoch 50 VAL Batch 300 Loss 0.4994 Accuracy 74.9528 AUC 0.7982\n",
            "Epoch 50 VAL Batch 350 Loss 0.4996 Accuracy 74.9429 AUC 0.7981\n",
            "Epoch 50 VAL Batch 400 Loss 0.4998 Accuracy 74.9217 AUC 0.7980\n",
            "Epoch 50 VAL Batch 450 Loss 0.5000 Accuracy 74.9073 AUC 0.7979\n",
            "Epoch 50 VAL Batch 500 Loss 0.5001 Accuracy 74.9010 AUC 0.7978\n",
            "Epoch 50 VAL Batch 550 Loss 0.5002 Accuracy 74.9009 AUC 0.7977\n",
            "Epoch 50 VAL Batch 600 Loss 0.5001 Accuracy 74.9074 AUC 0.7978\n",
            "Epoch 50 VAL Batch 650 Loss 0.5001 Accuracy 74.9049 AUC 0.7978\n",
            "Epoch 50 VAL Batch 700 Loss 0.5001 Accuracy 74.9082 AUC 0.7978\n",
            "Epoch 50 VAL Batch 750 Loss 0.5000 Accuracy 74.9082 AUC 0.7978\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "31-12 14:43 root         INFO     Epoch VAL 50 Loss 0.5000 Accuracy 74.9056 AUC 0.7978\n",
            "31-12 14:43 root         INFO     Saving checkpoint for epoch 50 at 31-Dec-riiid-3/checkpoints/ckpt-10\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time taken for 1 epoch: 219.01246213912964 secs\n",
            "\n",
            "Epoch 51 TRAIN Batch 0 Loss 0.5013 Accuracy 74.6758 AUC 0.7912\n",
            "Epoch 51 TRAIN Batch 50 Loss 0.5000 Accuracy 74.9077 AUC 0.7986\n",
            "Epoch 51 TRAIN Batch 100 Loss 0.5002 Accuracy 74.8960 AUC 0.7985\n",
            "Epoch 51 TRAIN Batch 150 Loss 0.5005 Accuracy 74.8842 AUC 0.7984\n",
            "Epoch 51 TRAIN Batch 200 Loss 0.5002 Accuracy 74.8817 AUC 0.7987\n",
            "Epoch 51 TRAIN Batch 250 Loss 0.5004 Accuracy 74.8772 AUC 0.7987\n",
            "Epoch 51 TRAIN Batch 300 Loss 0.5003 Accuracy 74.8776 AUC 0.7988\n",
            "Epoch 51 TRAIN Batch 350 Loss 0.5004 Accuracy 74.8738 AUC 0.7987\n",
            "Epoch 51 TRAIN Batch 400 Loss 0.5006 Accuracy 74.8634 AUC 0.7985\n",
            "Epoch 51 TRAIN Batch 450 Loss 0.5007 Accuracy 74.8561 AUC 0.7984\n",
            "Epoch 51 TRAIN Batch 500 Loss 0.5008 Accuracy 74.8491 AUC 0.7983\n",
            "Epoch 51 TRAIN Batch 550 Loss 0.5008 Accuracy 74.8457 AUC 0.7984\n",
            "Epoch 51 TRAIN Batch 600 Loss 0.5008 Accuracy 74.8405 AUC 0.7983\n",
            "Epoch 51 TRAIN Batch 650 Loss 0.5008 Accuracy 74.8464 AUC 0.7983\n",
            "Epoch 51 TRAIN Batch 700 Loss 0.5006 Accuracy 74.8567 AUC 0.7984\n",
            "Epoch 51 TRAIN Batch 750 Loss 0.5006 Accuracy 74.8581 AUC 0.7984\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "31-12 14:46 root         INFO     Epoch TRAIN 51 Loss 0.5006 Accuracy 74.8617 AUC 0.7985\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time taken for 1 epoch: 195.47807455062866 secs\n",
            "\n",
            "Epoch 52 TRAIN Batch 0 Loss 0.4906 Accuracy 75.5496 AUC 0.7999\n",
            "Epoch 52 TRAIN Batch 50 Loss 0.5002 Accuracy 74.9401 AUC 0.7988\n",
            "Epoch 52 TRAIN Batch 100 Loss 0.5008 Accuracy 74.8668 AUC 0.7984\n",
            "Epoch 52 TRAIN Batch 150 Loss 0.5004 Accuracy 74.8714 AUC 0.7987\n",
            "Epoch 52 TRAIN Batch 200 Loss 0.5006 Accuracy 74.8736 AUC 0.7986\n",
            "Epoch 52 TRAIN Batch 250 Loss 0.5006 Accuracy 74.8702 AUC 0.7986\n",
            "Epoch 52 TRAIN Batch 300 Loss 0.5005 Accuracy 74.8765 AUC 0.7986\n",
            "Epoch 52 TRAIN Batch 350 Loss 0.5007 Accuracy 74.8574 AUC 0.7983\n",
            "Epoch 52 TRAIN Batch 400 Loss 0.5009 Accuracy 74.8413 AUC 0.7982\n",
            "Epoch 52 TRAIN Batch 450 Loss 0.5010 Accuracy 74.8356 AUC 0.7981\n",
            "Epoch 52 TRAIN Batch 500 Loss 0.5011 Accuracy 74.8272 AUC 0.7981\n",
            "Epoch 52 TRAIN Batch 550 Loss 0.5011 Accuracy 74.8212 AUC 0.7981\n",
            "Epoch 52 TRAIN Batch 600 Loss 0.5012 Accuracy 74.8173 AUC 0.7981\n",
            "Epoch 52 TRAIN Batch 650 Loss 0.5012 Accuracy 74.8198 AUC 0.7981\n",
            "Epoch 52 TRAIN Batch 700 Loss 0.5012 Accuracy 74.8109 AUC 0.7981\n",
            "Epoch 52 TRAIN Batch 750 Loss 0.5014 Accuracy 74.7989 AUC 0.7979\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "31-12 14:49 root         INFO     Epoch TRAIN 52 Loss 0.5013 Accuracy 74.8061 AUC 0.7979\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time taken for 1 epoch: 196.6781485080719 secs\n",
            "\n",
            "Epoch 53 TRAIN Batch 0 Loss 0.5037 Accuracy 74.7339 AUC 0.7944\n",
            "Epoch 53 TRAIN Batch 50 Loss 0.5019 Accuracy 74.7407 AUC 0.7979\n",
            "Epoch 53 TRAIN Batch 100 Loss 0.5012 Accuracy 74.7819 AUC 0.7978\n",
            "Epoch 53 TRAIN Batch 150 Loss 0.5011 Accuracy 74.7936 AUC 0.7979\n",
            "Epoch 53 TRAIN Batch 200 Loss 0.5006 Accuracy 74.8305 AUC 0.7981\n",
            "Epoch 53 TRAIN Batch 250 Loss 0.5006 Accuracy 74.8364 AUC 0.7981\n",
            "Epoch 53 TRAIN Batch 300 Loss 0.5008 Accuracy 74.8202 AUC 0.7980\n",
            "Epoch 53 TRAIN Batch 350 Loss 0.5009 Accuracy 74.8161 AUC 0.7978\n",
            "Epoch 53 TRAIN Batch 400 Loss 0.5008 Accuracy 74.8209 AUC 0.7979\n",
            "Epoch 53 TRAIN Batch 450 Loss 0.5008 Accuracy 74.8253 AUC 0.7979\n",
            "Epoch 53 TRAIN Batch 500 Loss 0.5009 Accuracy 74.8203 AUC 0.7979\n",
            "Epoch 53 TRAIN Batch 550 Loss 0.5008 Accuracy 74.8227 AUC 0.7979\n",
            "Epoch 53 TRAIN Batch 600 Loss 0.5009 Accuracy 74.8173 AUC 0.7979\n",
            "Epoch 53 TRAIN Batch 650 Loss 0.5010 Accuracy 74.8125 AUC 0.7979\n",
            "Epoch 53 TRAIN Batch 700 Loss 0.5009 Accuracy 74.8196 AUC 0.7980\n",
            "Epoch 53 TRAIN Batch 750 Loss 0.5009 Accuracy 74.8189 AUC 0.7980\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "31-12 14:53 root         INFO     Epoch TRAIN 53 Loss 0.5008 Accuracy 74.8243 AUC 0.7980\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time taken for 1 epoch: 196.1815311908722 secs\n",
            "\n",
            "Epoch 54 TRAIN Batch 0 Loss 0.5069 Accuracy 74.4056 AUC 0.7918\n",
            "Epoch 54 TRAIN Batch 50 Loss 0.5028 Accuracy 74.6440 AUC 0.7968\n",
            "Epoch 54 TRAIN Batch 100 Loss 0.5019 Accuracy 74.7065 AUC 0.7970\n",
            "Epoch 54 TRAIN Batch 150 Loss 0.5012 Accuracy 74.7753 AUC 0.7973\n",
            "Epoch 54 TRAIN Batch 200 Loss 0.5011 Accuracy 74.7972 AUC 0.7975\n",
            "Epoch 54 TRAIN Batch 250 Loss 0.5006 Accuracy 74.8390 AUC 0.7978\n",
            "Epoch 54 TRAIN Batch 300 Loss 0.5002 Accuracy 74.8607 AUC 0.7980\n",
            "Epoch 54 TRAIN Batch 350 Loss 0.5003 Accuracy 74.8567 AUC 0.7981\n",
            "Epoch 54 TRAIN Batch 400 Loss 0.5004 Accuracy 74.8509 AUC 0.7981\n",
            "Epoch 54 TRAIN Batch 450 Loss 0.5004 Accuracy 74.8472 AUC 0.7981\n",
            "Epoch 54 TRAIN Batch 500 Loss 0.5002 Accuracy 74.8602 AUC 0.7983\n",
            "Epoch 54 TRAIN Batch 550 Loss 0.5001 Accuracy 74.8650 AUC 0.7984\n",
            "Epoch 54 TRAIN Batch 600 Loss 0.5001 Accuracy 74.8703 AUC 0.7983\n",
            "Epoch 54 TRAIN Batch 650 Loss 0.5002 Accuracy 74.8655 AUC 0.7983\n",
            "Epoch 54 TRAIN Batch 700 Loss 0.5001 Accuracy 74.8631 AUC 0.7983\n",
            "Epoch 54 TRAIN Batch 750 Loss 0.5002 Accuracy 74.8637 AUC 0.7982\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "31-12 14:56 root         INFO     Epoch TRAIN 54 Loss 0.5002 Accuracy 74.8568 AUC 0.7982\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time taken for 1 epoch: 196.65893054008484 secs\n",
            "\n",
            "Epoch 55 TRAIN Batch 0 Loss 0.4835 Accuracy 75.9804 AUC 0.8051\n",
            "Epoch 55 TRAIN Batch 50 Loss 0.5006 Accuracy 74.8620 AUC 0.7974\n",
            "Epoch 55 TRAIN Batch 100 Loss 0.5013 Accuracy 74.8058 AUC 0.7976\n",
            "Epoch 55 TRAIN Batch 150 Loss 0.5010 Accuracy 74.8271 AUC 0.7977\n",
            "Epoch 55 TRAIN Batch 200 Loss 0.5009 Accuracy 74.8433 AUC 0.7978\n",
            "Epoch 55 TRAIN Batch 250 Loss 0.5002 Accuracy 74.8719 AUC 0.7983\n",
            "Epoch 55 TRAIN Batch 300 Loss 0.5003 Accuracy 74.8618 AUC 0.7984\n",
            "Epoch 55 TRAIN Batch 350 Loss 0.5000 Accuracy 74.8720 AUC 0.7985\n",
            "Epoch 55 TRAIN Batch 400 Loss 0.5002 Accuracy 74.8534 AUC 0.7984\n",
            "Epoch 55 TRAIN Batch 450 Loss 0.5004 Accuracy 74.8471 AUC 0.7982\n",
            "Epoch 55 TRAIN Batch 500 Loss 0.5003 Accuracy 74.8545 AUC 0.7983\n",
            "Epoch 55 TRAIN Batch 550 Loss 0.5002 Accuracy 74.8679 AUC 0.7983\n",
            "Epoch 55 TRAIN Batch 600 Loss 0.5001 Accuracy 74.8704 AUC 0.7984\n",
            "Epoch 55 TRAIN Batch 650 Loss 0.5002 Accuracy 74.8619 AUC 0.7984\n",
            "Epoch 55 TRAIN Batch 700 Loss 0.5003 Accuracy 74.8533 AUC 0.7983\n",
            "Epoch 55 TRAIN Batch 750 Loss 0.5002 Accuracy 74.8633 AUC 0.7984\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "31-12 14:59 root         INFO     Epoch TRAIN 55 Loss 0.5002 Accuracy 74.8657 AUC 0.7984\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 55 VAL Batch 0 Loss 0.4969 Accuracy 75.1201 AUC 0.8068\n",
            "Epoch 55 VAL Batch 50 Loss 0.4987 Accuracy 75.0011 AUC 0.7991\n",
            "Epoch 55 VAL Batch 100 Loss 0.4987 Accuracy 74.9830 AUC 0.7992\n",
            "Epoch 55 VAL Batch 150 Loss 0.4983 Accuracy 74.9922 AUC 0.7989\n",
            "Epoch 55 VAL Batch 200 Loss 0.4987 Accuracy 74.9784 AUC 0.7986\n",
            "Epoch 55 VAL Batch 250 Loss 0.4986 Accuracy 74.9876 AUC 0.7987\n",
            "Epoch 55 VAL Batch 300 Loss 0.4989 Accuracy 74.9754 AUC 0.7986\n",
            "Epoch 55 VAL Batch 350 Loss 0.4990 Accuracy 74.9661 AUC 0.7985\n",
            "Epoch 55 VAL Batch 400 Loss 0.4992 Accuracy 74.9411 AUC 0.7984\n",
            "Epoch 55 VAL Batch 450 Loss 0.4995 Accuracy 74.9241 AUC 0.7983\n",
            "Epoch 55 VAL Batch 500 Loss 0.4996 Accuracy 74.9188 AUC 0.7982\n",
            "Epoch 55 VAL Batch 550 Loss 0.4996 Accuracy 74.9180 AUC 0.7981\n",
            "Epoch 55 VAL Batch 600 Loss 0.4995 Accuracy 74.9238 AUC 0.7982\n",
            "Epoch 55 VAL Batch 650 Loss 0.4995 Accuracy 74.9228 AUC 0.7982\n",
            "Epoch 55 VAL Batch 700 Loss 0.4995 Accuracy 74.9254 AUC 0.7982\n",
            "Epoch 55 VAL Batch 750 Loss 0.4994 Accuracy 74.9287 AUC 0.7982\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "31-12 15:00 root         INFO     Epoch VAL 55 Loss 0.4995 Accuracy 74.9238 AUC 0.7982\n",
            "31-12 15:00 root         INFO     Saving checkpoint for epoch 55 at 31-Dec-riiid-3/checkpoints/ckpt-11\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time taken for 1 epoch: 218.24199724197388 secs\n",
            "\n",
            "Epoch 56 TRAIN Batch 0 Loss 0.4945 Accuracy 75.4504 AUC 0.8036\n",
            "Epoch 56 TRAIN Batch 50 Loss 0.4987 Accuracy 74.9765 AUC 0.8000\n",
            "Epoch 56 TRAIN Batch 100 Loss 0.4994 Accuracy 74.8953 AUC 0.7993\n",
            "Epoch 56 TRAIN Batch 150 Loss 0.4997 Accuracy 74.8751 AUC 0.7990\n",
            "Epoch 56 TRAIN Batch 200 Loss 0.5000 Accuracy 74.8499 AUC 0.7987\n",
            "Epoch 56 TRAIN Batch 250 Loss 0.5006 Accuracy 74.8206 AUC 0.7984\n",
            "Epoch 56 TRAIN Batch 300 Loss 0.5009 Accuracy 74.8032 AUC 0.7981\n",
            "Epoch 56 TRAIN Batch 350 Loss 0.5009 Accuracy 74.8112 AUC 0.7981\n",
            "Epoch 56 TRAIN Batch 400 Loss 0.5009 Accuracy 74.8158 AUC 0.7982\n",
            "Epoch 56 TRAIN Batch 450 Loss 0.5008 Accuracy 74.8237 AUC 0.7982\n",
            "Epoch 56 TRAIN Batch 500 Loss 0.5007 Accuracy 74.8334 AUC 0.7982\n",
            "Epoch 56 TRAIN Batch 550 Loss 0.5005 Accuracy 74.8428 AUC 0.7983\n",
            "Epoch 56 TRAIN Batch 600 Loss 0.5006 Accuracy 74.8368 AUC 0.7983\n",
            "Epoch 56 TRAIN Batch 650 Loss 0.5004 Accuracy 74.8506 AUC 0.7984\n",
            "Epoch 56 TRAIN Batch 700 Loss 0.5004 Accuracy 74.8510 AUC 0.7984\n",
            "Epoch 56 TRAIN Batch 750 Loss 0.5004 Accuracy 74.8503 AUC 0.7984\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "31-12 15:03 root         INFO     Epoch TRAIN 56 Loss 0.5004 Accuracy 74.8492 AUC 0.7985\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time taken for 1 epoch: 195.88111662864685 secs\n",
            "\n",
            "Epoch 57 TRAIN Batch 0 Loss 0.4987 Accuracy 75.0790 AUC 0.8027\n",
            "Epoch 57 TRAIN Batch 50 Loss 0.5005 Accuracy 74.8337 AUC 0.7987\n",
            "Epoch 57 TRAIN Batch 100 Loss 0.5006 Accuracy 74.8386 AUC 0.7983\n",
            "Epoch 57 TRAIN Batch 150 Loss 0.5007 Accuracy 74.8254 AUC 0.7981\n",
            "Epoch 57 TRAIN Batch 200 Loss 0.5004 Accuracy 74.8589 AUC 0.7984\n",
            "Epoch 57 TRAIN Batch 250 Loss 0.5001 Accuracy 74.8777 AUC 0.7986\n",
            "Epoch 57 TRAIN Batch 300 Loss 0.5004 Accuracy 74.8523 AUC 0.7986\n",
            "Epoch 57 TRAIN Batch 350 Loss 0.5006 Accuracy 74.8391 AUC 0.7985\n",
            "Epoch 57 TRAIN Batch 400 Loss 0.5005 Accuracy 74.8412 AUC 0.7985\n",
            "Epoch 57 TRAIN Batch 450 Loss 0.5005 Accuracy 74.8369 AUC 0.7986\n",
            "Epoch 57 TRAIN Batch 500 Loss 0.5005 Accuracy 74.8373 AUC 0.7985\n",
            "Epoch 57 TRAIN Batch 550 Loss 0.5005 Accuracy 74.8408 AUC 0.7986\n",
            "Epoch 57 TRAIN Batch 600 Loss 0.5005 Accuracy 74.8479 AUC 0.7986\n",
            "Epoch 57 TRAIN Batch 650 Loss 0.5002 Accuracy 74.8722 AUC 0.7988\n",
            "Epoch 57 TRAIN Batch 700 Loss 0.5001 Accuracy 74.8773 AUC 0.7988\n",
            "Epoch 57 TRAIN Batch 750 Loss 0.5000 Accuracy 74.8800 AUC 0.7988\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "31-12 15:06 root         INFO     Epoch TRAIN 57 Loss 0.5001 Accuracy 74.8761 AUC 0.7988\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time taken for 1 epoch: 194.44882678985596 secs\n",
            "\n",
            "Epoch 58 TRAIN Batch 0 Loss 0.4944 Accuracy 75.5129 AUC 0.8005\n",
            "Epoch 58 TRAIN Batch 50 Loss 0.5016 Accuracy 74.7911 AUC 0.7979\n",
            "Epoch 58 TRAIN Batch 100 Loss 0.4995 Accuracy 74.9404 AUC 0.7990\n",
            "Epoch 58 TRAIN Batch 150 Loss 0.4990 Accuracy 74.9533 AUC 0.7992\n",
            "Epoch 58 TRAIN Batch 200 Loss 0.4989 Accuracy 74.9346 AUC 0.7994\n",
            "Epoch 58 TRAIN Batch 250 Loss 0.4992 Accuracy 74.9081 AUC 0.7991\n",
            "Epoch 58 TRAIN Batch 300 Loss 0.4994 Accuracy 74.8944 AUC 0.7991\n",
            "Epoch 58 TRAIN Batch 350 Loss 0.4996 Accuracy 74.8782 AUC 0.7990\n",
            "Epoch 58 TRAIN Batch 400 Loss 0.4997 Accuracy 74.8754 AUC 0.7990\n",
            "Epoch 58 TRAIN Batch 450 Loss 0.4997 Accuracy 74.8761 AUC 0.7990\n",
            "Epoch 58 TRAIN Batch 500 Loss 0.4997 Accuracy 74.8768 AUC 0.7989\n",
            "Epoch 58 TRAIN Batch 550 Loss 0.4998 Accuracy 74.8751 AUC 0.7990\n",
            "Epoch 58 TRAIN Batch 600 Loss 0.4998 Accuracy 74.8688 AUC 0.7989\n",
            "Epoch 58 TRAIN Batch 650 Loss 0.4999 Accuracy 74.8626 AUC 0.7988\n",
            "Epoch 58 TRAIN Batch 700 Loss 0.4998 Accuracy 74.8718 AUC 0.7988\n",
            "Epoch 58 TRAIN Batch 750 Loss 0.4999 Accuracy 74.8694 AUC 0.7988\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "31-12 15:09 root         INFO     Epoch TRAIN 58 Loss 0.4998 Accuracy 74.8781 AUC 0.7988\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time taken for 1 epoch: 196.05621099472046 secs\n",
            "\n",
            "Epoch 59 TRAIN Batch 0 Loss 0.4866 Accuracy 75.7632 AUC 0.8079\n",
            "Epoch 59 TRAIN Batch 50 Loss 0.4998 Accuracy 74.8597 AUC 0.7988\n",
            "Epoch 59 TRAIN Batch 100 Loss 0.4995 Accuracy 74.9028 AUC 0.7993\n",
            "Epoch 59 TRAIN Batch 150 Loss 0.4997 Accuracy 74.9131 AUC 0.7989\n",
            "Epoch 59 TRAIN Batch 200 Loss 0.4998 Accuracy 74.9117 AUC 0.7988\n",
            "Epoch 59 TRAIN Batch 250 Loss 0.4994 Accuracy 74.9382 AUC 0.7990\n",
            "Epoch 59 TRAIN Batch 300 Loss 0.4996 Accuracy 74.9251 AUC 0.7989\n",
            "Epoch 59 TRAIN Batch 350 Loss 0.4996 Accuracy 74.9182 AUC 0.7989\n",
            "Epoch 59 TRAIN Batch 400 Loss 0.4997 Accuracy 74.9070 AUC 0.7990\n",
            "Epoch 59 TRAIN Batch 450 Loss 0.4996 Accuracy 74.9158 AUC 0.7991\n",
            "Epoch 59 TRAIN Batch 500 Loss 0.4996 Accuracy 74.9222 AUC 0.7991\n",
            "Epoch 59 TRAIN Batch 550 Loss 0.4997 Accuracy 74.9153 AUC 0.7992\n",
            "Epoch 59 TRAIN Batch 600 Loss 0.4998 Accuracy 74.9023 AUC 0.7990\n",
            "Epoch 59 TRAIN Batch 650 Loss 0.4998 Accuracy 74.9081 AUC 0.7991\n",
            "Epoch 59 TRAIN Batch 700 Loss 0.4997 Accuracy 74.9106 AUC 0.7990\n",
            "Epoch 59 TRAIN Batch 750 Loss 0.4997 Accuracy 74.9112 AUC 0.7990\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "31-12 15:13 root         INFO     Epoch TRAIN 59 Loss 0.4998 Accuracy 74.9035 AUC 0.7989\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time taken for 1 epoch: 194.8657991886139 secs\n",
            "\n",
            "Epoch 60 TRAIN Batch 0 Loss 0.5088 Accuracy 74.8305 AUC 0.7914\n",
            "Epoch 60 TRAIN Batch 50 Loss 0.5002 Accuracy 74.8836 AUC 0.7986\n",
            "Epoch 60 TRAIN Batch 100 Loss 0.4997 Accuracy 74.9094 AUC 0.7992\n",
            "Epoch 60 TRAIN Batch 150 Loss 0.4996 Accuracy 74.9137 AUC 0.7995\n",
            "Epoch 60 TRAIN Batch 200 Loss 0.4996 Accuracy 74.9184 AUC 0.7992\n",
            "Epoch 60 TRAIN Batch 250 Loss 0.5000 Accuracy 74.8831 AUC 0.7990\n",
            "Epoch 60 TRAIN Batch 300 Loss 0.5000 Accuracy 74.8892 AUC 0.7989\n",
            "Epoch 60 TRAIN Batch 350 Loss 0.4998 Accuracy 74.9004 AUC 0.7990\n",
            "Epoch 60 TRAIN Batch 400 Loss 0.4999 Accuracy 74.8916 AUC 0.7990\n",
            "Epoch 60 TRAIN Batch 450 Loss 0.5000 Accuracy 74.8860 AUC 0.7989\n",
            "Epoch 60 TRAIN Batch 500 Loss 0.5000 Accuracy 74.8823 AUC 0.7989\n",
            "Epoch 60 TRAIN Batch 550 Loss 0.5000 Accuracy 74.8828 AUC 0.7989\n",
            "Epoch 60 TRAIN Batch 600 Loss 0.4999 Accuracy 74.8922 AUC 0.7990\n",
            "Epoch 60 TRAIN Batch 650 Loss 0.5000 Accuracy 74.8854 AUC 0.7990\n",
            "Epoch 60 TRAIN Batch 700 Loss 0.5000 Accuracy 74.8827 AUC 0.7990\n",
            "Epoch 60 TRAIN Batch 750 Loss 0.4999 Accuracy 74.8853 AUC 0.7990\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "31-12 15:16 root         INFO     Epoch TRAIN 60 Loss 0.5000 Accuracy 74.8797 AUC 0.7989\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 60 VAL Batch 0 Loss 0.4956 Accuracy 74.9130 AUC 0.8080\n",
            "Epoch 60 VAL Batch 50 Loss 0.4980 Accuracy 75.0007 AUC 0.7999\n",
            "Epoch 60 VAL Batch 100 Loss 0.4982 Accuracy 75.0047 AUC 0.7999\n",
            "Epoch 60 VAL Batch 150 Loss 0.4979 Accuracy 75.0277 AUC 0.7995\n",
            "Epoch 60 VAL Batch 200 Loss 0.4983 Accuracy 75.0065 AUC 0.7992\n",
            "Epoch 60 VAL Batch 250 Loss 0.4982 Accuracy 75.0178 AUC 0.7993\n",
            "Epoch 60 VAL Batch 300 Loss 0.4985 Accuracy 75.0050 AUC 0.7991\n",
            "Epoch 60 VAL Batch 350 Loss 0.4986 Accuracy 74.9912 AUC 0.7990\n",
            "Epoch 60 VAL Batch 400 Loss 0.4988 Accuracy 74.9721 AUC 0.7989\n",
            "Epoch 60 VAL Batch 450 Loss 0.4990 Accuracy 74.9560 AUC 0.7989\n",
            "Epoch 60 VAL Batch 500 Loss 0.4991 Accuracy 74.9496 AUC 0.7988\n",
            "Epoch 60 VAL Batch 550 Loss 0.4992 Accuracy 74.9500 AUC 0.7987\n",
            "Epoch 60 VAL Batch 600 Loss 0.4991 Accuracy 74.9556 AUC 0.7988\n",
            "Epoch 60 VAL Batch 650 Loss 0.4991 Accuracy 74.9531 AUC 0.7988\n",
            "Epoch 60 VAL Batch 700 Loss 0.4990 Accuracy 74.9582 AUC 0.7988\n",
            "Epoch 60 VAL Batch 750 Loss 0.4990 Accuracy 74.9570 AUC 0.7988\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "31-12 15:16 root         INFO     Epoch VAL 60 Loss 0.4990 Accuracy 74.9537 AUC 0.7988\n",
            "31-12 15:16 root         INFO     Saving checkpoint for epoch 60 at 31-Dec-riiid-3/checkpoints/ckpt-12\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time taken for 1 epoch: 217.22513628005981 secs\n",
            "\n",
            "Epoch 61 TRAIN Batch 0 Loss 0.4993 Accuracy 74.4788 AUC 0.8016\n",
            "Epoch 61 TRAIN Batch 50 Loss 0.5001 Accuracy 74.8448 AUC 0.7980\n",
            "Epoch 61 TRAIN Batch 100 Loss 0.5000 Accuracy 74.8629 AUC 0.7986\n",
            "Epoch 61 TRAIN Batch 150 Loss 0.5001 Accuracy 74.8725 AUC 0.7985\n",
            "Epoch 61 TRAIN Batch 200 Loss 0.4997 Accuracy 74.8890 AUC 0.7989\n",
            "Epoch 61 TRAIN Batch 250 Loss 0.4995 Accuracy 74.9138 AUC 0.7992\n",
            "Epoch 61 TRAIN Batch 300 Loss 0.4997 Accuracy 74.8938 AUC 0.7991\n",
            "Epoch 61 TRAIN Batch 350 Loss 0.4997 Accuracy 74.8956 AUC 0.7991\n",
            "Epoch 61 TRAIN Batch 400 Loss 0.4997 Accuracy 74.8944 AUC 0.7991\n",
            "Epoch 61 TRAIN Batch 450 Loss 0.4999 Accuracy 74.8791 AUC 0.7990\n",
            "Epoch 61 TRAIN Batch 500 Loss 0.5000 Accuracy 74.8768 AUC 0.7990\n",
            "Epoch 61 TRAIN Batch 550 Loss 0.4999 Accuracy 74.8789 AUC 0.7990\n",
            "Epoch 61 TRAIN Batch 600 Loss 0.4999 Accuracy 74.8838 AUC 0.7990\n",
            "Epoch 61 TRAIN Batch 650 Loss 0.4998 Accuracy 74.8881 AUC 0.7991\n",
            "Epoch 61 TRAIN Batch 700 Loss 0.4999 Accuracy 74.8871 AUC 0.7991\n",
            "Epoch 61 TRAIN Batch 750 Loss 0.4999 Accuracy 74.8862 AUC 0.7991\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "31-12 15:20 root         INFO     Epoch TRAIN 61 Loss 0.4999 Accuracy 74.8823 AUC 0.7990\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time taken for 1 epoch: 193.8173747062683 secs\n",
            "\n",
            "Epoch 62 TRAIN Batch 0 Loss 0.4920 Accuracy 75.0385 AUC 0.7999\n",
            "Epoch 62 TRAIN Batch 50 Loss 0.5001 Accuracy 74.8042 AUC 0.7986\n",
            "Epoch 62 TRAIN Batch 100 Loss 0.5009 Accuracy 74.7757 AUC 0.7985\n",
            "Epoch 62 TRAIN Batch 150 Loss 0.5006 Accuracy 74.8222 AUC 0.7986\n",
            "Epoch 62 TRAIN Batch 200 Loss 0.5006 Accuracy 74.8106 AUC 0.7984\n",
            "Epoch 62 TRAIN Batch 250 Loss 0.5010 Accuracy 74.7935 AUC 0.7984\n",
            "Epoch 62 TRAIN Batch 300 Loss 0.5008 Accuracy 74.8161 AUC 0.7986\n",
            "Epoch 62 TRAIN Batch 350 Loss 0.5008 Accuracy 74.8183 AUC 0.7985\n",
            "Epoch 62 TRAIN Batch 400 Loss 0.5008 Accuracy 74.8206 AUC 0.7985\n",
            "Epoch 62 TRAIN Batch 450 Loss 0.5006 Accuracy 74.8242 AUC 0.7986\n",
            "Epoch 62 TRAIN Batch 500 Loss 0.5006 Accuracy 74.8259 AUC 0.7985\n",
            "Epoch 62 TRAIN Batch 550 Loss 0.5007 Accuracy 74.8164 AUC 0.7985\n",
            "Epoch 62 TRAIN Batch 600 Loss 0.5007 Accuracy 74.8117 AUC 0.7985\n",
            "Epoch 62 TRAIN Batch 650 Loss 0.5006 Accuracy 74.8188 AUC 0.7984\n",
            "Epoch 62 TRAIN Batch 700 Loss 0.5006 Accuracy 74.8233 AUC 0.7985\n",
            "Epoch 62 TRAIN Batch 750 Loss 0.5003 Accuracy 74.8415 AUC 0.7986\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "31-12 15:23 root         INFO     Epoch TRAIN 62 Loss 0.5003 Accuracy 74.8463 AUC 0.7986\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time taken for 1 epoch: 195.2903289794922 secs\n",
            "\n",
            "Epoch 63 TRAIN Batch 0 Loss 0.5045 Accuracy 74.9834 AUC 0.7969\n",
            "Epoch 63 TRAIN Batch 50 Loss 0.4992 Accuracy 74.8911 AUC 0.8000\n",
            "Epoch 63 TRAIN Batch 100 Loss 0.4994 Accuracy 74.9161 AUC 0.8001\n",
            "Epoch 63 TRAIN Batch 150 Loss 0.4991 Accuracy 74.9452 AUC 0.8000\n",
            "Epoch 63 TRAIN Batch 200 Loss 0.4991 Accuracy 74.9585 AUC 0.8000\n",
            "Epoch 63 TRAIN Batch 250 Loss 0.4993 Accuracy 74.9371 AUC 0.7998\n",
            "Epoch 63 TRAIN Batch 300 Loss 0.4993 Accuracy 74.9340 AUC 0.7997\n",
            "Epoch 63 TRAIN Batch 350 Loss 0.4991 Accuracy 74.9285 AUC 0.7999\n",
            "Epoch 63 TRAIN Batch 400 Loss 0.4991 Accuracy 74.9251 AUC 0.7999\n",
            "Epoch 63 TRAIN Batch 450 Loss 0.4990 Accuracy 74.9311 AUC 0.7999\n",
            "Epoch 63 TRAIN Batch 500 Loss 0.4990 Accuracy 74.9259 AUC 0.7998\n",
            "Epoch 63 TRAIN Batch 550 Loss 0.4991 Accuracy 74.9225 AUC 0.7998\n",
            "Epoch 63 TRAIN Batch 600 Loss 0.4989 Accuracy 74.9389 AUC 0.7999\n",
            "Epoch 63 TRAIN Batch 650 Loss 0.4990 Accuracy 74.9286 AUC 0.7999\n",
            "Epoch 63 TRAIN Batch 700 Loss 0.4991 Accuracy 74.9274 AUC 0.7999\n",
            "Epoch 63 TRAIN Batch 750 Loss 0.4990 Accuracy 74.9288 AUC 0.7998\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "31-12 15:26 root         INFO     Epoch TRAIN 63 Loss 0.4990 Accuracy 74.9292 AUC 0.7997\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time taken for 1 epoch: 196.93451499938965 secs\n",
            "\n",
            "Epoch 64 TRAIN Batch 0 Loss 0.5133 Accuracy 74.2312 AUC 0.7964\n",
            "Epoch 64 TRAIN Batch 50 Loss 0.4989 Accuracy 74.9981 AUC 0.8003\n",
            "Epoch 64 TRAIN Batch 100 Loss 0.4977 Accuracy 75.0939 AUC 0.8010\n",
            "Epoch 64 TRAIN Batch 150 Loss 0.4984 Accuracy 75.0328 AUC 0.8006\n",
            "Epoch 64 TRAIN Batch 200 Loss 0.4988 Accuracy 74.9884 AUC 0.8003\n",
            "Epoch 64 TRAIN Batch 250 Loss 0.4990 Accuracy 74.9648 AUC 0.8000\n",
            "Epoch 64 TRAIN Batch 300 Loss 0.4990 Accuracy 74.9560 AUC 0.7999\n",
            "Epoch 64 TRAIN Batch 350 Loss 0.4991 Accuracy 74.9427 AUC 0.7998\n",
            "Epoch 64 TRAIN Batch 400 Loss 0.4991 Accuracy 74.9422 AUC 0.7998\n",
            "Epoch 64 TRAIN Batch 450 Loss 0.4991 Accuracy 74.9392 AUC 0.7997\n",
            "Epoch 64 TRAIN Batch 500 Loss 0.4989 Accuracy 74.9493 AUC 0.7998\n",
            "Epoch 64 TRAIN Batch 550 Loss 0.4990 Accuracy 74.9420 AUC 0.7997\n",
            "Epoch 64 TRAIN Batch 600 Loss 0.4991 Accuracy 74.9335 AUC 0.7997\n",
            "Epoch 64 TRAIN Batch 650 Loss 0.4991 Accuracy 74.9422 AUC 0.7997\n",
            "Epoch 64 TRAIN Batch 700 Loss 0.4992 Accuracy 74.9319 AUC 0.7996\n",
            "Epoch 64 TRAIN Batch 750 Loss 0.4992 Accuracy 74.9315 AUC 0.7996\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "31-12 15:29 root         INFO     Epoch TRAIN 64 Loss 0.4993 Accuracy 74.9242 AUC 0.7996\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time taken for 1 epoch: 196.97363114356995 secs\n",
            "\n",
            "Epoch 65 TRAIN Batch 0 Loss 0.5201 Accuracy 73.1296 AUC 0.7957\n",
            "Epoch 65 TRAIN Batch 50 Loss 0.4995 Accuracy 74.9104 AUC 0.7998\n",
            "Epoch 65 TRAIN Batch 100 Loss 0.4990 Accuracy 74.9318 AUC 0.7999\n",
            "Epoch 65 TRAIN Batch 150 Loss 0.4989 Accuracy 74.9363 AUC 0.8000\n",
            "Epoch 65 TRAIN Batch 200 Loss 0.4982 Accuracy 74.9883 AUC 0.8004\n",
            "Epoch 65 TRAIN Batch 250 Loss 0.4980 Accuracy 75.0048 AUC 0.8004\n",
            "Epoch 65 TRAIN Batch 300 Loss 0.4981 Accuracy 75.0070 AUC 0.8004\n",
            "Epoch 65 TRAIN Batch 350 Loss 0.4984 Accuracy 74.9898 AUC 0.8002\n",
            "Epoch 65 TRAIN Batch 400 Loss 0.4985 Accuracy 74.9795 AUC 0.8001\n",
            "Epoch 65 TRAIN Batch 450 Loss 0.4986 Accuracy 74.9723 AUC 0.8000\n",
            "Epoch 65 TRAIN Batch 500 Loss 0.4986 Accuracy 74.9672 AUC 0.8001\n",
            "Epoch 65 TRAIN Batch 550 Loss 0.4988 Accuracy 74.9591 AUC 0.8001\n",
            "Epoch 65 TRAIN Batch 600 Loss 0.4990 Accuracy 74.9444 AUC 0.7999\n",
            "Epoch 65 TRAIN Batch 650 Loss 0.4990 Accuracy 74.9410 AUC 0.7998\n",
            "Epoch 65 TRAIN Batch 700 Loss 0.4991 Accuracy 74.9371 AUC 0.7997\n",
            "Epoch 65 TRAIN Batch 750 Loss 0.4991 Accuracy 74.9305 AUC 0.7997\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "31-12 15:33 root         INFO     Epoch TRAIN 65 Loss 0.4991 Accuracy 74.9298 AUC 0.7997\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 65 VAL Batch 0 Loss 0.4955 Accuracy 74.9876 AUC 0.8085\n",
            "Epoch 65 VAL Batch 50 Loss 0.4978 Accuracy 75.0100 AUC 0.8001\n",
            "Epoch 65 VAL Batch 100 Loss 0.4979 Accuracy 75.0058 AUC 0.8002\n",
            "Epoch 65 VAL Batch 150 Loss 0.4976 Accuracy 75.0343 AUC 0.7998\n",
            "Epoch 65 VAL Batch 200 Loss 0.4980 Accuracy 75.0148 AUC 0.7995\n",
            "Epoch 65 VAL Batch 250 Loss 0.4980 Accuracy 75.0294 AUC 0.7996\n",
            "Epoch 65 VAL Batch 300 Loss 0.4983 Accuracy 75.0111 AUC 0.7993\n",
            "Epoch 65 VAL Batch 350 Loss 0.4984 Accuracy 75.0025 AUC 0.7992\n",
            "Epoch 65 VAL Batch 400 Loss 0.4986 Accuracy 74.9805 AUC 0.7991\n",
            "Epoch 65 VAL Batch 450 Loss 0.4989 Accuracy 74.9630 AUC 0.7991\n",
            "Epoch 65 VAL Batch 500 Loss 0.4990 Accuracy 74.9581 AUC 0.7990\n",
            "Epoch 65 VAL Batch 550 Loss 0.4990 Accuracy 74.9602 AUC 0.7989\n",
            "Epoch 65 VAL Batch 600 Loss 0.4989 Accuracy 74.9685 AUC 0.7990\n",
            "Epoch 65 VAL Batch 650 Loss 0.4989 Accuracy 74.9688 AUC 0.7990\n",
            "Epoch 65 VAL Batch 700 Loss 0.4988 Accuracy 74.9744 AUC 0.7990\n",
            "Epoch 65 VAL Batch 750 Loss 0.4988 Accuracy 74.9733 AUC 0.7990\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "31-12 15:33 root         INFO     Epoch VAL 65 Loss 0.4988 Accuracy 74.9685 AUC 0.7990\n",
            "31-12 15:33 root         INFO     Saving checkpoint for epoch 65 at 31-Dec-riiid-3/checkpoints/ckpt-13\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time taken for 1 epoch: 218.52387046813965 secs\n",
            "\n",
            "Epoch 66 TRAIN Batch 0 Loss 0.5006 Accuracy 74.4709 AUC 0.8016\n",
            "Epoch 66 TRAIN Batch 50 Loss 0.4977 Accuracy 75.0179 AUC 0.8006\n",
            "Epoch 66 TRAIN Batch 100 Loss 0.4985 Accuracy 74.9702 AUC 0.8001\n",
            "Epoch 66 TRAIN Batch 150 Loss 0.4984 Accuracy 74.9660 AUC 0.8001\n",
            "Epoch 66 TRAIN Batch 200 Loss 0.4984 Accuracy 74.9696 AUC 0.8004\n",
            "Epoch 66 TRAIN Batch 250 Loss 0.4987 Accuracy 74.9491 AUC 0.8003\n",
            "Epoch 66 TRAIN Batch 300 Loss 0.4989 Accuracy 74.9427 AUC 0.8002\n",
            "Epoch 66 TRAIN Batch 350 Loss 0.4988 Accuracy 74.9542 AUC 0.8001\n",
            "Epoch 66 TRAIN Batch 400 Loss 0.4986 Accuracy 74.9644 AUC 0.8003\n",
            "Epoch 66 TRAIN Batch 450 Loss 0.4987 Accuracy 74.9605 AUC 0.8003\n",
            "Epoch 66 TRAIN Batch 500 Loss 0.4988 Accuracy 74.9568 AUC 0.8002\n",
            "Epoch 66 TRAIN Batch 550 Loss 0.4987 Accuracy 74.9695 AUC 0.8002\n",
            "Epoch 66 TRAIN Batch 600 Loss 0.4988 Accuracy 74.9649 AUC 0.8001\n",
            "Epoch 66 TRAIN Batch 650 Loss 0.4987 Accuracy 74.9641 AUC 0.8001\n",
            "Epoch 66 TRAIN Batch 700 Loss 0.4987 Accuracy 74.9722 AUC 0.8002\n",
            "Epoch 66 TRAIN Batch 750 Loss 0.4988 Accuracy 74.9618 AUC 0.8001\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "31-12 15:36 root         INFO     Epoch TRAIN 66 Loss 0.4988 Accuracy 74.9619 AUC 0.8001\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time taken for 1 epoch: 197.3580710887909 secs\n",
            "\n",
            "Epoch 67 TRAIN Batch 0 Loss 0.5062 Accuracy 74.4856 AUC 0.7916\n",
            "Epoch 67 TRAIN Batch 50 Loss 0.4991 Accuracy 74.9627 AUC 0.7992\n",
            "Epoch 67 TRAIN Batch 100 Loss 0.4994 Accuracy 74.9492 AUC 0.7993\n",
            "Epoch 67 TRAIN Batch 150 Loss 0.4989 Accuracy 74.9532 AUC 0.7998\n",
            "Epoch 67 TRAIN Batch 200 Loss 0.4986 Accuracy 74.9770 AUC 0.8000\n",
            "Epoch 67 TRAIN Batch 250 Loss 0.4987 Accuracy 74.9520 AUC 0.7999\n",
            "Epoch 67 TRAIN Batch 300 Loss 0.4988 Accuracy 74.9396 AUC 0.7998\n",
            "Epoch 67 TRAIN Batch 350 Loss 0.4989 Accuracy 74.9346 AUC 0.7997\n",
            "Epoch 67 TRAIN Batch 400 Loss 0.4987 Accuracy 74.9431 AUC 0.7998\n",
            "Epoch 67 TRAIN Batch 450 Loss 0.4987 Accuracy 74.9464 AUC 0.7997\n",
            "Epoch 67 TRAIN Batch 500 Loss 0.4988 Accuracy 74.9377 AUC 0.7997\n",
            "Epoch 67 TRAIN Batch 550 Loss 0.4986 Accuracy 74.9530 AUC 0.7998\n",
            "Epoch 67 TRAIN Batch 600 Loss 0.4985 Accuracy 74.9556 AUC 0.7999\n",
            "Epoch 67 TRAIN Batch 650 Loss 0.4986 Accuracy 74.9524 AUC 0.7999\n",
            "Epoch 67 TRAIN Batch 700 Loss 0.4985 Accuracy 74.9539 AUC 0.7999\n",
            "Epoch 67 TRAIN Batch 750 Loss 0.4987 Accuracy 74.9399 AUC 0.7999\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "31-12 15:40 root         INFO     Epoch TRAIN 67 Loss 0.4986 Accuracy 74.9458 AUC 0.7999\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time taken for 1 epoch: 197.3019745349884 secs\n",
            "\n",
            "Epoch 68 TRAIN Batch 0 Loss 0.5033 Accuracy 74.6315 AUC 0.7970\n",
            "Epoch 68 TRAIN Batch 50 Loss 0.4964 Accuracy 75.1355 AUC 0.8020\n",
            "Epoch 68 TRAIN Batch 100 Loss 0.4965 Accuracy 75.1286 AUC 0.8017\n",
            "Epoch 68 TRAIN Batch 150 Loss 0.4968 Accuracy 75.0942 AUC 0.8010\n",
            "Epoch 68 TRAIN Batch 200 Loss 0.4969 Accuracy 75.0728 AUC 0.8009\n",
            "Epoch 68 TRAIN Batch 250 Loss 0.4973 Accuracy 75.0497 AUC 0.8009\n",
            "Epoch 68 TRAIN Batch 300 Loss 0.4974 Accuracy 75.0441 AUC 0.8008\n",
            "Epoch 68 TRAIN Batch 350 Loss 0.4974 Accuracy 75.0422 AUC 0.8007\n",
            "Epoch 68 TRAIN Batch 400 Loss 0.4976 Accuracy 75.0290 AUC 0.8005\n",
            "Epoch 68 TRAIN Batch 450 Loss 0.4978 Accuracy 75.0226 AUC 0.8004\n",
            "Epoch 68 TRAIN Batch 500 Loss 0.4979 Accuracy 75.0082 AUC 0.8003\n",
            "Epoch 68 TRAIN Batch 550 Loss 0.4981 Accuracy 74.9967 AUC 0.8003\n",
            "Epoch 68 TRAIN Batch 600 Loss 0.4982 Accuracy 74.9868 AUC 0.8001\n",
            "Epoch 68 TRAIN Batch 650 Loss 0.4982 Accuracy 74.9771 AUC 0.8001\n",
            "Epoch 68 TRAIN Batch 700 Loss 0.4982 Accuracy 74.9774 AUC 0.8001\n",
            "Epoch 68 TRAIN Batch 750 Loss 0.4981 Accuracy 74.9842 AUC 0.8001\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "31-12 15:43 root         INFO     Epoch TRAIN 68 Loss 0.4981 Accuracy 74.9823 AUC 0.8001\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time taken for 1 epoch: 197.47794342041016 secs\n",
            "\n",
            "Epoch 69 TRAIN Batch 0 Loss 0.5087 Accuracy 74.2871 AUC 0.7899\n",
            "Epoch 69 TRAIN Batch 50 Loss 0.4987 Accuracy 74.9981 AUC 0.7993\n",
            "Epoch 69 TRAIN Batch 100 Loss 0.4996 Accuracy 74.8977 AUC 0.7985\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4vnYx13H1gX"
      },
      "source": [
        "from IPython.display import FileLink, FileLinks\n",
        "FileLinks(OUTPUT_FOLDER) #lists all downloadable files on server"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_rWpnRgyiyC"
      },
      "source": [
        "## Add output to Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ph8Un94HsahC"
      },
      "source": [
        "OUTPUT_DRIVE = \"/content/drive/My Drive/kaggle-riiid/subs\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eglhQhuZsqyw"
      },
      "source": [
        "# https://stackoverflow.com/questions/15034151/copy-directory-contents-into-a-directory-with-python\n",
        "from distutils.dir_util import copy_tree\n",
        "copy_tree(OUTPUT_FOLDER, os.path.join(OUTPUT_DRIVE, OUTPUT_FOLDER))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Lzwa2GGzqAT"
      },
      "source": [
        "## Add output to Kaggle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOu1E5Xop-57"
      },
      "source": [
        "KAGGLE_JSON = \"/content/drive/My\\ Drive/kaggle-riiid/kaggle.json\"\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp $KAGGLE_JSON ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0N2cmXLygls"
      },
      "source": [
        "!kaggle datasets init -p {OUTPUT_FOLDER}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbCedVa7z5M-"
      },
      "source": [
        "import json\n",
        "\n",
        "with open(f'{OUTPUT_FOLDER}/dataset-metadata.json', 'r+') as f:\n",
        "    data = json.load(f)\n",
        "    data['title'] = OUTPUT_FOLDER\n",
        "    data['id'] = f'rafiko1/{OUTPUT_FOLDER}'\n",
        "    f.seek(0)\n",
        "    json.dump(data, f, indent=4)\n",
        "    f.truncate()\n",
        "\n",
        "!cat {OUTPUT_FOLDER}/dataset-metadata.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QiYmcZ0r0hoh"
      },
      "source": [
        "!kaggle datasets create -p {OUTPUT_FOLDER} -q -r zip "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfFKlQG5KL09"
      },
      "source": [
        "os.listdir(OUTPUT_FOLDER)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rfa2BsoE29sJ"
      },
      "source": [
        "ltg_bins"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqQ1fIsLwkGE"
      },
      "source": [
        "## Summary\n",
        "\n",
        "In this tutorial, you learned about positional encoding, multi-head attention, the importance of masking and how to create a transformer.\n",
        "\n",
        "Try using a different dataset to train the transformer. You can also create the base transformer or transformer XL by changing the hyperparameters above. You can also use the layers defined here to create [BERT](https://arxiv.org/abs/1810.04805) and train state of the art models. Futhermore, you can implement beam search to get better predictions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ob_U1TjRE6A-"
      },
      "source": [
        "# Older code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCPtV7asE7w_"
      },
      "source": [
        "# # From https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly\n",
        "# class DataGenerator(keras.utils.Sequence):\n",
        "#     'Generates data for Keras'\n",
        "#     def __init__(self, df, shuffle=True):\n",
        "#         'Initialization'\n",
        "        \n",
        "#         self.df = df\n",
        "#         self.users = self.df[\"user_id\"].nunique()\n",
        "#         self.batch_size = BATCH_SIZE\n",
        "#         self.shuffle = shuffle\n",
        "#         self.on_epoch_end()\n",
        "\n",
        "#     def __len__(self):\n",
        "#         'Denotes the number of batches per epoch'\n",
        "#         return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
        "\n",
        "#     def __getitem__(self, index):\n",
        "#         'Generate one batch of data'\n",
        "#         # Generate indexes of the batch\n",
        "#         indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "\n",
        "#         # Find list of IDs\n",
        "#         list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
        "\n",
        "#         # Generate data\n",
        "#         X, y = self.__data_generation(list_IDs_temp)\n",
        "\n",
        "#         return X, y\n",
        "\n",
        "#     def on_epoch_end(self):\n",
        "#         'Updates indexes after each epoch'\n",
        "#         self.indexes = np.arange(len(self.list_IDs))\n",
        "#         if self.shuffle == True:\n",
        "#             np.random.shuffle(self.indexes)\n",
        "\n",
        "#     def __data_generation(self, list_IDs_temp):\n",
        "#         'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
        "#         # Initialization\n",
        "#         X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
        "#         y = np.empty((self.batch_size), dtype=int)\n",
        "\n",
        "#         # Generate data\n",
        "#         for i, ID in enumerate(list_IDs_temp):\n",
        "#             # Store sample\n",
        "#             X[i,] = np.load('data/' + ID + '.npy')\n",
        "\n",
        "#             # Store class\n",
        "#             y[i] = self.labels[ID]\n",
        "\n",
        "#         return X, keras.utils.to_categorical(y, num_classes=self.n_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrylowI_ThEY"
      },
      "source": [
        "# def save_dict(seq_dict, filename):\n",
        "#     with open(os.path.join(OUTPUT_FOLDER, filename), 'wb') as handle:\n",
        "#       pickle.dump(seq_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTwScXwCThEY"
      },
      "source": [
        "# # Save last N dict to memory\n",
        "# E_dict = E_lists.apply(lambda x: x[-200:]).to_dict()\n",
        "# r_dict = r_lists.apply(lambda x: x[-200:]).to_dict()\n",
        "# et_dict = et_lists.apply(lambda x: x[-200:]).to_dict()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbXwrK5eThEY"
      },
      "source": [
        "# save_dict(E_dict, \"E.pkl\")\n",
        "# save_dict(r_dict, \"r.pkl\")\n",
        "# save_dict(et_dict, \"et.pkl\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}