{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 876,
     "status": "ok",
     "timestamp": 1608897792892,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "Fc59RMwUderb"
   },
   "outputs": [],
   "source": [
    "# Models\n",
    "# --------\n",
    "# RIIID PyTorch Transformer (SAINT-like)\n",
    "\n",
    "# CV=0.7901, LB=0.795\n",
    "# Trained Weights: fold1/stage2/snapshots/model_best.pt\n",
    "# Remove weights to start training from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:98% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2082,
     "status": "ok",
     "timestamp": 1608897794161,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "0ywGleXmderl"
   },
   "outputs": [],
   "source": [
    "import os, sys, random, gc, math, glob, time, pathlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import io, timeit, os, gc, pickle, psutil\n",
    "from multiprocessing import Pool\n",
    "from tqdm.notebook import tqdm\n",
    "import joblib\n",
    "from matplotlib import cm\n",
    "from datetime import datetime, timedelta\n",
    "import re, shutil\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, QuantileTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, TimeSeriesSplit, KFold, GroupKFold, ShuffleSplit\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "from joblib import Parallel, delayed\n",
    "from functools import partial\n",
    "from collections import OrderedDict, defaultdict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 4000)\n",
    "pd.options.display.float_format = '{:,.6f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2305,
     "status": "ok",
     "timestamp": 1608897794389,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "LJuktKAwderr"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "DEFAULT_FIG_WIDTH = 28 # 20\n",
    "sns.set_context(\"paper\", font_scale=1.2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2874,
     "status": "ok",
     "timestamp": 1608897794970,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "9JQoIgU0sDbm"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler, RandomSampler, SequentialSampler\n",
    "from torchvision import transforms, utils\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import Adam, SGD, AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2863,
     "status": "ok",
     "timestamp": 1608897794971,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "KrM_e3D3derw",
    "outputId": "29cc8b1a-4cd9-49f7-b691-efccfd4427e3"
   },
   "outputs": [],
   "source": [
    "print('Python     : ' + sys.version.split('\\n')[0])\n",
    "print('Numpy      : ' + np.__version__)\n",
    "print('Pandas     : ' + pd.__version__)\n",
    "print('PyTorch    : ' + torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2854,
     "status": "ok",
     "timestamp": 1608897794972,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "KOZb1yO7EFOX"
   },
   "outputs": [],
   "source": [
    "def seed_everything(s):\n",
    "    random.seed(s)\n",
    "    os.environ['PYTHONHASHSEED'] = str(s)\n",
    "    np.random.seed(s)\n",
    "    # Torch\n",
    "    torch.manual_seed(s)\n",
    "    torch.cuda.manual_seed(s)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(s)\n",
    "\n",
    "seed = 2020\n",
    "seed_everything(seed)\n",
    "RANDOM = np.random.RandomState(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2849,
     "status": "ok",
     "timestamp": 1608897794972,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "eF_LBBxiXZv8",
    "outputId": "2b3a3df3-2319-489d-8267-232ccd1854ce"
   },
   "outputs": [],
   "source": [
    "#DEVICE = \"cpu\"\n",
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print('Running on device: {}'.format(DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2825,
     "status": "ok",
     "timestamp": 1608897794972,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "hGn0BU1jzWJo"
   },
   "outputs": [],
   "source": [
    "ROW_ID = \"row_id\"\n",
    "\n",
    "CONTENT_TYPE_ID = \"content_type_id\" # False = Question, True = Lecture\n",
    "CONTENT_ID = \"content_id\" # Question/Lecture id\n",
    "ANSWERED_CORRECTLY = \"answered_correctly\" # -1 for lecture\n",
    "USER_ID = \"user_id\" # User unique identifier (around 400k users)\n",
    "TASK_CONTAINER_ID = \"task_container_id\"\n",
    "TIMESTAMP = \"timestamp\" # the time between this user interaction and the first event from that user\n",
    "USER_ANSWER = \"user_answer\" # Can be compared with correct_answer\n",
    "PRIOR_QUESTION_ELAPSED_TIME = \"prior_question_elapsed_time\" # the time is the total time a user took to solve all the questions in the previous bundle.\n",
    "PRIOR_QUESTION_HAD_EXPLANATION = \"prior_question_had_explanation\"\n",
    "\n",
    "# Questions\n",
    "QUESTION_ID = \"question_id\" # foreign key for the train/test content_id column, when the content type is question\n",
    "BUNDLE_ID = \"bundle_id\" # code for which questions are served together\n",
    "CORRECT_ANSWER = \"correct_answer\" # the answer to the question. Can be compared with the train user_answer column to check if the user was right.\n",
    "PART = \"part\" # top level category code for the question\n",
    "TAGS = \"tags\" # one or more detailed tag codes for the question. The meaning of the tags will not be provided, but these codes are sufficient for clustering the questions together\n",
    "TAGS_COMBO = \"tags_combo\"\n",
    "\n",
    "# Lectures\n",
    "TAG = \"tag\"\n",
    "LECTURE_ID = \"lecture_id\"\n",
    "TYPE_OF = \"type_of\"\n",
    "\n",
    "SECTION = \"section\"\n",
    "RANK = \"rank\"\n",
    "LAG = \"lag\"\n",
    "\n",
    "TARGET = ANSWERED_CORRECTLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2816,
     "status": "ok",
     "timestamp": 1608897794973,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "8A-d2NL1PNy_"
   },
   "outputs": [],
   "source": [
    "FEATURES = [CONTENT_ID, TARGET, PART, PRIOR_QUESTION_ELAPSED_TIME, LAG, PRIOR_QUESTION_HAD_EXPLANATION]\n",
    "\n",
    "# Sampler\n",
    "MAX_INTERACTIONS_CAP = 2*50000\n",
    "\n",
    "MIN_INTERACTIONS_TRAIN = 3\n",
    "MAX_INTERACTIONS_TRAIN = MAX_INTERACTIONS_CAP\n",
    "MIN_INTERACTIONS_VALID = 3\n",
    "MAX_INTERACTIONS_VALID = MAX_INTERACTIONS_CAP\n",
    "\n",
    "PIVOT_TS = False\n",
    "GROUPED = True\n",
    "LECTURES_ENABLED = False \n",
    "DUMP = False # True (on first run to dump features)\n",
    "TRAIN_SPLIT_LEN = 288\n",
    "META = [] # [ROW_ID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2806,
     "status": "ok",
     "timestamp": 1608897794973,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "Twz8rN7qd-qs"
   },
   "outputs": [],
   "source": [
    "class MaskedBCEWithLogitsLoss(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        if self.num_classes > 1:\n",
    "            self.loss_ce = nn.CrossEntropyLoss() # Input: (N, C) Target: (N)  0 <= target[i] <= C-1 \n",
    "        else:\n",
    "            self.loss_ce = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def forward(self, input, target, mask=None):\n",
    "        if self.num_classes > 1:\n",
    "            input_ = input # Already flatten (BS*seq_len, C)\n",
    "            target_ = target # Already flatten (BS*seq_len)\n",
    "            if mask is not None:\n",
    "                input_ = input_[mask == False]\n",
    "                target_ = target_[mask == False]\n",
    "        else:\n",
    "            # Flatten to (BS*seq_len)\n",
    "            input_ = input.reshape(-1)\n",
    "            target_ = target.reshape(-1)\n",
    "            if mask is not None:\n",
    "                mask_ = mask.reshape(-1)\n",
    "                input_ = input_[mask_ == False]\n",
    "                target_ = target_[mask_ == False]\n",
    "\n",
    "        return self.loss_ce(input_, target_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2798,
     "status": "ok",
     "timestamp": 1608897794974,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "5mSs5ueDJI4G"
   },
   "outputs": [],
   "source": [
    "class raw_conf:\n",
    "\n",
    "    mtype = \"SAINT\"\n",
    "    backbone = \"transformer\" \n",
    "\n",
    "    pad_mode = \"token\" # \"random\" # \"reflect\" # \"token\"\n",
    "    pad_right = True\n",
    "    flatten = True\n",
    "    sampler = None # \"prob\" # \"random\"\n",
    "\n",
    "    seq_len = 256 # 100\n",
    "    embedding_dim = 256 # embed_dim must be divisible by num_heads\n",
    "    exercices_id_size = 13523 if LECTURES_ENABLED is False else (13523 + 418) # LECTURES do not help\n",
    "    exercices_part_size = 7 if PART in FEATURES else None\n",
    "    response_size = 3 if LECTURES_ENABLED is True else 2 \n",
    "    elapsed_time_max_size = 300 if PRIOR_QUESTION_ELAPSED_TIME in FEATURES else None\n",
    "    elapsed_time_size = 73 if PRIOR_QUESTION_ELAPSED_TIME in FEATURES else None\n",
    "    elapsed_time_cat = True # False\n",
    "    lag_time_cat = True\n",
    "    lag_time_max_size = 1440 if LAG in FEATURES else None\n",
    "    lag_time_size = 366 if lag_time_cat is True else 0.0\n",
    "    explanation_size = 2 if PRIOR_QUESTION_HAD_EXPLANATION in FEATURES else None\n",
    "    position_encoding_enabled = True\n",
    "    \n",
    "    # Model\n",
    "    nhead = 8 # 4\n",
    "    num_encoder_layers = 4\n",
    "    num_decoder_layers = 4\n",
    "    dim_feedforward = 2048\n",
    "    dropout = 0.1\n",
    "    activation = None\n",
    "    num_classes = 1\n",
    "    loss = MaskedBCEWithLogitsLoss(num_classes)\n",
    "    post_activation = \"sigmoid\" if num_classes == 1 else \"softmax\"\n",
    "    post_activation_dim = 1 if post_activation == \"sigmoid\" else 2\n",
    "    custom_encoder = True # False # It removes one BatchNorm\n",
    "    custom_decoder = True # False # It removes one BatchNorm\n",
    "    \n",
    "    optimizer = \"Adam\" # \"Noam\" for stage1 # \"Adam\" for stage2\n",
    "    warm_up_step_count = 10*1000\n",
    "    warm_up_scale = 1.5\n",
    "    scheduler = \"Cosine\" if optimizer == \"Adam\" or optimizer == \"SGD\"  else None\n",
    "    lr = 0.0001 if optimizer == \"Adam\" or optimizer == \"Noam\" else 0.05 # 0.0012 # 0.0003\n",
    "    min_lr = 0.00005 if optimizer == \"Adam\" or optimizer == \"Noam\" else 0.03 # .000005 # 0.0001\n",
    "    beta1 = 0.9\n",
    "    train_verbose = True # False\n",
    "    valid_verbose = True # False\n",
    "    train_probs_threshold = 0.5\n",
    "    METRIC_ = \"max\"\n",
    "\n",
    "    L_DEVICE = DEVICE\n",
    "    WORKERS = 0 # 4 # 0\n",
    "    BATCH_SIZE = 128\n",
    "    ITERATIONS_LOGS = 50 # 1\n",
    "    CYCLES = 3\n",
    "    EPOCHS_PER_CYCLE = 12\n",
    "    EPOCHS = CYCLES * EPOCHS_PER_CYCLE\n",
    "\n",
    "    pin_memory = True\n",
    "\n",
    "conf = raw_conf()\n",
    "if torch.cuda.is_available():\n",
    "    conf.map_location=lambda storage, loc: storage.cuda()\n",
    "else:\n",
    "    conf.map_location='cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "executionInfo": {
     "elapsed": 3319,
     "status": "ok",
     "timestamp": 1608897795506,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "7DPmDi26gcHM",
    "outputId": "386092f0-bd0b-4066-d56d-9b2b263915f4"
   },
   "outputs": [],
   "source": [
    "step = np.arange(1, 12000)\n",
    "lr = conf.embedding_dim**(-0.5) * np.minimum(step**(-0.5)/(conf.warm_up_scale), step*(conf.warm_up_step_count**(-1.5)))\n",
    "d = plt.plot(lr)\n",
    "d = plt.title(max(lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3307,
     "status": "ok",
     "timestamp": 1608897795506,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "HUy5bbc2RCxw"
   },
   "outputs": [],
   "source": [
    "def save_dict(tmp_dict, filename):\n",
    "    pickle.dump(tmp_dict, open(filename, 'wb'))\n",
    "\n",
    "def load_dict(filename):\n",
    "    return pickle.load(tmp_dict, open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3302,
     "status": "ok",
     "timestamp": 1608897795507,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "ngnRMr2oder3"
   },
   "outputs": [],
   "source": [
    "HOME = \"./\"\n",
    "DATA_HOME =\"./data/\" \n",
    "TRAIN_DATA_HOME = DATA_HOME\n",
    "\n",
    "FEATURES_NAME = \"features_saint_qcut_256\"\n",
    "TRAIN_FEATURES_PATH = HOME + FEATURES_NAME + \"/\"\n",
    "TRAIN_FILE_LECTURES = TRAIN_DATA_HOME + \"lectures.parquet\"\n",
    "TRAIN_FILE_QUESTIONS = TRAIN_DATA_HOME + \"questions.parquet\"\n",
    "\n",
    "MODEL_NAME = \"%s_%s_%d_%d_%s_%s_v13.4\" % (conf.mtype, conf.backbone, conf.seq_len, conf.embedding_dim, conf.post_activation, \"Q\" if LECTURES_ENABLED is False else \"QL\")\n",
    "MODEL_PATH = HOME + MODEL_NAME\n",
    "STAGE = \"stage3\" # \"stage1\"\n",
    "MODEL_BEST = 'model_best.pt'\n",
    "\n",
    "if not os.path.exists(MODEL_PATH):\n",
    "    os.makedirs(MODEL_PATH)\n",
    "\n",
    "TRAIN = True # True # True\n",
    "RESUME_FOLD = 0\n",
    "RESUME = True # False # True\n",
    "PRETRAINED = None\n",
    "PRETRAINED_STAGE = \"stage2\" # None #\n",
    "FREEZE_BACKBONE = False # True\n",
    "PRETRAINED_BACKBONE_STAGE = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3521,
     "status": "ok",
     "timestamp": 1608897795745,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "Ur5PFZxa5SUR"
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "train_pd = None\n",
    "FOLD = 1\n",
    "if not os.path.exists(TRAIN_FEATURES_PATH + \"train_cleaned.pkl\"):\n",
    "    train_pd = pd.read_pickle(DATA_HOME + \"cv%d_train.pickle\" % FOLD)\n",
    "    train_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "executionInfo": {
     "elapsed": 3877,
     "status": "ok",
     "timestamp": 1608897796114,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "PJPfrCYYKz8V",
    "outputId": "c6e34a20-10d1-42bf-f3e1-9f93f4fd22b3"
   },
   "outputs": [],
   "source": [
    "# Load question data\n",
    "def load_questions():\n",
    "    train_questions_pd = pd.read_parquet(TRAIN_FILE_QUESTIONS)\n",
    "    train_questions_pd[PART] = train_questions_pd[PART].astype(np.int8)\n",
    "    train_questions_pd[BUNDLE_ID] = train_questions_pd[BUNDLE_ID].astype(np.int32)\n",
    "    tag = train_questions_pd[TAGS].str.split(\" \", n = 10, expand = True) \n",
    "    tag.columns = ['tags1','tags2','tags3','tags4','tags5','tags6']\n",
    "    train_questions_pd =  pd.concat([train_questions_pd,tag], axis=1)\n",
    "    train_questions_pd['tags1'] = train_questions_pd['tags1'].astype(np.float32).astype('Int16')\n",
    "    train_questions_pd['tags2'] = train_questions_pd['tags2'].astype(np.float32).astype('Int16')\n",
    "    train_questions_pd['tags3'] = train_questions_pd['tags3'].astype(np.float32).astype('Int16')\n",
    "    train_questions_pd[SECTION] = 3\n",
    "    train_questions_pd.loc[(train_questions_pd[PART] >= 5) & (train_questions_pd[PART] <= 7), SECTION] = 2\n",
    "    train_questions_pd.loc[(train_questions_pd[PART] >= 1) & (train_questions_pd[PART] <= 4), SECTION] = 1\n",
    "    train_questions_pd[SECTION] = train_questions_pd[SECTION].astype(np.int8)\n",
    "    train_questions_pd.rename(columns={\"question_id\": CONTENT_ID}, inplace=True)\n",
    "\n",
    "    unique_tags_combos_keys = {v:i for i,v in enumerate(train_questions_pd[TAGS].unique())} # '51 131 162 38': 0, '131 36 81': 1, ...\n",
    "    train_questions_pd[TAGS_COMBO] = train_questions_pd[TAGS].apply(lambda x : unique_tags_combos_keys[x])\n",
    "    train_questions_pd[TAGS_COMBO] = pd.to_numeric(train_questions_pd[TAGS_COMBO], downcast='integer')\n",
    "\n",
    "    for col in [\"tags1\", \"tags2\", \"tags3\", \"tags4\", \"tags5\", \"tags6\"]:\n",
    "        if col in train_questions_pd.columns:\n",
    "            train_questions_pd[col] = train_questions_pd[col].astype('category').cat.codes\n",
    "    train_questions_pd.drop(columns=[TAGS, CORRECT_ANSWER, TAGS_COMBO, BUNDLE_ID, \"tags2\", \"tags3\", \"tags4\", \"tags5\", \"tags6\", SECTION], inplace=True)\n",
    "    return train_questions_pd\n",
    "\n",
    "questions_df = load_questions()\n",
    "print(questions_df[CONTENT_ID].min(), questions_df[CONTENT_ID].max(), questions_df[CONTENT_ID].nunique())\n",
    "questions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "executionInfo": {
     "elapsed": 3866,
     "status": "ok",
     "timestamp": 1608897796115,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "iQTDJhCrXluc",
    "outputId": "a21a013c-ef42-42a2-d95d-3040342ea438"
   },
   "outputs": [],
   "source": [
    "typeof_dict = {\n",
    "    'concept': 0,\n",
    "    'solving question': 1,\n",
    "    'intention': 2,\n",
    "    'starter': 3,\n",
    "}\n",
    "\n",
    "def load_lectures():\n",
    "    # Content-id in lectures DOES NOT match to contentid in questions\n",
    "    train_lectures_pd = pd.read_parquet(TRAIN_FILE_LECTURES)\n",
    "    train_lectures_pd[PART] = train_lectures_pd[PART].astype(np.int8)\n",
    "    train_lectures_pd[TYPE_OF] = train_lectures_pd[TYPE_OF].map(typeof_dict)\n",
    "    train_lectures_pd.rename(columns={\"lecture_id\": CONTENT_ID}, inplace=True)\n",
    "    train_lectures_pd.drop(columns=[TAG, TYPE_OF], inplace=True)\n",
    "    return train_lectures_pd\n",
    "\n",
    "train_lectures_pd = load_lectures()\n",
    "print(train_lectures_pd.shape, train_lectures_pd[CONTENT_ID].nunique())\n",
    "train_lectures_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3854,
     "status": "ok",
     "timestamp": 1608897796115,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "vZQqhXALL7qi"
   },
   "outputs": [],
   "source": [
    "if LECTURES_ENABLED is True and DUMP is True:\n",
    "    lect_dict = {}\n",
    "    print(train_lectures_pd[CONTENT_ID].min(), train_lectures_pd[CONTENT_ID].max(), train_lectures_pd[CONTENT_ID].nunique())\n",
    "    for i, lecture_id in enumerate(sorted(train_lectures_pd[CONTENT_ID].unique())):\n",
    "        lect_dict[lecture_id] = i\n",
    "    print(\"lect_dict\", len(lect_dict))\n",
    "    save_dict(lect_dict, MODEL_PATH + \"/lect_dict.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3828,
     "status": "ok",
     "timestamp": 1608897796118,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "HP1v59tiHAMA",
    "outputId": "bf145a18-4294-4bdd-cf39-fab4dec23a32"
   },
   "outputs": [],
   "source": [
    "test_cols = [ROW_ID, TIMESTAMP, USER_ID, CONTENT_ID, CONTENT_TYPE_ID, PRIOR_QUESTION_ELAPSED_TIME, PRIOR_QUESTION_HAD_EXPLANATION] # 'answered_correctly_avg_c' TASK_CONTAINER_ID\n",
    "ext_cols = []\n",
    "train_pd = train_pd[test_cols + ext_cols + [TARGET]] if train_pd is not None else None\n",
    "\n",
    "if LECTURES_ENABLED is True and DUMP is True:\n",
    "    # Merge lectures parts\n",
    "    train_lec_part = pd.merge(train_pd.loc[train_pd.content_type_id == True].reset_index(drop=True), train_lectures_pd, on=[CONTENT_ID], how=\"left\")\n",
    "    # Update target and content_id for lectures\n",
    "    train_lec_part[TARGET] = np.int8(2)\n",
    "    train_lec_part[\"offset_id\"] = train_lec_part[CONTENT_ID].map(lect_dict).astype(np.int32) + np.int32(13523)\n",
    "    # Merge question parts\n",
    "    train_que_part = pd.merge(train_pd.loc[train_pd.content_type_id == False].reset_index(drop=True), questions_df[[CONTENT_ID, PART]], on=[CONTENT_ID], how=\"left\")\n",
    "    train_que_part[\"offset_id\"] = train_que_part[CONTENT_ID]\n",
    "    train_pd = pd.concat([train_que_part, train_lec_part], axis=0).sort_values([USER_ID, TIMESTAMP]).reset_index(drop=True)\n",
    "    train_pd[CONTENT_ID] = train_pd[\"offset_id\"]\n",
    "    train_pd.drop(columns=[\"offset_id\"], inplace=True)\n",
    "    print(train_pd[CONTENT_ID].min(), train_pd[CONTENT_ID].max(), train_pd[CONTENT_ID].nunique())\n",
    "    del train_que_part, train_lec_part\n",
    "gc.collect()\n",
    "#train_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4188,
     "status": "ok",
     "timestamp": 1608897796507,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "JQbdBCfcgvW9"
   },
   "outputs": [],
   "source": [
    "def cleanup(df, elapsed_time_seconds_mean=None, lag_minutes_mean=None, quantile_transformer=None, lag_bins=None, elapsed_time_bins=None, standard_scaler=None):\n",
    "    # Keep questions only?\n",
    "    if LECTURES_ENABLED is False:\n",
    "        df = df[df[CONTENT_TYPE_ID] == False].reset_index(drop=True)\n",
    "\n",
    "    if PART in FEATURES and questions_df is not None and PART not in df.columns:\n",
    "        df = pd.merge(df, questions_df, on=[CONTENT_ID], how=\"left\")\n",
    "\n",
    "    # Explanation\n",
    "    if PRIOR_QUESTION_HAD_EXPLANATION in FEATURES:\n",
    "        df[PRIOR_QUESTION_HAD_EXPLANATION].fillna(False, inplace=True)\n",
    "        df[PRIOR_QUESTION_HAD_EXPLANATION] = df[PRIOR_QUESTION_HAD_EXPLANATION].astype(np.int8)\n",
    "\n",
    "    if PRIOR_QUESTION_ELAPSED_TIME in FEATURES:\n",
    "        # Compute mean elapsed time to fill NaN\n",
    "        # Convert elapsed time to seconds\n",
    "        df[PRIOR_QUESTION_ELAPSED_TIME] = df[PRIOR_QUESTION_ELAPSED_TIME]/1000.0 # In seconds\n",
    "        \n",
    "        df[PRIOR_QUESTION_ELAPSED_TIME] = np.round(df[PRIOR_QUESTION_ELAPSED_TIME])\n",
    "\n",
    "        if elapsed_time_bins is None:\n",
    "            df[PRIOR_QUESTION_ELAPSED_TIME], elapsed_time_bins = pd.qcut(df[PRIOR_QUESTION_ELAPSED_TIME], conf.elapsed_time_max_size, duplicates=\"drop\", retbins=True)\n",
    "            df[PRIOR_QUESTION_ELAPSED_TIME] = df[PRIOR_QUESTION_ELAPSED_TIME].cat.codes # codes \n",
    "            print(\"Max ELAPSED_TIME code:\", df[PRIOR_QUESTION_ELAPSED_TIME].max(), \"Min ELAPSED_TIME code:\", df[PRIOR_QUESTION_ELAPSED_TIME].min(), \"Total ELAPSED_TIME:\", df[PRIOR_QUESTION_ELAPSED_TIME].nunique(), \"Total elapsed_time_bins:\", len(elapsed_time_bins))  \n",
    "            df[PRIOR_QUESTION_ELAPSED_TIME] = (df[PRIOR_QUESTION_ELAPSED_TIME].replace(-1, len(elapsed_time_bins)-1)).astype(np.int32) # Replace -1 = NaN id (72)\n",
    "        else:\n",
    "            df[PRIOR_QUESTION_ELAPSED_TIME] = pd.cut(df[PRIOR_QUESTION_ELAPSED_TIME], bins=elapsed_time_bins, labels=False, include_lowest=True) # apply bins and category code\n",
    "            df[PRIOR_QUESTION_ELAPSED_TIME] = (df[PRIOR_QUESTION_ELAPSED_TIME].fillna(len(elapsed_time_bins)-1)).astype(np.int32) # Replace NaN id (72)\n",
    "\n",
    "    # Compute lag between 2 exercices\n",
    "    if LAG in FEATURES:\n",
    "        df[LAG] = df.groupby(USER_ID)[TIMESTAMP].shift()\n",
    "        df[LAG] = np.clip(((df[TIMESTAMP] - df[LAG])/(1000.0)), 0, float('inf'))\n",
    "\n",
    "        if conf.lag_time_cat is True:\n",
    "            df[LAG] = np.round(df[LAG])\n",
    "            if lag_bins is None:\n",
    "                df[LAG], lag_bins = pd.qcut(df[LAG], conf.lag_time_max_size, duplicates=\"drop\", retbins=True) # duplicated -> reduce about 1/2 of N_ltg\n",
    "                df[LAG] = df[LAG].cat.codes # codes \n",
    "                print(\"Max LAG code:\", df[LAG].max(), \"Min LAG code:\", df[LAG].min(), \"Total LAG:\", df[LAG].nunique(), \"Total lag_bins:\", len(lag_bins))  \n",
    "                df[LAG] = (df[LAG].replace(-1, len(lag_bins)-1)).astype(np.int32) # Replace -1 = NaN id (365)\n",
    "            else:\n",
    "                df[LAG] = pd.cut(df[LAG], bins=lag_bins, labels=False, include_lowest=True) # apply bins and category code\n",
    "                df[LAG] = (df[LAG].fillna(len(lag_bins)-1)).astype(np.int32) # Replace NaN id (365)\n",
    "        else:\n",
    "            print(\"Standard scaler\") # Does not help\n",
    "            if standard_scaler is None:\n",
    "                standard_scaler = StandardScaler()\n",
    "                standard_scaler.fit(df[LAG].values.reshape(-1, 1))\n",
    "            df[LAG] = standard_scaler.transform(df[LAG].values.reshape(-1, 1))\n",
    "            df[LAG].fillna(0.0, inplace=True)\n",
    "            df[LAG] = df[LAG].astype(\"float32\")\n",
    "\n",
    "    # Add position\n",
    "    df[RANK] = df.groupby([USER_ID])[TIMESTAMP].rank(method=\"first\", ascending=True).astype(np.int32)\n",
    "    \n",
    "    # Need to start with zero index\n",
    "    if PART in FEATURES:\n",
    "        df[PART] = df[PART] - 1\n",
    "\n",
    "    return df, elapsed_time_seconds_mean, lag_minutes_mean, quantile_transformer, lag_bins, elapsed_time_bins, standard_scaler\n",
    "\n",
    "if DUMP is True:\n",
    "    train_pd, elapsed_time_seconds_mean_, lag_minutes_mean_, quantile_transformer_, lag_bins_, elapsed_time_bins_, standard_scaler_= cleanup(train_pd, elapsed_time_seconds_mean=None, lag_minutes_mean=None, quantile_transformer=None, lag_bins=None, elapsed_time_bins=None, standard_scaler=None)\n",
    "    if quantile_transformer_ is not None:\n",
    "        save_dict(quantile_transformer_, MODEL_PATH + \"/quantiles.pkl\")\n",
    "    if lag_bins_ is not None:\n",
    "        print(\"lag_bins:\", len(lag_bins_))\n",
    "        assert(conf.lag_time_size == len(lag_bins_))\n",
    "        save_dict(lag_bins_, MODEL_PATH + \"/lag_bins.pkl\")   \n",
    "    if elapsed_time_bins_ is not None:\n",
    "        print(\"elapsed_time_bins:\", len(elapsed_time_bins_))\n",
    "        assert(conf.elapsed_time_size == len(elapsed_time_bins_))\n",
    "        save_dict(elapsed_time_bins_, MODEL_PATH + \"/elapsed_time_bins.pkl\")  \n",
    "    if standard_scaler_ is not None:\n",
    "        print(\"standard_scaler:\", standard_scaler_)\n",
    "        save_dict(standard_scaler_, MODEL_PATH + \"/standard_scaler.pkl\")          \n",
    "    print(train_pd.shape)\n",
    "else:\n",
    "    elapsed_time_seconds_mean_ = 25.439438358434938\n",
    "    lag_minutes_mean_ = 327.18331043496374 if LECTURES_ENABLED is True else 333.3975388518916 # (questions only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4183,
     "status": "ok",
     "timestamp": 1608897796508,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "o8DMDIu0dh51"
   },
   "outputs": [],
   "source": [
    "valid_pd = pd.read_pickle(DATA_HOME + \"cv%d_valid.pickle\" % FOLD)\n",
    "valid_pd = valid_pd[test_cols + ext_cols + [TARGET]]\n",
    "if LECTURES_ENABLED is True and DUMP is True:\n",
    "    valid_lec_part = pd.merge(valid_pd.loc[valid_pd.content_type_id == True].reset_index(drop=True), train_lectures_pd, on=[CONTENT_ID], how=\"left\")\n",
    "    valid_lec_part[TARGET] = np.int8(2)\n",
    "    valid_lec_part[\"offset_id\"] = valid_lec_part[CONTENT_ID].map(lect_dict).astype(np.int32) + np.int32(13523)\n",
    "    valid_que_part = pd.merge(valid_pd.loc[valid_pd.content_type_id == False].reset_index(drop=True), questions_df[[CONTENT_ID, PART]], on=[CONTENT_ID], how=\"left\")\n",
    "    valid_que_part[\"offset_id\"] = valid_que_part[CONTENT_ID]\n",
    "    valid_pd = pd.concat([valid_que_part, valid_lec_part], axis=0).sort_values([USER_ID, TIMESTAMP]).reset_index(drop=True)\n",
    "    valid_pd[CONTENT_ID] = valid_pd[\"offset_id\"]\n",
    "    valid_pd.drop(columns=[\"offset_id\"], inplace=True)\n",
    "    print(valid_pd[CONTENT_ID].min(), valid_pd[CONTENT_ID].max(), valid_pd[CONTENT_ID].nunique())\n",
    "    del valid_que_part, valid_lec_part\n",
    "_ = gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4172,
     "status": "ok",
     "timestamp": 1608897796509,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "9fsBzXtIRHjn"
   },
   "outputs": [],
   "source": [
    "if DUMP is True:\n",
    "    valid_pd, _, _, _, _, _, _ = cleanup(valid_pd, elapsed_time_seconds_mean=elapsed_time_seconds_mean_, lag_minutes_mean=lag_minutes_mean_, quantile_transformer = quantile_transformer_, lag_bins=lag_bins_, elapsed_time_bins=elapsed_time_bins_, standard_scaler=standard_scaler_)\n",
    "    print(valid_pd.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4403,
     "status": "ok",
     "timestamp": 1608897796748,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "bVl1XVty4ToC"
   },
   "outputs": [],
   "source": [
    "if DUMP is True:\n",
    "    emb_cols = FEATURES + [RANK, USER_ID] + META\n",
    "    for col in emb_cols:\n",
    "        print(col, \"train uniques:\", train_pd[col].nunique() if col in train_pd.columns else None) \n",
    "        print(col, \"valid uniques:\", valid_pd[col].nunique() if col in valid_pd.columns else None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4392,
     "status": "ok",
     "timestamp": 1608897796749,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "z2xOwvLDQroD"
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(TRAIN_FEATURES_PATH + \"train_cleaned.pkl\"):\n",
    "    train_count_pd = train_pd.groupby([USER_ID])[ROW_ID].count().reset_index()\n",
    "    train_count_pd.columns = [USER_ID, \"ft_row_id_agg_nunique_per_user_id\"]\n",
    "    train_pd = pd.merge(train_pd, train_count_pd, on=[USER_ID], how=\"left\")\n",
    "    valid_count_pd = valid_pd.groupby([USER_ID])[ROW_ID].count().reset_index()\n",
    "    valid_count_pd.columns = [USER_ID, \"ft_row_id_agg_nunique_per_user_id\"]\n",
    "    valid_pd = pd.merge(valid_pd, valid_count_pd, on=[USER_ID], how=\"left\")\n",
    "    del train_count_pd, valid_count_pd\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4386,
     "status": "ok",
     "timestamp": 1608897796749,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "Alsnr5nx-Ni6"
   },
   "outputs": [],
   "source": [
    "# Filter sequences (to control padding rate)\n",
    "emb_cols = FEATURES + [RANK, USER_ID] + META\n",
    "\n",
    "if not os.path.exists(TRAIN_FEATURES_PATH + \"train_cleaned.pkl\"):\n",
    "    train_pd = train_pd[train_pd[\"ft_row_id_agg_nunique_per_user_id\"] >= MIN_INTERACTIONS_TRAIN]\n",
    "    valid_pd = valid_pd[valid_pd[\"ft_row_id_agg_nunique_per_user_id\"] >= MIN_INTERACTIONS_VALID]\n",
    "    print(train_pd.shape)\n",
    "    train_pd = train_pd[train_pd[RANK] <= MAX_INTERACTIONS_TRAIN]\n",
    "    valid_pd = valid_pd[valid_pd[RANK] <= MAX_INTERACTIONS_VALID]\n",
    "    print(train_pd.shape)\n",
    "    for col in emb_cols:\n",
    "        print(col, \"train uniques:\", train_pd[col].nunique() if col in train_pd.columns else None) \n",
    "        print(col, \"valid uniques:\", valid_pd[col].nunique() if col in valid_pd.columns else None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4381,
     "status": "ok",
     "timestamp": 1608897796750,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "Cla00glwScz-"
   },
   "outputs": [],
   "source": [
    "# Convert to TimeSeries dataset\n",
    "def to_series(df, pivot=False):\n",
    "    if pivot is True:\n",
    "        series = []\n",
    "        for col in FEATURES:\n",
    "            a = df[[USER_ID, RANK, col]]\n",
    "            a = a.set_index([USER_ID, RANK])\n",
    "            a = a.unstack(fill_value=-1).reset_index()\n",
    "            a[\"name\"] = col\n",
    "            a = a.set_index([\"name\", USER_ID])\n",
    "            a.columns = [i for i in range(a.shape[1])]\n",
    "            series.append(a)\n",
    "        df = pd.concat(series, axis=0)\n",
    "    else:\n",
    "        df.set_index([USER_ID, TIMESTAMP], inplace=True)\n",
    "        df = df.sort_index()\n",
    "        df = df.reset_index()\n",
    "        df.drop(columns=[TIMESTAMP], inplace=True)\n",
    "        df = df.set_index(USER_ID)\n",
    "        df = df[FEATURES + META]\n",
    "    if GROUPED == True:\n",
    "        df = df[FEATURES + META].groupby(USER_ID).apply(lambda r: [r[c].values for c in FEATURES + META])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11166,
     "status": "ok",
     "timestamp": 1608897803541,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "yPkBGYdHXGOs",
    "outputId": "437d6413-dd02-4cc1-8504-db52ed2a620c"
   },
   "outputs": [],
   "source": [
    "if os.path.exists(TRAIN_FEATURES_PATH + \"train_cleaned.pkl\"):\n",
    "    del train_pd\n",
    "    train_pd = pd.read_pickle(TRAIN_FEATURES_PATH + \"train_cleaned.pkl\")\n",
    "    print(\"Train reloaded\")\n",
    "else:\n",
    "    train_pd = to_series(train_pd, pivot=PIVOT_TS)\n",
    "    train_pd.to_pickle(TRAIN_FEATURES_PATH + \"train_cleaned.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11408,
     "status": "ok",
     "timestamp": 1608897803794,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "l6zoBZS3SSN8",
    "outputId": "9b3cf8b3-7b4f-4a09-c18e-364255fdc8eb"
   },
   "outputs": [],
   "source": [
    "if os.path.exists(TRAIN_FEATURES_PATH + \"valid_cleaned.pkl\"):\n",
    "    del valid_pd\n",
    "    valid_pd = pd.read_pickle(TRAIN_FEATURES_PATH + \"valid_cleaned.pkl\")\n",
    "    print(\"Valid reloaded\")\n",
    "else:\n",
    "    valid_pd = to_series(valid_pd, pivot=PIVOT_TS)\n",
    "    valid_pd.to_pickle(TRAIN_FEATURES_PATH + \"valid_cleaned.pkl\")\n",
    "print(valid_pd.shape)\n",
    "valid_pd.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12293,
     "status": "ok",
     "timestamp": 1608897804690,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "bzWk8OJ5WOvM"
   },
   "outputs": [],
   "source": [
    "# Dataset/DataLoader:\n",
    "class RIIIDDataset(Dataset):\n",
    "    def __init__(self, df, conf, factory, subset=\"train\", categoricals=None, transform=None, augmentations=None, weights=False, flatten=False, min_len=3, force_len=None, verbose=False):\n",
    "        super().__init__()\n",
    "        self.history_users = None\n",
    "        self.categoricals = categoricals\n",
    "        self.subset = subset\n",
    "        self.transform = transform\n",
    "        self.augmentations = augmentations\n",
    "        self.conf = conf\n",
    "        self.factory = factory\n",
    "        self.verbose = verbose\n",
    "\n",
    "        if flatten is True and GROUPED is True:\n",
    "            self.dex = []\n",
    "            self.df = {}\n",
    "            split_len = self.conf.seq_len if force_len is None else force_len\n",
    "            total = 0\n",
    "            total_short = 0\n",
    "            count_short = 0\n",
    "            for i, user_id in enumerate(df.index):\n",
    "                feats = df[user_id]\n",
    "                if(i % 10000 == 0):\n",
    "                    print('Processed %d users, features=%d' % (i, len(feats)))\n",
    "                if len(feats[0]) >= min_len:\n",
    "                    if len(feats[0]) > split_len:\n",
    "                        total_questions = len(feats[0])\n",
    "                        last_pos = total_questions // split_len\n",
    "                        for seq in range(last_pos):\n",
    "                            index = f\"{user_id}_{seq}\"\n",
    "                            self.dex.append(index)\n",
    "                            start = seq * split_len\n",
    "                            end = (seq + 1) * split_len\n",
    "                            self.df[index] = [feats[f][start:end] for f, _ in enumerate(FEATURES + META)]\n",
    "                            total = total + split_len\n",
    "                        if len(feats[0][end:]) >= min_len:\n",
    "                            index = f\"{user_id}_{last_pos + 1}\"\n",
    "                            self.dex.append(index)\n",
    "                            self.df[index] = [feats[f][end:] for f, _ in enumerate(FEATURES + META)]\n",
    "                            total = total + len(feats[0][end:])\n",
    "                            total_short = total_short + len(feats[0][end:])\n",
    "                            count_short = count_short + 1\n",
    "                    else:\n",
    "                        index = f'{user_id}'\n",
    "                        self.dex.append(index)\n",
    "                        self.df[index] = [feats[f][:] for f, _ in enumerate(FEATURES + META)]\n",
    "                        total = total + len(feats[0])\n",
    "                        total_short = total_short + len(feats[0])\n",
    "                        count_short = count_short + 1\n",
    "                        \n",
    "            print(\"Total users_seq:\", len(self.dex), \"total:\", total, \"total_short:\", total_short, \"ratio_short:\", total_short/count_short, \"split len:\", split_len)\n",
    "        else:\n",
    "            self.df = df\n",
    "            self.dex = self.df if subset == \"test\" else self.df.reset_index()[USER_ID].unique()\n",
    "\n",
    "\n",
    "        def zero_offset(max_offset, user_id):\n",
    "            return 0\n",
    "        \n",
    "        def random_offset(max_offset, user_id):\n",
    "            return np.random.randint(max_offset)\n",
    "\n",
    "        if subset == 'train':\n",
    "            self.get_offset = random_offset\n",
    "        elif subset == 'valid':\n",
    "            self.get_offset = zero_offset # lambda x: 0\n",
    "        elif subset == 'ho':\n",
    "            self.get_offset = zero_offset # lambda x: 0\n",
    "        elif subset == 'test':\n",
    "            self.get_offset = zero_offset # lambda x: 0            \n",
    "        else:\n",
    "            raise RuntimeError(\"Unknown subset\")\n",
    "\n",
    "        self.uweights = self.compute_weights(self.df) if subset != \"test\" and weights is True else None\n",
    "\n",
    "    def compute_weights(self, df_):\n",
    "        if isinstance(df_, dict):\n",
    "            ret = []\n",
    "            for seq_id_, v in df_.items():\n",
    "                ret.append((seq_id_, len(v[0])))\n",
    "            df_dist = pd.DataFrame(ret)\n",
    "        else:\n",
    "            if GROUPED is False:\n",
    "                df_dist = df_.value_counts(subset=[USER_ID]).reset_index()\n",
    "            else:\n",
    "                ret = []\n",
    "                for seq_id_, v in zip(df_.index, df_):\n",
    "                    ret.append((seq_id_, len(v[0])))\n",
    "                df_dist = pd.DataFrame(ret)     \n",
    "        df_dist.columns = [USER_ID, \"prob\"]\n",
    "        df_dist = df_dist[df_dist[\"prob\"] <= MAX_INTERACTIONS_CAP].reset_index(drop=True)\n",
    "        df_dist[\"prob\"] = df_dist[\"prob\"]/df_dist[\"prob\"].sum()\n",
    "        df_dist = df_dist.set_index(USER_ID).sort_index()\n",
    "        print(\"compute_weights\")\n",
    "        display(df_dist.head())\n",
    "        return df_dist\n",
    "   \n",
    "    def __len__(self):\n",
    "        return len(self.dex)\n",
    "\n",
    "    def cleanup(self):\n",
    "        if self.factory is not None:\n",
    "            self.factory.cleanup()\n",
    "       \n",
    "    def get_sample(self, row, categoricals, user_id):        \n",
    "\n",
    "        # build slice_pd with (features, seq_len)\n",
    "        slice_pd = None\n",
    "        mask = np.zeros((self.conf.seq_len), dtype=bool) # All False\n",
    "\n",
    "        if GROUPED == True:\n",
    "            series_len = len(row[0]) # Questions for a given user\n",
    "            start_index = 0\n",
    "            stop_index = series_len\n",
    "            pad_row, pad_size = None, None\n",
    "\n",
    "            # build slice_pd with (features, seq_len)\n",
    "            if series_len < self.conf.seq_len:\n",
    "                # Not enough data, left padding\n",
    "                pad_size = self.conf.seq_len-series_len\n",
    "                if self.conf.pad_mode == \"random\":\n",
    "                    # Pick another user in existing dataset\n",
    "                    iidx = self.get_offset(len(self.dex), user_id)\n",
    "                    random_user_id_row = self.df.loc[self.dex[iidx]]\n",
    "                    while (len(random_user_id_row[0]) < pad_size):\n",
    "                        iidx = self.get_offset(len(self.dex), user_id) if self.subset == \"train\" else iidx + 1 # No random for valid, just the next one\n",
    "                        random_user_id_row = self.df.loc[self.dex[iidx]]\n",
    "                    pad_row = random_user_id_row\n",
    "                elif self.conf.pad_mode == \"token\":\n",
    "                    pad_row = np.zeros((len(row), pad_size), dtype=np.int16)\n",
    "                    for i, f in enumerate(FEATURES + META):\n",
    "                        if f == CONTENT_ID:\n",
    "                            pad_row[i, :] = self.conf.exercices_id_size\n",
    "                        elif f == PART:\n",
    "                            pad_row[i, :] = self.conf.exercices_part_size \n",
    "                        elif f == TARGET: \n",
    "                            pad_row[i, :] = self.conf.response_size + 1  # + 1 as we've start_token already                         \n",
    "                        elif f == LAG:\n",
    "                            pad_row[i, :] = self.conf.lag_time_size + 1  # + 1 as we've start_token already                                            \n",
    "                        elif f == PRIOR_QUESTION_ELAPSED_TIME:\n",
    "                            pad_row[i, :] = self.conf.elapsed_time_size + 1 # + 1 as we've start_token already\n",
    "                        elif f == PRIOR_QUESTION_HAD_EXPLANATION:\n",
    "                            pad_row[i, :] = self.conf.explanation_size + 1  # + 1 as we've start_token already \n",
    "                        elif f == ROW_ID:\n",
    "                            pad_row[i, :] = -1                          \n",
    "                else:\n",
    "                    # Zeros\n",
    "                    pad_row = np.zeros((len(row), pad_size), dtype=np.int16)                \n",
    "                # Right/Left pad\n",
    "                mask = np.concatenate([np.zeros((self.conf.seq_len-pad_size), dtype=bool), np.ones((pad_size), dtype=bool)]) if self.conf.pad_right is True else np.concatenate([np.ones((pad_size), dtype=bool), np.zeros((self.conf.seq_len-pad_size), dtype=bool)])# Right pad\n",
    "            elif series_len > self.conf.seq_len:       \n",
    "                # Pick a random value and get seq_len\n",
    "                start_index = self.get_offset(series_len - self.conf.seq_len, user_id)\n",
    "                stop_index = start_index + self.conf.seq_len\n",
    "\n",
    "            sample = {}\n",
    "            for f_idx, input in enumerate(FEATURES + META, 0):\n",
    "                # Pick column\n",
    "                series_data = row[f_idx][start_index:stop_index]\n",
    "                if pad_row is not None:\n",
    "                    # Right/Left pad\n",
    "                    series_data = np.concatenate([row[f_idx][start_index:stop_index], pad_row[f_idx][0:pad_size]]) if self.conf.pad_right is True else np.concatenate([pad_row[f_idx][0:pad_size], row[f_idx][start_index:stop_index]])\n",
    "                labels = None\n",
    "                if input == TARGET:\n",
    "                    labels = torch.from_numpy(series_data).long()\n",
    "                item = torch.from_numpy(series_data)\n",
    "                if self.transform is not None: \n",
    "                    item = self.transform(item)\n",
    "                sample[input] = item\n",
    "                if labels is not None:\n",
    "                    sample[\"labels\"] = labels\n",
    "            if LECTURES_ENABLED is True:\n",
    "                mask[sample[CONTENT_ID] >= 13523] = True\n",
    "            sample[\"mask\"] = mask             \n",
    "\n",
    "        return sample\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        if self.subset == \"test\":\n",
    "            # For test, we need one question only to answer (with related user)\n",
    "            row = self.df.iloc[idx:idx+1,:]\n",
    "        else:\n",
    "            # For train/valid we need series per user\n",
    "            user_id = self.dex[idx]\n",
    "            if isinstance(self.df, dict):                \n",
    "                row = self.df[user_id]\n",
    "            else:\n",
    "                row = self.df.loc[user_id]\n",
    "\n",
    "        sample =  self.get_sample(row, self.categoricals, user_id)\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12279,
     "status": "ok",
     "timestamp": 1608897804693,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "4h1UmESl4rGk"
   },
   "outputs": [],
   "source": [
    "class NoamOpt:\n",
    "    \"Optim wrapper that implements rate.\"\n",
    "\n",
    "    def __init__(self, model_size, factor, warmup, optimizer, warmup_scale=1.0):\n",
    "        self.optimizer = optimizer\n",
    "        self._step = 0\n",
    "        self.warmup = warmup\n",
    "        self.warmup_scale = warmup_scale\n",
    "        self.factor = factor\n",
    "        self.model_size = model_size\n",
    "        self._rate = 0\n",
    "\n",
    "    def zero_grad(self):\n",
    "        self.optimizer.zero_grad()\n",
    "\n",
    "    def step(self):\n",
    "        \"Update parameters and rate\"\n",
    "        self._step += 1\n",
    "        rate = self.rate()\n",
    "        for p in self.optimizer.param_groups:\n",
    "            p['lr'] = rate\n",
    "        self._rate = rate\n",
    "        self.optimizer.step()\n",
    "\n",
    "    def rate(self, step=None):\n",
    "        \"Implement `lrate` above\"\n",
    "        if step is None:\n",
    "            step = self._step\n",
    "        return self.factor * \\\n",
    "               (self.model_size ** (-0.5) *\n",
    "                min(step ** (-0.5) / self.warmup_scale, step * self.warmup ** (-1.5)))\n",
    "\n",
    "class NoamOptimizer:\n",
    "    def __init__(self, model, lr, model_size, warmup, warmup_scale):\n",
    "        self._adam = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "        self._opt = NoamOpt(model_size=model_size, factor=1, warmup=warmup, optimizer=self._adam, warmup_scale=warmup_scale)\n",
    "\n",
    "    def zero_grad(self):\n",
    "        self._opt.zero_grad()\n",
    "\n",
    "    def step(self):\n",
    "        self._opt.step()\n",
    "    \n",
    "    def get_last_lr(self):\n",
    "        return self._opt._rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12265,
     "status": "ok",
     "timestamp": 1608897804694,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "tdN4U4GLVH6c"
   },
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model) # torch.Size([max_len, d_model])\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1) # torch.Size([max_len, 1]) # 0,1,2,3,4,...max_len-1\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model)) # torch.Size([d_model/2])\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1) # torch.Size([max_len, 1, d_model])\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomEncoder(nn.Module):\n",
    "    def __init__(self, d_model=512, nhead=6, num_encoder_layers=6, dim_feedforward=2048, dropout=0.1, activation =\"relu\", verbose=False):\n",
    "        super().__init__()\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model, nhead, dim_feedforward, dropout, activation)\n",
    "        encoder_norm = None # nn.LayerNorm(d_model)\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer, num_encoder_layers, encoder_norm) # Stack encoder layers\n",
    "\n",
    "    def forward(self, src, mask=None, src_key_padding_mask=None):\n",
    "        memory = self.encoder(src, mask=mask, src_key_padding_mask=src_key_padding_mask)\n",
    "        return memory\n",
    "\n",
    "class CustomDecoder(nn.Module):\n",
    "    def __init__(self, d_model=512, nhead=6, num_decoder_layers=6, dim_feedforward=2048, dropout=0.1, activation =\"relu\", verbose=False):\n",
    "        super().__init__()\n",
    "\n",
    "        decoder_layer = nn.TransformerDecoderLayer(d_model, nhead, dim_feedforward, dropout, activation)\n",
    "        decoder_norm = None # nn.LayerNorm(d_model)\n",
    "        self.decoder = nn.TransformerDecoder(decoder_layer, num_decoder_layers, decoder_norm) # Stack decoder layers\n",
    "\n",
    "    def forward(self, tgt, memory, tgt_mask=None, memory_mask=None, tgt_key_padding_mask=None, memory_key_padding_mask=None):       \n",
    "        output = self.decoder(tgt, memory, tgt_mask=tgt_mask, memory_mask=memory_mask, tgt_key_padding_mask=tgt_key_padding_mask, memory_key_padding_mask=memory_key_padding_mask)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 13458,
     "status": "ok",
     "timestamp": 1608897805899,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "j3_ps7QF-SEM"
   },
   "outputs": [],
   "source": [
    "# Model\n",
    "class RIIIDModel(nn.Module):\n",
    "    def __init__(self, cfg, verbose=False):\n",
    "        super().__init__()\n",
    "        self.response_size = cfg.response_size\n",
    "        self.lag_time_size = cfg.lag_time_size\n",
    "        self.elapsed_time_size = cfg.elapsed_time_size\n",
    "        self.explanation_size = cfg.explanation_size\n",
    "        self.seq_len = cfg.seq_len\n",
    "        self.embedding_dim = cfg.embedding_dim\n",
    "        self.elapsed_time_cat = cfg.elapsed_time_cat\n",
    "        self.lag_time_cat = cfg.lag_time_cat\n",
    "        self.num_classes = cfg.num_classes\n",
    "        self.verbose = verbose\n",
    "        self.pad_mode = cfg.pad_mode\n",
    "\n",
    "        self.pos_encoder1 = None\n",
    "        self.pos_encoder2 = None\n",
    "        self.position_size_embedding = None\n",
    "\n",
    "        additional_token_dim = 1 if self.pad_mode == \"token\" else 0\n",
    "\n",
    "        # Exercices embeddings\n",
    "        self.exercices_id_embedding = nn.Embedding(cfg.exercices_id_size + additional_token_dim, self.embedding_dim)\n",
    "        self.exercices_part_embedding = nn.Embedding(cfg.exercices_part_size + additional_token_dim, self.embedding_dim) if cfg.exercices_part_size is not None else None\n",
    "\n",
    "        # Response embeddings\n",
    "        self.response_embedding = nn.Embedding(cfg.response_size + 1 + additional_token_dim, self.embedding_dim) # +1 to include start token\n",
    "        \n",
    "        if self.elapsed_time_cat is True:\n",
    "            self.elapsed_time_embedding = nn.Embedding(cfg.elapsed_time_size + 1 + additional_token_dim, self.embedding_dim) if cfg.elapsed_time_size is not None else None # +1 to include start token\n",
    "        else:\n",
    "            self.elapsed_time_embedding = nn.Linear(1, self.embedding_dim, bias=False) if cfg.elapsed_time_size is not None else None # Continuous embedding\n",
    "        \n",
    "        if self.lag_time_cat is True:\n",
    "            self.lag_time_embedding = nn.Embedding(cfg.lag_time_size + 1 + additional_token_dim, self.embedding_dim) if cfg.lag_time_size is not None else None # +1 to include start token\n",
    "        else:\n",
    "            self.lag_time_embedding = nn.Linear(1, self.embedding_dim, bias=False) if cfg.lag_time_size is not None else None # Continuous embedding\n",
    "            \n",
    "        self.explanation_embedding = nn.Embedding(cfg.explanation_size + 1 + additional_token_dim, self.embedding_dim) if cfg.explanation_size is not None else None # +1 to include start token\n",
    "        \n",
    "        input_features_dim = self.embedding_dim\n",
    "\n",
    "        # Position encoder (relative or absolute position of the tokens in the sequence)\n",
    "        if cfg.position_encoding_enabled is True:\n",
    "            self.pos_encoder1 = PositionalEncoding(input_features_dim, cfg.dropout)\n",
    "            self.pos_encoder2 = self.pos_encoder1\n",
    "        else:\n",
    "            # Relative position\n",
    "            self.position_size_embedding = nn.Embedding(cfg.seq_len + 1 + additional_token_dim, self.embedding_dim) # +1 to include start token\n",
    "\n",
    "        # Transformer with default encoder/decoder        \n",
    "        self.transformer = nn.Transformer(d_model=input_features_dim, \n",
    "                                          nhead=cfg.nhead, \n",
    "                                          num_encoder_layers=cfg.num_encoder_layers,\n",
    "                                          num_decoder_layers=cfg.num_decoder_layers, \n",
    "                                          dim_feedforward=cfg.dim_feedforward, \n",
    "                                          dropout=cfg.dropout, \n",
    "                                          activation='relu', \n",
    "                                          custom_encoder = CustomEncoder(d_model=input_features_dim, nhead=cfg.nhead , num_encoder_layers=cfg.num_encoder_layers, \n",
    "                                                                         dim_feedforward=cfg.dim_feedforward, dropout=cfg.dropout, activation =\"relu\") if cfg.custom_encoder is True else None, \n",
    "                                          custom_decoder = CustomDecoder(d_model=input_features_dim, nhead=cfg.nhead, num_decoder_layers=cfg.num_decoder_layers, \n",
    "                                                                         dim_feedforward=cfg.dim_feedforward, dropout=cfg.dropout, activation='relu') if cfg.custom_decoder is True else None)\n",
    "                \n",
    "        # Decoder\n",
    "        self.fc = nn.Linear(input_features_dim, self.num_classes)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "\n",
    "    def init_weights(self):\n",
    "        # Xavier uniform initialization\n",
    "        for p in self.parameters():\n",
    "            if p.dim() > 1:\n",
    "                nn.init.xavier_uniform_(p)\n",
    "\n",
    "    # If a BoolTensor is provided, the positions with the value of True will be ignored while the position with the value of False will be unchanged.\n",
    "    # tensor([[False,  True,  True,  True],\n",
    "    #         [False, False,  True,  True],\n",
    "    #         [False, False, False,  True],\n",
    "    #         [False, False, False, False]])    \n",
    "    def generate_mask(self, size, diagonal=1):        \n",
    "        return torch.triu(torch.ones(size, size)==1, diagonal=diagonal)\n",
    "\n",
    "    def forward(self, data, src_mask=None, tgt_mask=None, mem_mask=None, src_key_padding_mask=None, tgt_key_padding_mask=None, memory_key_padding_mask=None):\n",
    "        \n",
    "        # Each input is (BS, seq_len)\n",
    "        # Content\n",
    "        data_content_id = data[CONTENT_ID].long()\n",
    "        # Answers\n",
    "        data_response = data[TARGET].long()        \n",
    "\n",
    "        # Optional features\n",
    "        data_part = data[PART].long() if self.exercices_part_embedding is not None else None\n",
    "        \n",
    "        if self.elapsed_time_cat is True:\n",
    "            data_elapsed_time = data[PRIOR_QUESTION_ELAPSED_TIME].long() if self.elapsed_time_embedding is not None else None\n",
    "        else:\n",
    "            data_elapsed_time = data[PRIOR_QUESTION_ELAPSED_TIME].float().unsqueeze(2) if self.elapsed_time_embedding is not None else None\n",
    "        if self.lag_time_cat is True:\n",
    "            data_lag_time = data[LAG].long() if self.lag_time_embedding is not None else None\n",
    "        else:\n",
    "            data_lag_time = data[LAG].float().unsqueeze(2) if self.lag_time_embedding is not None else None\n",
    "        \n",
    "        data_explanation = data[PRIOR_QUESTION_HAD_EXPLANATION].long() if self.explanation_embedding is not None else None\n",
    "\n",
    "\n",
    "        # Start token(s)\n",
    "        # --------------\n",
    "\n",
    "        # Add start token to correctness\n",
    "        data_response = torch.roll(data_response, shifts=(0, 1), dims=(0, 1)) # Shift right the sequence\n",
    "        data_response[:,0] = self.response_size # Start token (2)\n",
    "\n",
    "        # Add start token to lag time\n",
    "        if data_lag_time is not None:\n",
    "            data_lag_time = torch.roll(data_lag_time, shifts=(0, 1), dims=(0, 1)) # Shift right the sequence\n",
    "            data_lag_time[:,0] = self.lag_time_size # Start token\n",
    "\n",
    "        # Add start token to elapsed time\n",
    "        if data_elapsed_time is not None:\n",
    "            data_elapsed_time = torch.roll(data_elapsed_time, shifts=(0, 1), dims=(0, 1)) # Shift right the sequence\n",
    "            if self.elapsed_time_cat is True:\n",
    "                data_elapsed_time[:,0] = self.elapsed_time_size # Start token\n",
    "            else:\n",
    "                data_elapsed_time[:,0] = 0.0\n",
    "\n",
    "        # Add start token to explanation\n",
    "        if data_explanation is not None:\n",
    "            data_explanation = torch.roll(data_explanation, shifts=(0, 1), dims=(0, 1)) # Shift right the sequence\n",
    "            data_explanation[:,0] = self.explanation_size # Start token\n",
    "        \n",
    "        # Questions, Part, Elapsed time, Lag embeddings\n",
    "        x_content_id = self.exercices_id_embedding(data_content_id) # (BS, seq_len, embedding_dim)\n",
    "\n",
    "        x_exercices_part = self.exercices_part_embedding(data_part) if self.exercices_part_embedding is not None else None # (BS, seq_len, embedding_dim)\n",
    "        x_elapsed_time = self.elapsed_time_embedding(data_elapsed_time) if self.elapsed_time_embedding is not None else None # (BS, seq_len, embedding_dim)\n",
    "        x_lag_time = self.lag_time_embedding(data_lag_time) if self.lag_time_embedding is not None else None # (BS, seq_len, embedding_dim)\n",
    "        x_explanation = self.explanation_embedding(data_explanation) if self.explanation_embedding is not None else None # (BS, seq_len, embedding_dim)\n",
    "\n",
    "        # Response embeddings\n",
    "        x_correctness = self.response_embedding(data_response) # (BS, seq_len, embedding_dim)\n",
    "\n",
    "        x_position = None\n",
    "\n",
    "        # Ei (sum of embeddings)\n",
    "        x_exercices = x_content_id\n",
    "        \n",
    "        if x_exercices_part is not None:\n",
    "            x_exercices = x_exercices + x_exercices_part  # (BS, seq_len, embedding_dim)\n",
    "        \n",
    "        x_position_exercices = self.pos_encoder1(x_exercices) if self.pos_encoder1 is not None else x_exercices # (BS, seq_len, embedding_dim)\n",
    "\n",
    "        # Ri (sum of embeddings) [S, R1, Rk-1], S is start token\n",
    "        \n",
    "        x_responses = x_correctness \n",
    "        \n",
    "        if x_lag_time is not None:\n",
    "            x_responses = x_responses + x_lag_time\n",
    "\n",
    "        if x_elapsed_time is not None:\n",
    "            x_responses = x_responses + x_elapsed_time # (BS, seq_len, embedding_dim)\n",
    "\n",
    "        if x_explanation is not None:\n",
    "            x_responses = x_responses + x_explanation # (BS, seq_len, embedding_dim)        \n",
    "        \n",
    "        x_position_responses = self.pos_encoder2(x_responses) if self.pos_encoder2 is not None else x_responses # (BS, seq_len, embedding_dim)\n",
    "\n",
    "        # Transformer src: (S,N,E), tgt:(T,N,E), src_mask:(S,S), tgt_mask:(T,T)\n",
    "        # where S is the source sequence length, T is the target sequence length, N is the batch size, E is the feature number\n",
    "        # output: (T,N,E)\n",
    "        # src_key_padding_mask: (N,S), tgt_key_padding_mask: (N,T), memory_key_padding_mask: (N,S)    \n",
    "        x_position_exercices = x_position_exercices.transpose(1,0) # (seq_len, BS, embedding_dim)\n",
    "        x_position_responses = x_position_responses.transpose(1,0) # (seq_len, BS, embedding_dim)\n",
    "        \n",
    "        x_transformer = self.transformer(src=x_position_exercices, tgt=x_position_responses, src_mask=src_mask, tgt_mask=tgt_mask, memory_mask=mem_mask, \n",
    "                                         src_key_padding_mask=src_key_padding_mask, tgt_key_padding_mask=tgt_key_padding_mask, memory_key_padding_mask=memory_key_padding_mask) # (seq_len, BS, embedding_dim)\n",
    "        x_transformer = x_transformer.transpose(1,0) # (BS, seq_len, embedding_dim)\n",
    "     \n",
    "        output = self.fc(x_transformer)\n",
    "        output = output.squeeze(dim=2)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 13456,
     "status": "ok",
     "timestamp": 1608897805903,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "kla3DrFkDD_-"
   },
   "outputs": [],
   "source": [
    "def build_model(cfg, device, encoder_weights=None, backbone_weights=None, freeze_backbone=False, verbose=False):\n",
    "\n",
    "    model = RIIIDModel(cfg, verbose=verbose)\n",
    "\n",
    "    # Load weights\n",
    "    if (encoder_weights is not None) and (os.path.exists(encoder_weights)):\n",
    "        print(\"Load weights before optimizer from: %s\" % encoder_weights)\n",
    "        model.load_state_dict(torch.load(encoder_weights, map_location=cfg.map_location), strict=False)\n",
    "        if freeze_backbone is True:\n",
    "            print(\"Freeze backbone\")\n",
    "            model.freeze_backbone()\n",
    "\n",
    "    model = model.to(device)\n",
    "\n",
    "    if cfg.optimizer == \"Noam\":\n",
    "        optimizer = NoamOptimizer(model=model, lr=cfg.lr, model_size=cfg.embedding_dim, warmup=cfg.warm_up_step_count, warmup_scale=cfg.warm_up_scale)\n",
    "    else:\n",
    "        if cfg.optimizer == \"SGD\":\n",
    "            optimizer = SGD(filter(lambda p: p.requires_grad, model.parameters()), lr=cfg.lr, momentum=0.9)\n",
    "        else:\n",
    "            optimizer = Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=cfg.lr, betas=(cfg.beta1, 0.999))\n",
    "    \n",
    "    # Loss\n",
    "    loss = cfg.loss\n",
    "\n",
    "    loss = loss.to(device)\n",
    "\n",
    "    return model, loss, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 13434,
     "status": "ok",
     "timestamp": 1608897805906,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "iE6brA4hF9dm"
   },
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred, mask=None):\n",
    "    score = 0.0\n",
    "\n",
    "    # Flatten to (cumulated_BS * seq_len)\n",
    "    if mask is not None:\n",
    "        mask = mask.reshape(-1)\n",
    "        y_true = y_true.reshape(-1)[mask == False]\n",
    "        y_pred = y_pred.reshape(-1)[mask == False]         \n",
    "        score = (y_true == y_pred).sum()\n",
    "        score = score/len(y_pred)\n",
    "    else:\n",
    "        y_true = y_true.reshape(-1)\n",
    "        y_pred = y_pred.reshape(-1)\n",
    "        score = (y_true == y_pred).sum()\n",
    "        score = score/len(y_pred)      \n",
    "\n",
    "    return score\n",
    "\n",
    "def auc(y_true, y_pred, mask=None): \n",
    "    # Flatten to (cumulated_BS * seq_len)\n",
    "    if mask is not None:\n",
    "        mask = mask.reshape(-1)\n",
    "        y_true = y_true.reshape(-1)[mask == False]\n",
    "        y_pred = y_pred.reshape(-1)[mask == False]       \n",
    "        score = metrics.roc_auc_score(y_true, y_pred)\n",
    "    else:\n",
    "        y_true = y_true.reshape(-1)\n",
    "        y_pred = y_pred.reshape(-1)\n",
    "        score = metrics.roc_auc_score(y_true, y_pred)\n",
    "\n",
    "    return score        \n",
    "\n",
    "METRIC = auc\n",
    "METRIC_NAME = METRIC.__name__\n",
    "METRICS = [accuracy]\n",
    "METRICS_PROBS = [METRIC]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 13926,
     "status": "ok",
     "timestamp": 1608897806409,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "M9CL4f6eb3YX"
   },
   "outputs": [],
   "source": [
    "def format_logs(logs):\n",
    "    str_logs = ['{} - {:.4}'.format(k, v) for k, v in logs.items()]\n",
    "    s = ', '.join(str_logs)\n",
    "    return s\n",
    "\n",
    "# Train loop\n",
    "def train_loop_fn(batches, preprocessing, model, optimizer, criterion, device, stage=\"Train\", verbose=True):\n",
    "    model.train()\n",
    "    count, train_loss = 0, 0.0\n",
    "    all_predicted_classes, all_predicted_probs, all_target_classes = None, None, None\n",
    "    all_padding_mask = None\n",
    "\n",
    "    src_mask = None\n",
    "    with tqdm(batches, desc=stage, file=sys.stdout, disable=not(verbose)) as iterator:\n",
    "        for x, batch in enumerate(iterator, 1):\n",
    "            try:\n",
    "                for k, v in batch.items():\n",
    "                    batch[k] = v.to(device) if k != ROW_ID else None\n",
    "                samples_data, labels_data, padding_mask_data = batch, batch[\"labels\"], batch.get(\"mask\")\n",
    "                padding_mask_data_ = padding_mask_data\n",
    "\n",
    "                src_mask = model.generate_mask(conf.seq_len).to(device) if src_mask is None else src_mask\n",
    "\n",
    "                optimizer.zero_grad() # reset gradient\n",
    "\n",
    "                # Preprocessing\n",
    "                with torch.no_grad():\n",
    "                    data = preprocessing(samples_data) if preprocessing is not None else samples_data\n",
    "\n",
    "                # Model\n",
    "                output = model(data, src_mask=src_mask, tgt_mask=src_mask, mem_mask=src_mask, \n",
    "                                src_key_padding_mask=padding_mask_data_, tgt_key_padding_mask=padding_mask_data_, memory_key_padding_mask=padding_mask_data_) # forward pass\n",
    "                \n",
    "                if conf.num_classes > 1:\n",
    "                    padding_mask_data_copy = padding_mask_data\n",
    "                    loss = criterion(output.view(-1, conf.num_classes), labels_data.view(-1), mask=padding_mask_data_copy.view(-1)) # Flatten as CrossEntropy requires (BS, C)\n",
    "                else:\n",
    "                    loss = criterion(output, labels_data.float(), mask=padding_mask_data)\n",
    "\n",
    "                if (conf.ITERATIONS_LOGS > 0) and (x % conf.ITERATIONS_LOGS == 0):\n",
    "                    loss_value = loss.item()\n",
    "                    if ~np.isnan(loss_value): train_loss += loss_value\n",
    "                    else: print(\"Warning: NaN loss\")                \n",
    "                \n",
    "                loss.backward() # backward pass\n",
    "\n",
    "                # Update weights\n",
    "                optimizer.step()     \n",
    "\n",
    "                if (conf.ITERATIONS_LOGS > 0) and (x % conf.ITERATIONS_LOGS == 0):\n",
    "                    # Labels predictions\n",
    "                    predicted_probs = torch.sigmoid(output) if conf.post_activation == \"sigmoid\" else output\n",
    "                    predicted_probs = torch.softmax(output, dim=conf.post_activation_dim).detach().cpu().numpy()[:,:,1] if conf.post_activation == \"softmax\" else predicted_probs.detach().cpu().numpy()\n",
    "                    predicted_classes = torch.argmax(output[:,:,0-2:], dim=conf.post_activation_dim).detach().cpu().numpy() if conf.post_activation == \"softmax\" else np.where(predicted_probs > conf.train_probs_threshold, 1, 0)\n",
    "                    target_classes = labels_data.detach().cpu().numpy()\n",
    "                    padding_mask = padding_mask_data.cpu().numpy() if padding_mask_data is not None else None\n",
    "\n",
    "                    # Concatenate for all batches\n",
    "                    all_predicted_probs = np.concatenate([all_predicted_probs, predicted_probs], axis=0) if all_predicted_probs is not None else predicted_probs\n",
    "                    all_predicted_classes = np.concatenate([all_predicted_classes, predicted_classes], axis=0) if all_predicted_classes is not None else predicted_classes      \n",
    "                    all_target_classes = np.concatenate([all_target_classes, target_classes], axis=0) if all_target_classes is not None else target_classes \n",
    "                    all_padding_mask = np.concatenate([all_padding_mask, padding_mask], axis=0) if all_padding_mask is not None else padding_mask  \n",
    "\n",
    "                    count += 1\n",
    "\n",
    "                    if verbose: \n",
    "                        scores_str = {\"train_%s\" % m.__name__: m(all_target_classes, all_predicted_probs, mask=all_padding_mask) for m in METRICS_PROBS}\n",
    "                        if METRICS is not None: scores_str = {**scores_str, **{\"train_%s\" % m.__name__: m(all_target_classes, all_predicted_classes, mask=all_padding_mask) for m in METRICS}}\n",
    "                        scores_str[\"train_loss\"] = (train_loss / count)\n",
    "                        iterator.set_postfix_str(format_logs(scores_str))\n",
    "                    \n",
    "            except Exception as ex:\n",
    "                print(\"Training batch error:\", ex)\n",
    "    \n",
    "    scores = {\"train_%s\" % m.__name__: m(all_target_classes, all_predicted_probs, mask=all_padding_mask) for m in METRICS_PROBS}\n",
    "    if METRICS is not None: scores = {**scores, **{\"train_%s\" % m.__name__: m(all_target_classes, all_predicted_classes, mask=all_padding_mask) for m in METRICS}}\n",
    "    scores[\"train_loss\"] = (train_loss / count)\n",
    "    \n",
    "    return (scores, all_target_classes, all_predicted_classes, all_predicted_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 13920,
     "status": "ok",
     "timestamp": 1608897806410,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "8V8qBxnK1xf6"
   },
   "outputs": [],
   "source": [
    "# Valid loop\n",
    "def valid_loop_fn(batches, preprocessing, model, criterion, device, stage=\"Valid\", verbose=True):\n",
    "    model.eval()\n",
    "    count, valid_loss = 0, 0.0\n",
    "    all_predicted_classes, all_predicted_probs, all_target_classes = None, None, None\n",
    "    all_padding_mask = None\n",
    "\n",
    "    src_mask = None\n",
    "    with tqdm(batches, desc=stage, file=sys.stdout, disable=not(verbose)) as iterator:\n",
    "        for batch in iterator:\n",
    "            try:\n",
    "                for k, v in batch.items():\n",
    "                    batch[k] = v.to(device) if k != ROW_ID else None\n",
    "                samples_data, labels_data, padding_mask_data = batch, batch[\"labels\"], batch.get(\"mask\")\n",
    "                padding_mask_data_ = padding_mask_data\n",
    "\n",
    "                src_mask = model.generate_mask(conf.seq_len).to(device) if src_mask is None else src_mask                  \n",
    "\n",
    "                with torch.no_grad():\n",
    "                    # Preprocessing\n",
    "                    data = preprocessing(samples_data) if preprocessing is not None else samples_data\n",
    "                    # NN model        \n",
    "                    output = model(data, src_mask=src_mask, tgt_mask=src_mask, mem_mask=src_mask, \n",
    "                                   src_key_padding_mask=padding_mask_data_, tgt_key_padding_mask=padding_mask_data_, memory_key_padding_mask=padding_mask_data_) # forward pass\n",
    "\n",
    "                # Compute loss\n",
    "                if conf.num_classes > 1:\n",
    "                    padding_mask_data_copy = padding_mask_data             \n",
    "                    loss = criterion(output.view(-1, conf.num_classes), labels_data.view(-1), mask=padding_mask_data_copy.view(-1)) # Flatten as CrossEntropy requires (BS, C)\n",
    "                else:\n",
    "                    loss = criterion(output, labels_data.float(), mask=padding_mask_data)\n",
    "\n",
    "                loss_value = loss.item()\n",
    "                if ~np.isnan(loss_value): valid_loss += loss_value\n",
    "                else: print(\"Warning: NaN loss\")\n",
    "          \n",
    "                # Labels predictions\n",
    "                predicted_probs = torch.sigmoid(output) if conf.post_activation == \"sigmoid\" else output\n",
    "                predicted_probs = torch.softmax(output, dim=conf.post_activation_dim).detach().cpu().numpy()[:,:,1] if conf.post_activation == \"softmax\" else predicted_probs.detach().cpu().numpy()\n",
    "                predicted_classes = torch.argmax(output[:,:,0-2:], dim=conf.post_activation_dim).detach().cpu().numpy() if conf.post_activation == \"softmax\" else np.where(predicted_probs > conf.train_probs_threshold, 1, 0)\n",
    "                target_classes = labels_data.detach().cpu().numpy()\n",
    "                padding_mask = padding_mask_data.cpu().numpy() if padding_mask_data is not None else None\n",
    "\n",
    "                # Concatenate for all batches\n",
    "                all_predicted_probs = np.concatenate([all_predicted_probs, predicted_probs], axis=0) if all_predicted_probs is not None else predicted_probs\n",
    "                all_predicted_classes = np.concatenate([all_predicted_classes, predicted_classes], axis=0) if all_predicted_classes is not None else predicted_classes      \n",
    "                all_target_classes = np.concatenate([all_target_classes, target_classes], axis=0) if all_target_classes is not None else target_classes      \n",
    "                all_padding_mask = np.concatenate([all_padding_mask, padding_mask], axis=0) if all_padding_mask is not None else padding_mask      \n",
    "\n",
    "                count += 1\n",
    "\n",
    "                if verbose: \n",
    "                    scores_str = {\"valid_%s\" % m.__name__: m(all_target_classes, all_predicted_probs, mask=all_padding_mask) for m in METRICS_PROBS}\n",
    "                    if METRICS is not None: scores_str = {**scores_str, **{\"valid_%s\" % m.__name__: m(all_target_classes, all_predicted_classes, mask=all_padding_mask) for m in METRICS}}\n",
    "                    scores_str[\"valid_loss\"]= (valid_loss / count)\n",
    "                    iterator.set_postfix_str(format_logs(scores_str))\n",
    "                \n",
    "            except Exception as ex:\n",
    "                print(\"Validation batch error:\", ex)\n",
    "    \n",
    "    scores = {\"valid_%s\" % m.__name__: m(all_target_classes, all_predicted_probs, mask=all_padding_mask) for m in METRICS_PROBS}\n",
    "    if METRICS is not None: scores = {**scores, **{\"valid_%s\" % m.__name__: m(all_target_classes, all_predicted_classes, mask=all_padding_mask) for m in METRICS}}\n",
    "    scores[\"valid_loss\"]= (valid_loss / count)    \n",
    "\n",
    "    return (scores, all_target_classes, all_predicted_classes, all_predicted_probs, all_padding_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 13906,
     "status": "ok",
     "timestamp": 1608897806410,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "oV9NVPFQbzmA"
   },
   "outputs": [],
   "source": [
    "# Train one fold\n",
    "factory = None\n",
    "def run_stage(X_train, X_valid, stage, fold, device):\n",
    "    \n",
    "    # Datasets\n",
    "    train_dataset = RIIIDDataset(X_train, conf, factory, subset=\"train\", categoricals=None, weights=True if conf.sampler == \"prob\" else False, flatten = conf.flatten, force_len=TRAIN_SPLIT_LEN)\n",
    "    valid_dataset = RIIIDDataset(X_valid, conf, factory, subset=\"valid\", categoricals=None, flatten = conf.flatten)\n",
    "\n",
    "    train_sampler = WeightedRandomSampler(weights=train_dataset.uweights[\"prob\"].values, replacement=True, num_samples=len(train_dataset)) if conf.sampler == \"prob\" else None\n",
    "        \n",
    "    # Dataloaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=conf.BATCH_SIZE, sampler=train_sampler, num_workers=conf.WORKERS, drop_last = False, pin_memory=conf.pin_memory, shuffle=True if train_sampler is None else False)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=conf.BATCH_SIZE, shuffle=False, num_workers=conf.WORKERS, drop_last = False, pin_memory=conf.pin_memory)\n",
    "\n",
    "    # Build model\n",
    "    snapshot_path = \"%s/fold%d/%s/snapshots\" % (MODEL_PATH, fold, stage)\n",
    "    if not os.path.exists(snapshot_path):\n",
    "        os.makedirs(snapshot_path)\n",
    "    cnn_model, criterion, optimizer = build_model(conf, device, freeze_backbone=FREEZE_BACKBONE, \n",
    "                                                  encoder_weights=os.path.join(snapshot_path.replace(stage, PRETRAINED_STAGE), MODEL_BEST) if PRETRAINED_STAGE is not None else None,\n",
    "                                                  backbone_weights=os.path.join(snapshot_path.replace(stage, PRETRAINED_BACKBONE_STAGE), MODEL_BEST) if PRETRAINED_BACKBONE_STAGE is not None else \"imagenet\")\n",
    "    \n",
    "    if RESUME == True:\n",
    "        resume_path = os.path.join(snapshot_path, MODEL_BEST)\n",
    "        if os.path.exists(resume_path):\n",
    "            cnn_model.load_state_dict(torch.load(resume_path, map_location=conf.map_location))\n",
    "            print(\"Resuming, model weights loaded: %s\" % resume_path)\n",
    "    \n",
    "    scheduler = None\n",
    "    if conf.scheduler is not None:\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=conf.EPOCHS_PER_CYCLE+1, eta_min=conf.min_lr)\n",
    "    print(criterion, optimizer, scheduler)\n",
    "\n",
    "    metric = METRIC_NAME\n",
    "    valid_loss_min = np.Inf\n",
    "    metric_loss_criterion = np.Inf if conf.METRIC_ == \"min\" else -np.Inf\n",
    "    history = []\n",
    "    for epoch in tqdm(range(1, conf.EPOCHS + 1)):\n",
    "\n",
    "        lr = optimizer.param_groups[0]['lr'] if isinstance(scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau) else scheduler.get_last_lr()[0] if scheduler is not None else optimizer.get_last_lr()\n",
    "        info = \"[%d], lr=%.7f\" % (epoch, lr)\n",
    "\n",
    "        # Train loop\n",
    "        train_scores, _, _, _ = train_loop_fn(train_loader, None, cnn_model, optimizer, criterion, device, stage=\"Train%s\" % info, verbose=conf.train_verbose)\n",
    "\n",
    "        # Validation loop\n",
    "        valid_scores, _, _, _, _ = valid_loop_fn(valid_loader, None, cnn_model, criterion, device, stage=\"Valid%s\" % info, verbose=conf.valid_verbose)\n",
    "\n",
    "        # Keep track of loss and metrics\n",
    "        history.append({\"epoch\":epoch, \"lr\": lr, **train_scores, **valid_scores})\n",
    "\n",
    "        if conf.scheduler is not None:\n",
    "            scheduler.step()\n",
    "\n",
    "        metric_loss = valid_scores[\"valid_%s\" % metric]\n",
    "        if (conf.METRIC_ == \"min\" and metric_loss < metric_loss_criterion and epoch > 1) or (conf.METRIC_ == \"max\" and metric_loss > metric_loss_criterion and epoch > 1):\n",
    "            print(\"Epoch%s, Valid loss from: %.4f to %.4f, Metric improved from %.4f to %.4f, saving model ...\" % (info, valid_loss_min, valid_scores[\"valid_loss\"], metric_loss_criterion, metric_loss))\n",
    "            metric_loss_criterion = metric_loss\n",
    "            valid_loss_min = valid_scores[\"valid_loss\"]\n",
    "            torch.save(cnn_model.state_dict(), os.path.join(snapshot_path, MODEL_BEST))\n",
    "\n",
    "    return (history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": []
    },
    "id": "l8MmUGpZgWRn",
    "outputId": "ca96582c-887b-4ff2-98ec-d6b6509ba379",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if TRAIN is True:\n",
    "    print(FEATURES)\n",
    "    print('Fold', FOLD, 'train users:', train_pd.reset_index()[USER_ID].nunique(), 'valid users:', valid_pd.reset_index()[USER_ID].nunique()) \n",
    "    print('Fold', FOLD, 'train size:', train_pd.shape, 'valid size:', valid_pd.shape)\n",
    "    _ = run_stage(train_pd, valid_pd, STAGE, FOLD, conf.L_DEVICE)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "MODEL-PT-v14.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
